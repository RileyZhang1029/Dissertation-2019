            C:\Documents and Settings\senthil.d\Desktop\Bioinfo-26(13)issue\btq230.dvi [09:55 15/6/2010 Bioinformatics-btq230.tex] Page: 1595 15951600 BIOINFORMATICS ORIGINAL PAPER Vol.
26 no.
13 2010, pages 15951600doi:10.1093/bioinformatics/btq230 Sequence analysis Advance Access publication May 13, 2010 Classification of DNA sequences using Bloom filters Henrik Stranneheim1,, Max Kller2, Tobias Allander3, Bjrn Andersson4, Lars Arvestad5 and Joakim Lundeberg1, 1Science for Life Laboratory, KTH Royal Institute of Technology, SE-100 44 Stockholm, 2LingVitae AB, Roslagstullsbacken 33, 114 21 Stockholm, 3Department of Microbiology, Laboratory for Clinical Microbiology, Tumor and Cell Biology, Karolinska University Hospital, Karolinska Institutet, SE-17176 Stockholm, 4Department of Cell and Molecular Biology, Karolinska Institutet, SE-17177 Stockholm and 5School of Computer Science and Communication, Stockholm Bioinformatics Center, AlbaNova University Center, Royal Institute of Technology, 106 91 Stockholm, Sweden Associate Editor: Alex Bateman ABSTRACT Motivation: New generation sequencing technologies producing increasingly complex datasets demand new efficient and specialized sequence analysis algorithms.
Often, it is only the novel sequences in a complex dataset that are of interest and the superfluous sequences need to be removed.
Results: A novel algorithm, fast and accurate classification of sequences (FACSs), is introduced that can accurately and rapidly classify sequences as belonging or not belonging to a reference sequence.
FACS was first optimized and validated using a synthetic metagenome dataset.
An experimental metagenome dataset was then used to show that FACS achieves comparable accuracy as BLAT and SSAHA2 but is at least 21 times faster in classifying sequences.
Availability: Source code for FACS, Bloom filters and MetaSim dataset used is available at http://facs.biotech.kth.se.
The Bloom::Faster 1.6 Perl module can be downloaded from CPAN atContacts: henrik.stranneheim@biotech.kth.se; joakiml@biotech.kth.se Supplementary information: Supplementary data are available at Bioinformatics online.
Received on September 11, 2009; revised on March 16, 2010; accepted on April 21, 2010 1 INTRODUCTION The era of personal genomics is fast approaching, as a result of which whole human genomes will be obtained on a routine basis.
Currently, only a fraction of such sequences contain relevant soughtafter information and the remaining sequences need to be removed.
More complex datasets are also becoming increasingly available, derived from: metagenome studies that contain a mixture of genetic material from different organisms present in environmental or patient samples (Allander et al., 2005; Rusch et al., 2007); studies of dynamic methylation pattern profiles (Down et al., 2008); and sequencing of re-arranged and mutated genomes (Ley et al., 2008).
To handle and analyse this vast amount of data requires fast, accurate and specialized methods that can align a large number of sequences onto genomes or reference sequences.
The increasing need for To whom correspondence should be addressed.
faster algorithms has led to the development of software such as MEGABLAST (Zhang et al., 2000), SSAHA (Ning et al., 2001) and BLAST-like alignment tool (Kent, 2002) for longer DNA sequence reads.
More recently, SOAP (Li et al., 2008b), MAQ (Li et al., 2008a), SHRIMP (Rumble et al., 2009), BWA (Li and Durbin, 2009) and Bowtie (Langmead et al., 2009) have been developed for shorter DNA sequence reads.
Many of these algorithms can detect single nucleotide changes.
For most of these existing methods a hash-table must be built containing either the query (BLAST, MAQ and SHRIMP) or reference (SSAHA, BLAT and SOAP) sequences; this hash-table must then be searched to align reads.
One important issue in metagenomic studies is the classification of sequences as novel, or belonging to a known genome, i.e.filtering out data that has been seen before.
There is a need for a fast preprocessing step that reduces the complexity of the data before more careful analysis is performed.
Often, it is the novel reads that are of interest and the location of other reads in their originating genomes is irrelevant.
This means that alignment tools, such as those mentioned above, actually perform more computations than necessary.
A Bloom filter is a space-efficient data structure with fast lookup times and a manageable risk of producing false positives.
It was originally developed by Burton Bloom in the 1970s to reduce the amount of space required to contain hash-coded information (Bloom, 1970).
In this article, an algorithm is described, fast and accurate classification of sequence (FACSs), which uses a novel scheme to classify sequence reads as belonging to one of many reference sequences or being novel.
The algorithm transforms the reference sequence into Bloom filters, and then the Bloom filters can be queried for exact matches.
This method allows rapid classification of sequences using
