            G:\bioinformatics\Bioinfo-26(8)issue\btq099.dvi [12:48 25/3/2010 Bioinformatics-btq099.tex] Page: 1112 11121118 BIOINFORMATICS ORIGINAL PAPER Vol.
26 no.
8 2010, pages 11121118doi:10.1093/bioinformatics/btq099 Databases and ontologies Advance Access publication March 3, 2010 Modeling sample variables with an Experimental Factor Ontology James Malone1,, Ele Holloway1, Tomasz Adamusiak1, Misha Kapushesky1, Jie Zheng2, Nikolay Kolesnikov1, Anna Zhukova1, Alvis Brazma1 and Helen Parkinson1 1Microarray Informatics Team, EMBL-EBI, Wellcome Trust Genome Campus, Hinxton, Cambridgeshire CB10 1SD, UK and 2Center for Bioinformatics, University of Pennsylvania School of Medicine, Philadelphia, PA 19104, USA Associate Editor: Alfonso Valencia ABSTRACT Motivation: Describing biological sample variables with ontologies is complex due to the cross-domain nature of experiments.
Ontologies provide annotation solutions; however, for cross-domain investigations, multiple ontologies are needed to represent the data.
These are subject to rapid change, are often not interoperable and present complexities that are a barrier to biological resource users.
Results: We present the Experimental Factor Ontology, designed to meet cross-domain, application focused use cases for gene expression data.
We describe our methodology and open source tools used to create the ontology.
These include tools for creating ontology mappings, ontology views, detecting ontology changes and using ontologies in interfaces to enhance querying.
The application of reference ontologies to data is a key problem, and this work presents guidelines on how community ontologies can be presented in an application ontology in a data-driven way.
Availability: http://www.ebi.ac.uk/efo Contact: malone@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
Received on November 24, 2009; revised on February 4, 2010; accepted on March 1, 2010 1 INTRODUCTION The description of experimental variables, even within a single discipline, involves the use of many cross-domain concepts.
For example, describing the characteristics of a single sample in an experiment can use terminology from cell biology, proteomics, transcriptomics, disease, anatomy and environmental science.
This is not a new problem and it is not restricted to bioinformatics.
However, it is pressing within this domain due to the quantity of heterogeneous data available in different formats across multiple resources (Schofield et al., 2009).
The desire to integrate data generated with different experimental technologies and in different biological domains motivates our work.
Experimental descriptions are captured and made available as text within database records, published papers and web site content.
These descriptions contain latent semantic information that is hard to extract and reflects the natural language of the domain.
One solution to this problem is the use of a controlled vocabulary to describe the data.
With this approach, the terminology used in a particular context is restricted to a set of terms that define important aspects of a domain or application.
Ontology adds an extra layer of expressivity by To whom correspondence should be addressed.
structuring this vocabulary into ontological classes and by specifying the sorts of operations that can be performed on them.
Importantly, the ontological models produced from this process are expressed in a language that enables human understanding and computational reasoning over the representation.
Languages such as the W3C recommendation Web Ontology Language (OWL) (Horrocks et al., 2003) aid interoperability by standardizing the syntax across all domains.
Advantageously, validation of this OWL representation can also be performed through the use of description logic reasoners (Sirin et al., 2007).
In bioinformatics, the interest in ontologies to model domain knowledge is apparent from the steadily increasing number of groups developing them.
In an attempt to align these efforts, the OBO Foundry (Smith et al., 2007) provides useful guidance on best practice for developing ontologies in the biomedical domain.
This includes the creation of orthogonal reference ontologies, from which classes are considered defining units of the area they describe.
Although this is a worthwhile longer term aim, the state of the art is that existing ontologies are not orthogonal or interoperable, and many present a focus that is unsuitable for gene expression data.
They can, however, be used to construct application ontologies that focus on describing and structuring a data space for a particular application.
While a vision of full interoperability between ontologies overcomes some of the barriers to integration, there still remain unresolved issues for data-driven applications.
Cross products, i.e.classes composed of two or more existing classes (formally in OWL, the intersection of two or more classes), are required between existing ontologies to more accurately describe omics data.
For example, a cell type in a given tissue or the transcription factors within a pathway activated in a disease state.
Few cross products are available to date partly because many ontologies do not use a common upper level ontology.
Where there are non-orthogonal ontologies, those that best describe a dataset of interest typically do not have the necessary cross products.
Furthermore, combining even ontologies that are interoperable can present problems.
Ontologies such as FMA (Rosse and Mejino, 2003) contain tens of thousands of classes, combined with other ontologies such as Gene Ontology (GO) and Disease Ontology (Osborne et al., 2009), and this presents a large model to consider; this is a particular problem if description logic reasoners are used for consistency checking and inference.
The use of multiple ontologies to annotate experimental data brings with it a considerable overhead.
Consider an annotation example, where a biological user submitting data needs the term lymphoma.
BioPortal (Noy et al., 2009) returns 629 matches from 24 ontologies.
The casual user is not equipped to select from these The Author(s) 2010.
Published by Oxford University Press.
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/2.5), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.
[12:48 25/3/2010 Bioinformatics-btq099.tex] Page: 1113 11121118 Experimental Factor Ontology non-orthogonal ontologies and selecting a more specific child term is more problematic; the Disease Ontology alone has 16 subclasses.
In other cases, such as genetic disease, many diseases are not present in the Disease Ontology or SNOMED despite their large size.
Inconsistent use of synonyms also presents a problem, as synonyms are often for a more or less granular term in another ontology.
Another consideration is that ontologies change over time and managing this in the context of annotations is problematic.
Mechanisms are therefore required to help manage this.
Representation of biological ontologies is necessarily complex as they have multiple purposes; explicitly modeling biological relationships, aiding interoperability with other ontologies and facilitating data annotation, to name a few.
This complexity is a barrier to the consumer of ontology annotated data as they may be unfamiliar with the language, constructs and labels used.
Consider the class information content entity from Information Artifact Ontology (IAO) (http://purl.obolibrary.org/obo/iao) defined as an entity that is generically dependent on some artifact and stands in relation of aboutness to some entity.
Such a definition may be incomprehensible to a biologist, yet is an important class in Experimental Factor Ontology (EFO).
A user-friendly view on upper level ontology is thus required.
In this article, we describe our data annotation and query use cases.
We present an application ontology, the EFO, which fulfills the use cases in the context of gene expression data; the methodology and tools that we have developed to produce the ontology are also described and are freely available.
We also illustrate the novel cross-product classes that we create using reference ontologies.
Our application ontology provides a solution for integrating reference ontologies, extracting information from text, applying annotation and visualization of biological data.
1.1 Motivation: the Gene Expression Atlas The Gene Expression Atlas (Kapushesky et al., 2010) provides summaries of gene expression across multiple experimental conditions, called experimental factors.
It also provides a gene level view of experimental data acquired from ArrayExpress (Parkinson et al., 2009).
This data is manually curated to provide an explicit, consistent and homogenous description across a wide range of sample attributes, such as species, developmental stage, disease and tissue type.
Protocol parameters related to the processing of samples, such as application of chemical compounds and sampling times, are also needed.
As of November 2009, there are 40 000 unique annotations of sample or assay properties covering 330 species in datasets suitable for the Gene Expression Atlas.
Given the diverse nature of the annotations, there is a need to support complex queries that contain semantic information.
For example, the query, which genes are under-expressed in brain cancer samples in human or mouse, requires the querying mechanism to understand the term cancer.
Annotations made at the experimental level are necessarily granular in nature; an experiment where the sample is of adenocarcinoma will be annotated with adenocarcinoma rather than more generally cancer.
A database query requiring cancer would therefore not return annotations to adenocarcinoma since this requires additional knowledge.
An alternative solution would be to annotate this sample with adenocarcinoma and cancer and any other intermediate classifications such as carcinoma; however, this has a number of disadvantages.
First, this requires curation, a labor-intensive process.
Second, it embeds the semantics within the database, tightly coupling the data with the domain knowledge.
This makes the approach fragile, since a change or extension to domain knowledge may require a large database update.
It also limits reuse of the knowledge within other resources.
A better solution to this problem is to annotate data using ontologies.
This enables the separation of the formal description of domain knowledge, allowing reuse of these resources and improving interoperability with other data with similar semantic representations.
To annotate the diverse data in the Gene Expression Atlas, classes are required from multiple existing ontologies to capture the cross-domain nature of the data.
Initially, we limited scope to data generated to 12 species including: human, mouse, rat, Arabidopsis, budding yeast, fission yeast, Drosophila melanogaster, Caenorhabditis elegans and zebra fish.
These species have ontologies that describe anatomy and developmental stages, though the limitations of gene expression technology mean that only a subset of tissues or other variables are typically analyzed.
An important use case is the comparability between experiments, for example, where the same tissue, cell type, disease and developmental stage was studied across experiments and species and the data can be potentially combined.
Finally, name value pairs that could be mapped to existing domain ontologies were prioritized as these also cover the most common queries e.g.disease state, cell line, cell type developmental stage, etc.
Data in the gene expression domain are typically not mapped to an ontology at the point of submission, and neither Gene Expression Omnibus nor ArrayExpress use species-specific ontologies in their submission tools.
Requiring use of ontologies at this point is a barrier to data deposition, therefore, the majority of ontology mapping occurs after submission and is based on user-supplied name value pairs e.g.DiseaseState = breast cancer.
An important use case is text mining of data prior to its inclusion in ArrayExpress.
Exploratory analyses of the data prior to the construction of EFO revealed that many terms appear at high frequencies and there is a long tailon the data distribution (Malone et al., 2009).
For example, in the ArrayExpress archive 1350 samples have the annotation heart, 65 ventricle, 14 myocardium and a single annotation for pericardium.
Compare this with the representation of the human heart from the Foundational Model of Anatomy (FMA) (Rosse and Mejino, 2003) where there are >20 terms describing the various parts of the heart.
It is clear that comparatively few terms are needed to describe the data in the Gene Expression domain and that the complexity in FMA is not needed.
For both text mining and query purposes across free text in the data, there is a requirement for synonyms.
This includes local synonyms, e.g.whole brain, to detect user-defined annotation or to deal with alternate spellings.
Our approach for the gene expression domain therefore is analogous to that of the GO (Blake and Harris, 2008), which was initially developed to describe gene products for model organism databases; it has a data-driven motivation, with ontological principles such as use of an upper level ontology applied to provide robustness and to allow interoperability with other ontologies.
2 METHODS The EFO is an application ontologyan ontology engineered for domainspecific use or application focus and whose scope is specified through testable 1113 [12:48 25/3/2010 Bioinformatics-btq099.tex] Page: 1114 11121118 J.Malone et al.use cases and which maps to reference or canonical ontologies.
EFO was developed following the middle-outmethodology first described in Uschold and Grninger (1996) and later by (Gmez-Prez et al., 2004).
Ontologies, like software, should conform to a set of specifications and use cases, and can be tested using competency questions.
Use cases are used to determine the classes we include, and the relations, restrictions and axioms used in our ontology: (1) Data annotationgoal: the primary use case for this application is the annotation of transcriptomics data in the Gene Expression Atlas.
Task: this is a coverage use case, i.e.can we annotate all of the data we wish to associate ontology classes with?
(2) Query supportgoal: to enable querying across hierarchies for which data exists (and is annotated).
Task: enabling queries such as retrieve all cell line data that is derived from epithelial tissue and are associated with cancer.
(3) Data visualization and explorationgoal: to present a tree structure of annotated data within Atlas.
Task: presenting an ontology tree to the user to show which classes have associated data.
(4) Data integrationgoal: to allow integration of data both across experiments in Gene Expression Atlas and externally.
Task: integrating with external resources that use or map to the same ontology class and compare data from these independent sources.
(5) Data summarization and mininggoal: to obtain an analysis of samples, given common conditions of interest.
Task: provide a summary for gene expression data levels for samples treated across same condition, e.g.treated with bacterial toxins.
In addition to use cases, a list of competency questions allows us to evaluate at which point the ontology is able to satisfy the scope of the application (Stevens et al., 2000).
Examples include Which cell lines are derived from epithelial cells?
and which organism parts are parts of the forebrain?
As the ontology will be applied in the context of gene expression data, e.g.which genes in cancerous vs. normal kidney samples in humans show differential expression?, both an ontological query and a data-driven query in the context of an application are needed.
The ontology therefore should represent cancer, kidney and human to resolve this query while the differential expression is determined by the application of the ontology in the context of the data, and this competency question therefore demonstrates the application domain.
One approach to ontology development is the use of a modular methodology using a mixture of generic domain, generic task and application ontologies whose parts are clearly defined so that they can be reused (Stevens et al., 2000).
Our methodology reuses reference ontologies (full list available at http://www.ebi.ac.uk/efo/metadata), where they exist and where they describe classes that are in scope for EFO.
We also enrich these classes with additional axioms e.g.making associations between cell lines and their cell types of origin.
To promote interoperability with the OBO Foundry ontologies, we have selected BFO as an upper ontology; however, we use only a subset of its classes necessary to fulfill our use cases and we provide user-friendly class labels.
An outline of the high-level classes that structure EFO is illustrated in Figure 1.
The five primary axes used are as follows: information, site, process, material and material property.
Our ontology development methodology is as follows (complete process documents can be found at www.ebi.ac.uk/efo): (1) Extract data annotations from the Atlas.
Determine the depth and breadth of these annotations and target the most frequently occurring annotations.
(2) Identify OBO Foundry reference ontologies relevant to an EFO category based on annotation use cases.
(3) Use the query use cases obtained from analysis of query logs to build an appropriate hierarchy.
Fig.1.
EFO upper level structure used to organize the ontology with intermediate node examples.
Fig.2.
Separating the ontology layer (EFO) from the data (ArrayExpress) and the presentation layers (Atlas).
(4) Perform mapping between existing annotations and reference ontologies using the Double Metaphone phonetic matching algorithm.
This produces a list of candidate ontology class matches.
(5) Expert validation of candidate matches, curate and include matched classes into the EFO hierarchy with appropriate intermediate nodes.
Adding classes takes two forms: Where there is no overlap between reference ontologies, import the class directly into EFO [maintaining the original Uniform Resource Identifier (URI)].
Where overlap exists, create a new EFO class (with EFO URI) as a mapping class and add annotation properties with URIs of all mapped classes.
(6) Perform mappings to other reference or application ontologies where these are not provided by the source ontology.
(7) Add structure to EFO to provide an intuitive hierarchy with userfriendly labels and add restrictions to add value e.g.associate cell lines with cell types and tissues of origin.
The strategy of decoupling the data, the presentation layer and the semantic layer is illustrated in Figure 2.
Using EFO as a separate layer in our application means we are able to effect changes to the ontology, such as adding new classes or new class relations, without modifying the underlying data or the presentation layer and manage changes in reference ontologies cleanly.
A further advantage of this approach is that the ontology can be reused without imposing any special requirements on the implementation or on the application presentation layer, thereby enabling EFO to be used in other applications and expanded accordingly.
Our methodology also aims to observe OBO Foundry best practice guidelines.
A set of OWL annotation properties are used to capture metadata 1114 [12:48 25/3/2010 Bioinformatics-btq099.tex] Page: 1115 11121118 Experimental Factor Ontology about the classes; we add human readable labels and use univocal and consistent syntax for class names.
Metadata details for EFO can be found at http://www.ebi.ac.uk/efo/metadata.
We also use the Relation Ontology (RO) (Smith et al., 2005).
There are relations that are not captured by RO (such as those used in OBI), and therefore, we extend RO where necessary.
Our intention is to integrate with future, richer versions of RO when available.
2.1 Detecting external ontology changes Ontologies that are used within biology evolve rapidly due to scientific advances and because the associated computational technologies are themselves rapidly evolving (Smith et al., 2007).
Because we consume from multiple ontologies, class information must be maintained and updated.
This problem is no more severe than if we mapped data annotations to each ontology separately, rather than to EFO that maps to external reference ontologies.
Here we list the changes in external ontologies which affect EFO: (1) An axiom is added to an existing named class.
(2) An axiom is removed from an existing named class.
(3) A new named class is added to the ontology.
(4) A named class is made obsolete.
(5) An annotation property is edited on a named class.
The OWL-API (Horridge et al., 2009) provides a Java-based interface which allows manipulation of OWL ontologies at the axiom level.
Therefore, comparing two different versions of OWL ontologies in an axiom-based approach, as seen in the OWL-API, can be achieved using a set difference operation.
In set theory this is given by a relative complement.
Formally, for sets A and B the relative complement of A in B, that is, the set of elements in B, but not in A, is given as: B\A={xB|x/A} (1) Given two sets of axioms, A and B, and axiom an: A = {a1,a2,a3,a4},B = {a1,a2,a3,a5} B\A = {a1,a2,a3,a5}\{a1,a2,a3,a4} = {a5} For a set of axioms which are equal: A = {a1,a2,a3,a4},B = {a1,a2,a3,a4} B\A = {a1,a2,a3,a4}\{a1,a2,a3,a4} = (2) A=B (3) We can use this information to deduce that no changes have occurred between ontologies and moreover to infer that the classes A and B are logically equivalent.
We have designed a freely available tool, Bubastis, to analyze and report on the five major types of ontology changes we enumerate.
Specifically, we extract the classes mapped to EFO and check for changes.
A log of any changes is created along with relevant time and date stamps and a report generated.
Usefully, if there are no changes the tool will automatically report this too.
This approach allows us to computationally manage the imports and mappings we create within EFO, ensuring they are valid and reducing the overhead on ontology curation.
It also allows us to manage remapping data annotations to EFO which makes the curation process easier.
Importantly, this allows us to maintain a consistent use of external resources ensuring that we do not map to obsolete classes, and erroneous mappings caused by external changes are flagged.
There is still an outstanding issue of how correct the external resources are.
For example, reference ontologies EFO has consumed contain their own mappings which we have further imported to expand interoperability.
On scrutiny, some of these were found to be incorrect.
For example, mappings to EFO class brain structure derived from synonyms in an external ontology Minimal Anatomical Terminology (MAT) included abnormal brain.
Errors of this type are communicated back to the authors of the source ontology.
This represents a useful feature of this methodology; we review how reference bio-ontologies map to one another and how correct these mappings are.
It is clear that synonyms are used in different ways in different contexts and care must be exercised when using these; we now validate synonyms prior to including these and provide feedback both requesting terms and flagging errors when performing mapping.
2.2 Creating an ontology view While an upper level framework can provide structure to the ontology, such high-level classes (cf.
Fig.1) can often appear as abstract and confusing for biological users.
For example, the Basic Formal Ontology (BFO) (Grenon and Smith, 2004) contains the classes continuant and occurent.
Such classes are useful to organize the ontology and to aid interoperability between ontologies, but are less helpful for a biological user.
With this in mind, we use only some of BFO within EFO, and those parts are hidden from users.
First, we create an annotation property, ArrayExpress_label, which we use to indicate a preferential label that is displayed in the Atlas browser which replaces any other label on the class, though such labels may also be synonyms and are supported for queries.
For example, the BFO class processual entity is displayed as process in the Atlas user interface for readability.
Second, we use a further annotation property organizational_class which is given a value of true in any classes we wish to hide from the user (e.g.disposition) which are identified as structural and which are not desired to be visualized in queries.
This allows us to show parts of the ontology relevant to the users, while still using an accepted upper level ontology.
Views generated from EFO are used in both the Atlas and ArrayExpress Archive.
EFO is used to improve searching across textual experimental descriptions and key value pairs used to annotate samples.
When a user enters a keyword that matches an EFO class, synonyms found in alternative_term annotation properties in EFO classes are also used in the search, thereby returning extra matches.
We also provide an option to extend searches with classes related to their query via is_a or part_of ontological relations.
This functionality as deployed in the ArrayExpress Archive is powered by the Apache Lucene as a search engine, and we have packaged the EFOpowered search extension as a separate Java library.
The algorithm consists of two parts.
First, EFO in OWL format is parsed; the ontology tree is traversed and synonyms, all part_of or is_a children for all classes in EFO are extracted and a map structure is built for fast lookup.
Second, the map structure is used with a rewritten input Lucene Query with additional synonyms and children (if the option is selected and if they exist).
For our previous example, query breast carcinomais transformed to (breast carcinoma OR breast cancerOR ductal carcinoma in situ, etc.).
This library is available as stand-alone JAR, Maven artifacts and source code from http://github.com/arrayexpress/aeinterface/tree/master/components/efo-query-expand/.
The Gene Expression Atlas code base is currently under revision to create a stand-alone install anywhere utility, which will also become publicly available and open source in the near future.
2.3 Supporting the linked data vision In addition to using EFO within the Gene Expression Atlas and ArrayExpress Archive, we also embrace the ideas of linked data and integration with external resources.
In the context of the semantic web, linked data describes a method of creating typed links between data (Bizer et al., 2009).
In EFO, we use dereferenceable URIs for all of the classes in the ontology which are assigned EFO URIs.
Such classes are assigned a unique identifier, e.g.http://www.ebi.ac.uk/efo/EFO_0000001, with the number fragment incremented for each new class.
Since each of these identifiers is dereferenceable via the http protocol, they can be requested 1115 [12:48 25/3/2010 Bioinformatics-btq099.tex] Page: 1116 11121118 J.Malone et al.from a web server and information about the class returned as userfriendly content.
These pages contain information such as the Resource Description Framework Schema (RDFS) class label, parent classes, child classes and annotation properties e.g.text definition.
These pages are also machine readable: the source code for each page is actually an EFO Resource Description Framework (RDF) fragment describing a specific class.
Computer agents can therefore interact with the EFO class web pages in a way that is analogous to human user interaction.
Note, this does not apply to those classes in which URIs are imported from external ontologies; for such ontology URIs, the owner of these ontologies would be responsible for creating dereferenceable URIs.
There are two key elements to linking gene expression data.
The first is that parts of the Atlas sample and assay data are annotated with EFO class identifiers.
We associate data elements to our explicit definition of what the data represent, by annotating each experiment with EFO classes.
The second element is the set of cross-ontology mappings that are maintained within EFO.
As EFO is an application ontology, there is an advantage in reusing and importing classes from existing ontologies where possible.
Not only does this reduce the effort in adding new classes to EFO, but it also provides interoperability (via cross
