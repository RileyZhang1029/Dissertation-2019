            G:\fpp\tex\journals\oup\BioInfo\Bioinfo-25(15)issue\btp266.dvi [15:20 26/6/2009 Bioinformatics-btp266.tex] Page: 1984 19841986 BIOINFORMATICS APPLICATIONS NOTE Vol.
25 no.
15 2009, pages 19841986doi:10.1093/bioinformatics/btp266 Systems biology CATMAID: collaborative annotation toolkit for massive amounts of image data Stephan Saalfeld1, Albert Cardona2, Volker Hartenstein3 and Pavel Tomanck1, 1Max Planck Institute of Molecular Cell Biology and Genetics, Pfotenhauerstrae 108, Dresden, Germany, 2Institute of Neuroinformatics, Uni/ETH Zrich, Winterthurerstrasse 190, Zrich, Switzerland and 3Department of Molecular, Cell and Developmental Biology, University of California, Los Angeles, USA Received on February 13, 2009; revised and accepted on April 15, 2009 Advance Access publication April 17, 2009 Associate Editor: Limsoon Wong ABSTRACT Summary: High-resolution, three-dimensional (3D) imaging of large biological specimens generates massive image datasets that are difficult to navigate, annotate and share effectively.
Inspired by online mapping applications like GoogleMaps, we developed a decentralized web interface that allows seamless navigation of arbitrarily large image stacks.
Our interface provides means for online, collaborative annotation of the biological image data and seamless sharing of regions of interest by bookmarking.
The CATMAID interface enables synchronized navigation through multiple registered datasets even at vastly different scales such as in comparisons between optical and electron microscopy.
Availability: http://fly.mpi-cbg.de/catmaid Contact: tomancak@mpi-cbg.de 1 INTRODUCTION High-throughput and high-resolution imaging technologies generate many more images than can be practically shown in printed journals and thus these massive image datasets are presented to the scientific community through web interfaces.
Recently, a new class of large-scale biological image data emerged that focuses on high-resolution description of large biological specimens using three-dimensional (3D) microscopy techniques.
Since most biological specimens are large in comparison to the scales employed by high-resolution microscopes, the entire specimens are captured by stitching many overlapping image tiles into a single canvas of virtually unlimited size.
Microscopy techniques used in the tiling mode present new challenges for the annotation, analysis and sharing of gigantic datasets.
An analogy can be drawn between high-resolution imaging of large biological specimens and Geographical Information Systems (GIS) showing satellite imagery of the earth.
In both cases, the raw image data must be viewed at a number of different scales to reveal notable features.
Similarly, both data types become meaningful only when significant landmarks in the images are labeled.
For geographical data, an impressive array of computational tools have been developed to represent the imagery overlaid with annotated features to form high-resolution maps of the planet available from everywhere via web-based interfaces.
In biology, To whom correspondence should be addressed.
features such as tissues, cells or organelles can be distinguished on different scale levels and serve as a map to orient in the complex anatomy of the biological entity.
It is clear that large anatomical scans of biological specimens must be accompanied with proper maps of relevant biological features to enable insights into the organization and function of biological systems.
Modern neurobiology is particularly active in mapping high-resolution anatomy (Mikula et al., 2007) and patterns of gene expression (Lein et al., 2007) in the brain.
We present here a decentralized web interface, modeled after GoogleMaps, to navigate large multidimensional biological image datasets and collaboratively annotate features in them.
We demonstrate the navigation, annotation and sharing functionality of the Collaborative Annotation Toolkit for Massive Amounts of Image Data (CATMAID) on a serial section Transmission Electron Microscopy (ssTEM) dataset covering the neuropile of one half of the first instar larval brain of Drosophila melanogaster.
2 IMPLEMENTATION CATMAID combines three main components: a centralized data server, decentralized image servers and the client-side user interface (Fig.1A).
The data server stores meta-information about datasets, users and annotations in a PostgreSQL database.
The entities of the database are projects, stacks, annotations, spatial entities and users.
Projects implicitly define global reference frames in 3D space and thus provide a spatial context for annotations and images.
Stacks are image datasets prepared for viewing through CATMAID (see below).
A stack stores its dimensions in pixels, the 3D resolution in nm/px and a base URL to the image server.
Stacks reference projects through a translation vector.
That is, each stack may appear in several contexts registered relative to different reference frames.
All stacks referencing the same project can be navigated synchronously.
Annotations are textlabels or
