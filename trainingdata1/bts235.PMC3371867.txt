Copyedited by: TRJ

MANUSCRIPT CATEGORY:

BIOINFORMATICS

Vol. 28 ISMB 2012, pages i147–i153
doi:10.1093/bioinformatics/bts235

Incorporating prior information into association studies
Gregory Darnell1,†, Dat Duong2,†, Buhm Han1 and Eleazar Eskin1,3,∗
1Department of Computer Science, University of California, Los Angeles, CA 90095, 2Department of Statistics,
University of California, Berkeley, CA 94720 and 3Department of Human Genetics, University of California,
Los Angeles, CA 90095, USA

ABSTRACT
Summary: Recent technological developments in measuring genetic
variation have ushered in an era of genome-wide association studies
which have discovered many genes involved in human disease.
Current methods to perform association studies collect genetic
information and compare the frequency of variants in individuals
with and without the disease. Standard approaches do not take into
account any information on whether or not a given variant is likely
to have an effect on the disease. We propose a novel method for
computing an association statistic which takes into account prior
information. Our method improves both power and resolution by
8% and 27%, respectively, over traditional methods for performing
association studies when applied to simulations using the HapMap
data. Advantages of our method are that it is as simple to apply to
association studies as standard methods, the results of the method
are interpretable as the method reports p-values, and the method is
optimal in its use of prior information in regards to statistical power.
Availability: The method presented herein is available at
http://masa.cs.ucla.edu
Contact: eeskin@cs.ucla.edu

1 INTRODUCTION
The cost of collecting genetic information has been decreasing
with advances in high-throughput genomic technology (Matsuzaki
et al., 2004). Over the last few years, hundreds of genes have
been identiﬁed as being associated with common human disease
(Risch and Merikangas, 1996; Visscher et al., 2012). Traditionally,
association studies are performed without making any assumptions
about which variants are more or less likely to be involved in the
disease. These methods evaluate an association statistic at each
single nucleotide polymorphism (SNP), and only take into account
one SNP at a time. The Bonferroni correction is often used to control
the overall false-positive rate by uniformly limiting the signiﬁcance
threshold at each SNP (Franke et al., 2010).

Current standard approaches report a p-value for each variant and
there is a good understanding in the community of what signiﬁcance
levels are required for genome-wide association (Pe’er et al., 2008).
Virtually all association studies report p-values as their results which
allows investigators to interpret their ﬁndings in the context of other
groups’ ﬁndings.

Although the lack of assumptions has the advantage of being
unbiased in the search for variants involved in the disease, we know
that not all SNPs contribute equally to the disease (Adzhubei et al.,
2010). Recent studies (Eskin, 2008) have shown that incorporating

†The authors wish it to be known that, in their opinion, the ﬁrst two authors
should be regarded as joint First Authors.
∗
To whom correspondence should be addressed.

information such as the results of

prior
functional studies
(ENCODE Project Consortium, 2007) can increase statistical power.
Unfortunately, the methods for incorporating prior information are
complicated and difﬁcult to apply in practice. Methods that use prior
information are typically Bayesian association study methods (Pe’er
et al., 2006; Fridley et al., 2010) and instead report Bayes factors
which are not usually reported in other studies. Although standard
methods do not take into account prior information, they do have
the advantage of being simple.

information, which is as

We present a novel method for performing association studies
using prior
simple to apply as
standard association statistics and reports p-values, yet, optimally
incorporates prior information. We extend our method to take
advantage of the correlation structure to consider multiple markers
in a region (de Bakker et al., 2005; Devlin and Risch, 1995). When
considering multiple markers, we compute an association statistic at
each SNP in the region, not only the collected SNPs. Incorporating
prior SNP information increases power over traditional association
studies while maintaining the same overall false-positive rate.

Our method can be used in association studies to improve both
the power and resolution of a study. When our method is applied
to simulations using data from individuals in the HapMap, we
demonstrate a signiﬁcant increase in power and resolution compared
with the methods used in a traditional association study. Our
method also has the advantage of maintaining the inherent simplicity
of a traditional association study. As a result, the computational
complexity of our method matches that of a traditional association
study.

We measure resolution by calculating the distance between
the location of the assumed causal SNP and the location of the
SNP corresponding to the maximum-likelihood ratio. Our method
increases the average resolution of the four HapMap populations by
27% and the average power by 8% over the traditional method.

Our method has a connection to multithreshold associations
presented in (Eskin, 2008). In this work, we show that
the
multithreshold association method which uses the prior information
optimally to maximize statistical power can be interpreted as a
likelihood ratio test (LRT). This is the key observation underlying
our approach and allows us to propose a very simple method which is
also optimal with respect to statistical power, but has the advantage
of being simple and easy to interpret.

2 METHODS
2.1 Traditional association studies
Traditional association studies collect m markers in N /2 case and N /2 control
individuals. We assume a low-disease prevalence, however, our method can
be easily extended to higher prevalence. For each marker i and relative risk γ ,
= γ fi/((γ −1)fi+1),
the true case allele frequency is deﬁned as follows: p

+
i

 The Author(s) 2012. Published by Oxford University Press.
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/
by-nc/3.0), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i147 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

G.Darnell et al.

−
i

where fi is the population allele frequency. The control allele frequency
−
i , is approximately equal to the population allele
for the causal maker, p
≈ fi. The non-causal markers have equal case and control allele
frequency, p
= p
−
+
i . The overall allele frequency in the case–control
frequencies, that is, p
i , ˆp
i )/2. Let ˆp
i and ˆpi be the observed values of the
sample is, pi =(p
+p
−
−
+
i
corresponding statistic.
(cid:2)
(cid:3)ˆpi(1−ˆpi)

The statistic

si =

−ˆp

+
i

+
i

−
i

(1)

ˆp

for each marker i is approximately normally distributed with variance 1
pi(1−pi). The
and mean non-centrality parameter λi
power of a standard association study to detect a signiﬁcant association at a
maker i, relies on the non-centrality parameter and is

N = p

−p

2/N

+
i

−
i

2
N

√

(cid:4)√

(cid:3)

√
N )= (−1(t/2)−λi

√
N )

Ps(t,λi

+1−(−1(1−t/2)−λi

√

N )

where the value of t is the signiﬁcance threshold, which serves to control
the overall false-positive rate, and  and −1 denote the cumulative density
function (CDF) and the inverse of CDF of the standard normal distribution,
respectively. The false-positive rate represents the probability of rejecting
the null hypothesis for any marker, assuming there is no causal marker. In
our case, we control this probability to α.
If markers are assumed to be independent, the signiﬁcance threshold is
computed using the Bonferroni correction, αs= α/M . It is important to note
that in traditional association studies, the signiﬁcance threshold, αs, is ﬁxed
for all markers, M .

computed for each marker, Ps(t,λi

When computing the overall power of a study,

√
the power is ﬁrst
N ). The overall power, deﬁned as
N ), is the average of the power computed at each marker.
For clarity, we have assumed that only the markers are the causal variants,
which is clearly not realistic; we drop this assumption below.

1
M Ps(t,λi

(cid:5)

√

M
i

2.2 Association studies with prior information
Obviously, we do not know which variant is causal and which variant is not
causal. However, some variants are more likely involved in the disease than
others based on information on how much of a molecular effect that variant
has. Let us assume that a marker i has probability ci of being causal. We
deﬁne a revised power function that includes prior probabilities

M(cid:6)

i

ci(cid:5)

cj

√
N )

Ps(αs,λi

(2)

where αs is set to control the overall false-positive rate to α.

2.3 Maximizing power in a multithreshold

association study

One way to incorporate prior information into association studies is to use
multithreshold association (Eskin, 2008). In this approach, we use a different
signiﬁcance threshold at each marker and these thresholds are set to maximize
the statistical power taking into account prior information (Adzhubei et al.,
2010). We denote the new set of thresholds as variables t1...tm. Overall power
can be deﬁned as a function of the thresholds t1...tm.
√
N )

(cid:6) ci(cid:5)

P(t1...tm)=

Ps(ti,λi

(3)

cj

(cid:5)

By optimizing the threshold at each marker, we can increase the overall
∗
power of a standard association study. Our task is to ﬁnd the t
...t
= α. This constrained
m
that maximizes (3) under the condition that
optimization can be solved using the method of Lagrange multipliers,
assuming the markers are not correlated. Below we show how to use this
method to maximize our object function, and as a result ﬁnd the per marker
threshold, t

...t

∗
1

∗
i

t

∗
1

∗
m.

The objective function to maximize is

(cid:6) ci(cid:5)

(cid:7)

α−

(cid:6)

(cid:8)

ti

.

√

N )+l

Ps(ti,λi

P(t1...tm)=

cj

(cid:9)

We take the partial derivative of the objective function with respect to ti

and l and set them equal to 0 to obtain

P(t1...tm)= ci(cid:5)

cj

√
N ,1)
φ(−1(ti/2);0,1)

0.5φ(−1(ti/2);λi
√
+ 0.5φ(−1(ti/2);−λi
N ,1)
φ(−1(ti/2);0,1)
(cid:6)
ti =0,

(cid:10)

P(t1...tm)=α−

∂
∂ti

∂
∂l

+l=0

(4)

(cid:5)

where φ is the probability density function (PDF) of the standard normal
distribution. See Appendix for the detailed derivation.
As (4) is true for all marker i∈1...m, we set up the following equality:
√
N ,1)
φ(−1(t1/2);0,1)

(cid:9)

cj

= ...= cm(cid:5)

(cid:9)

(cid:10)

c1(cid:5)
0.5φ(−1(t1/2);λ1
√
+ 0.5φ(−1(t1/2);−λ1
N ,1)
φ(−1(t1/2);0,1)
√
0.5φ(−1(tm/2);λm
N ,1)
φ(−1(t1/2);0,1)
√
+ 0.5φ(−1(tm/2);−λm
N ,1)
φ(−1(tm/2);0,1)
∗
∗
(cid:5)
m satisfying (5). We begin
1
, set it equal to (5), and solve for t1...tm simultaneously.
ti < α, we do otherwise) and repeat the
ti = α are denoted

(cid:5)

(cid:10)

(5)

cj

∗

∗

(cid:5)

ti = α. We can numerically ﬁnd t

where
with a guess for c
If
process. The resulting t1...tm satisfying the constraint
∗
t
1

ti > α, we decrease c
∗
m.

(when

...t

...t
We gain intuition on our method by imagining that we have a total budget
of α to distribute among a portfolio of i assets or stocks. Each asset has a
certain return on investment, which depends on the ti, the fraction of the total
budget that we allocate to the asset. In order to optimize the total return on our
budget of α, we allocate our funds such that the marginal return on investment
for each asset is equal. Intuitively, this is because if the marginal return is
not equal between investments, we can always increase the overall return
by taking out funds from the smaller return investment and put them into
the larger return investment. In the case of power, the budget is our overall
signiﬁcance threshold, α. The power return for each marker again depends on
the ti we allocate to each marker. In setting the optimal signiﬁcance threshold
for each marker, we consider the rate of return, or power, which depends on
the amount invested, or signiﬁcance threshold. In determining how to allocate
the fraction of the overall signiﬁcance threshold to each marker, we compute
the partial derivative of the power function at each marker and set them equal
to each other, which is equivalent to the investment-return analogy.

2.4 Connection to LRT
The key observation in this article is that the multithreshold association
has a close connection to the LRT. The LRT compares the likelihood ratio
of a statistic with a given threshold C
, where the likelihood ratio is a
direct comparison of the probability of observing the statistic under the null
distribution versus the alternative distribution. It is possible to apply the
LRT to determine an LRT statistic of a given marker, and thus determine a
signiﬁcance designation for that marker.

∗

Consider the probability of observing the statistic si in Equation (1). The

null distribution is

si ∼ N (0,1)

i148

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i148 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

Incorporating information to association studies

and the alternative distribution is, given the non-centrality parameter λi

si ∼0.5N (λi

√
N ,1)+0.5N (−λi

√
N ,1)

√

N ,

where the 50:50 mixture is taken assuming that we do not know the direction
of the effect (two-sided test). A standard LRT will reject the null hypothesis
at si if (0.5φ(si;λi
can be
set to control the overall false-positive rate to α.

√
N ,1))/φ(si;0,1) > C

√
N ,1)+ 0.5φ(si;−λi

. C

∗

∗

For the purposes of a multithreshold association study, we will modify
the likelihood ratio and the LRT such that the prior information is included,

0.5φ(si;λi

ci(cid:5)

cj

√
N ,1)+0.5φ(si;−λi
φ(si;0,1)

√
N ,1)

cj

∗

This likelihood ratio is exactly the same term found in (5). LRT in this case
∗
will be done by comparing this likelihood ratio to a number C
/2);−λi

, where
√
N ,1)

0.5φ(−1(t

/2);λi

∗
i

∗= ci(cid:5)

C

√
N ,1)+0.5φ(−1(t
φ(−1(t

/2);0,1)

∗
i

∗
i

where C
∗
<−1(t
i

is the threshold that controls overall false-positive rate to α.
∗
i

is >−−1(t

/2), then

Note that when observed value si at marker i
√
N ,1)

0.5φ(si;λi

√
N ,1)+0.5φ(si;−λi
φ(si;0,1)

ci(cid:5)

cj

∗

> C

/2) or

and we can reject the null hypothesis at i. Thus, LRT and multithreshold
association test are equivalent.

When there are correlations between markers, we can still ﬁnd a C
∗

that the chance of Â rejecting any of the null hypotheses is α. C
easily calculated using permutation (see Appendix).

∗

such
can be

2.5 Maximizing power for tag SNPs
Previously, we made the assumption that the markers themselves are causal.
Usually, markers are more likely to be tags for the causal variation. Using
this information, we can assign each potential polymorphism to the best
marker, or tag. We use notation vk ∈ Ti to associate each set of polymorphisms
vk to a single marker i. The effect of non-centrality parameter of indirect
association is reduced by a factor|rki|, where|rki| is the correlation coefﬁcient
between polymorphism k and marker i (Pritchard and Przeworski, 2001).
This correlation coefﬁcient can be determined from reference data such as the
(HapMap et al., 2005). We can give each polymorphism a prior probability
√
of being causal ck . If a polymorphism k is causal, the power function when
observing marker i is Ps(ti,rkiλk
N ). Let us denote the total power captured
by a marker i as P(ti,Ti,N ). In our case, the total power function of the
association study is

P(t1...tm)= m(cid:6)
= m(cid:6)

i

P(ti,Ti,N )

(cid:6)
vk∈Ti

ck(cid:5)

cj

i

√

N )

Ps(ti,rkiλk

(cid:5)

This power function can be maximized with respect to t1...tm using the same
ti = α. The objective function
approach as before. There is a constraint that
now becomes
√

(cid:6)

(cid:7)

(cid:8)

Ps(ti,rkiλk

N )+l

α−

ti

P(t1...tm)= m(cid:6)

(cid:6)
vk∈Ti

ck(cid:5)

cj

i

We take partial derivatives of this objective function with respect to ti and α
and set them equal to zero

(cid:6)
(cid:6)
vk∈Ti

ck(cid:5)

cj
ti =0

P(t1...tm)= l+

P(t1...tm)= α−

∂
∂ti

∂
∂l

√
N )=0

d
dti

Ps(ti,rkiλk

Similarly to Equation (A.3), we can obtain

(cid:9)

cj

ck(cid:5)

√
0.5φ(−1(t1/2);rk1λk
N ,1)
φ(−1(t1/2);0,1)
(cid:10)

(cid:6)
vk∈T1
√
+ 0.5φ(−1(t1/2);−rk1λk
N ,1)
φ(−1(t1/2);0,1)
(cid:9)
(cid:6)
vk∈Tm
√
+ 0.5φ(−1(tm/2);−rkmλk
φ(−1(tm/2);0,1)

√
0.5φ(−1(tm/2);rkmλk
N ,1)
φ(−1(t1/2);0,1)
(cid:10)

ck(cid:5)

N ,1)

cj

= ...=

(6)

In Section 2.4, when markers are assumed to be causal, we detect an

association at marker i if the observed statistic si at i satisﬁes

0.5φ(si;λi

ci(cid:5)

cj

√
N ,1)+0.5φ(si;−λi
φ(si;0,1)

√
N ,1)

∗

> C

√

ck(cid:5)

0.5φ(si;rkiλk

Similarly, when makers themselves are not assumed to be causal, we
determine an association at maker i if the statistic si at i satisﬁes

(cid:6)
vk∈Ti
is the threshold that controls false-positive rate to α, the overall
∗

M
signiﬁcant threshold of the association study. We can determine this M
by permutation even when there are correlations between markers.

N ,1)+0.5φ(si;−rkiλk
φ(si;0,1)

√
N ,1)

> M

cj

∗

∗

2.6 Multiple-testing adjusted p-value
We can obtain multiple-testing adjusted p-values in our multithreshold
association study as follows. In an association study with only one
marker, we deﬁne the test to be signiﬁcant if the observed statistic ˆs
is greater than its threshold −1(α/2). Then, we can use ˆs to compute
a p-value ˆα which measures how signiﬁcant of an association we
observed by using the relationship 2(ˆs)= ˆα. For example, in a traditional
association study with one marker, if the ˆα is (cid:7)0.05, then we can say
that this marker strongly associates with the disease. In an association
study with m markers, we identify the associated markers by comparing
each of the observed statistics ˆs1,...,ˆsm against its corresponding cutoff
−1(t1/2),...,−1(tm/2). To determine how signiﬁcant the association at
each marker is, we need to compute the p-value at that marker. As the
cutoff values −1(t1/2),...,−1(tm/2) are usually not identical in our
multithreshold association study, we compute the multiple-testing adjusted
p-values ˆα1,..., ˆαm at m markers separately. The multiple-testing adjusted p-
value is the probability under the null hypothesis of observing a signiﬁcant
association at any marker.
We compute the adjusted p-value ˆαi at a marker i by using its observed
ˆsi. If ˆsi = −1(ti/2),
then the multiple-testing adjusted p-value is α.
For ˆsi > −1(ti/2), we need to ﬁnd the p-value ˆαi < α. Estimating this
signiﬁcance level is equivalent to ﬁnding the ˆαi and a new set of thresholds
(cid:5)
∗
∗
m such that when we maximize equation (3) with the constraint
t
,...,t
= ˆαi, then the cutoff for marker i is 2(ˆsi). We denote the gradient
∗
1
j t
in Equation (5) at the observed marker i as ˆβ. As all the partial derivatives
j
of Equation (3) are equal at the optimal solution [Equation (5)], we can
=2(ˆsi), by setting each of the
∗
determine a new set t
gradients in Equation (5) equal to ˆβ. Finally, the p-value ˆαi is the sum of
1
m. Once the ˆα1,..., ˆαm have been determined, these values are sorted.
∗
∗
t
1
The marker corresponding to the lowest p-value is the one that is most
strongly associated to the disease. Using this approach, we can report a
p-value which is adjusted for prior information for each variant.

∗
∗
m, where t
i

,...,t

,...,t

2.7 New multivariate normal distribution method for

correlated markers

In the previous sections, we assumed independent markers 1...m that are
possibly correlated to causal variation. However, marker themselves can be

i149

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i149 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

ci(cid:5)

cj

∗

G.Darnell et al.

correlated to each other. If the markers are correlated, the statistics at the
markers follow a multivariate normal distribution (MVN) with variance–
covariance matrix , where the entries of  are the correlation coefﬁcients
between the markers (Han et al., 2009).

Here, we propose a new LRT method designed for the situation that the
markers are correlated. By using information from all the markers, we can
have better resolution than when inspecting one of the markers.

√
N ,...,rimλi

√
If variation i is causal and the marker j is correlated to i, the non-centrality
parameter at marker j is rijλi
N (Pritchard and Przeworski, 2001). If we
√
consider correlations between variation i and all the markers, the vector of
N =
non-centrality parameters with respect to causal variation i will be i
(ri1λi

√
N ).
√
N =(cid:8)0 and the alternate hypothesis Ha : i

We modify the LRT of the previous section to take into account multiple
√
correlated markers. Given a putative causal variation i, we have the following
N (cid:9)=(cid:8)0
null hypothesis H0: i
at markers 1...m.
Let (cid:8)s=(s1,...,sm) be the vector of the observed statistics of all markers.
The LRT is performed by comparing the probability of (cid:8)s under the null and
alternative hypothesis, using the formula

0.5φ((cid:8)s;i

√
N ,)+0.5φ((cid:8)s;−i

√
N ,)

∗

> C

(7)

φ((cid:8)s;(cid:8)0,)

is set to control the false-positive rate to α and can be found by
where C
permutation. φ is the PDF of the MVN distribution. Again, the 50:50 mixture
of the distributions is taken for the alternative hypothesis to perform two-
sided test. When the condition in Equation (7) is satisﬁed, we have sufﬁcient
evidence to reject the null hypothesis at variation i.

It should be noted that the new method is different from the methods
we described previously in that the testing is performed per each putative
causal variant instead of per each marker. The information of putative causal
variants is obtained from the reference dataset, for example, by considering
all known variants. This implies increased multiple-testing burden because
the number of known variants is much greater than the number of markers in
general. However, although the number of tests are considerably increased,
the test statistics are highly correlated and therefore the actual multiple-
testing burden increases less steeply than the number of tests if we use
permutation. Our results show that the new method outperforms previous
methods in terms of both power and resolution even after we take into account
the increased multiple testing burden.

3 RESULTS
3.1 Candidate gene study associations Project
We follow the evaluation protocol shown in (de Bakker et al., 2005)
to simulate association studies in a candidate gene-sized region
using the HapMap data ENCODE (ENCODE Project Consortium,
2007). In these simulations, we make case and control individuals
by randomly sampling from the pool of haplotypes from HapMap
samples in the ENCODE regions. The disease status for each
individual is decided by randomly assigning an SNP from this
region as causal with a certain relative risk. We assume the scenario
where we are using a whole-genome genotyping product such as
the Affymetrix 500k SNP chip (Matsuzaki et al., 2004) and where a
subset of SNPs from this region are collected as markers. Simulation
studies are done over the four HapMap populations in each of the
10 ENCODE regions.

We compare power of four different methods. The ﬁrst method
is the traditional association test where the Bonferroni correction
is used. The second method is the multithreshold association test
where the markers are assumed to be causal. Since this method only
takes into account the non-centrality parameter at each marker, it is
equivalent to accounting for the minor allele frequencies (MAFs) of

i150

the markers to determine the optimal multithresholds. We call this
method multithreshold method with MAF prior. The third method is
the multithreshold association test where we assume causal variants
are in LD with markers. We use the HapMap data and assign each
SNP to a marker by choosing the marker with the highest correlation
coefﬁcient with the SNP. This method takes into account not only
the non-centrality parameters (or MAF) at the causal variants but
also how many causal variants are assigned to each marker and how
much the marker and the assigned causal variants are correlated. We
call this method multithreshold method with LD and MAF prior.
This method is equivalent to the method presented in (Eskin, 2008).
The fourth method is the new MVN method where we assume the
markers are correlated. The testing is performed at each putative
causal variant.

To measure power of each method while correctly accounting
for the multiple testing burden of each method, we perform the
following simulation procedure. Assuming the null hypothesis of
no association, we generate 1000 null panels. We compute the
maximum statistic among all markers for all null panels to obtain the
empirical null distribution of maximum statistic for each method.
The top 5% quantile of the distribution gives us the empirically
estimated threshold for α=0.05. Then, we generate 1000 alternative
panels assuming the disease model. The power is measured as the
number of alternative panels whose maximum statistic exceeds the
threshold corresponding to α=0.05. This empirical procedure is
shown to accurately control the false-positive rate nearly identical
to permuting each panel (de Bakker et al., 2005).

Table 1 shows the power of all four methods. In general, the
multithreshold method with MAF prior does not show a better
performance than the traditional method. This shows that taking into
account only MAF and not the correlations between the marker and
the causal variants can be not helpful. The multithreshold method
with both LD and MAF prior increases power compared with the
traditional method, on average by 1.2%. When we consider only the
SNPs whose traditional method’s power is in mid-range (between
0.1 and 0.9), the power is increased by a greater amount, 4.0%,
which goes along with the results of (Eskin, 2008).

The power increase of the new MVN method is the greatest
among all methods. It increases power by 8.3% on average when
considering all SNPs and by 15.7% on average when considering
the SNPs with mid-range power. The power increase is even as
great as 24.7% in the YRI population for the SNPs with mid-range
power. This shows that the new MVN method can be very helpful
in detecting associations.

We also look at the resolution, by how far the peak association
statistic is located from the actual causal variant. We measure this
distance in the unit of basepairs and report the results in Table 2. The
multithreshold method with MAF prior does not help the resolution
either. On the other hand, the multithreshold method with both LD
and MAF prior improves the resolution by 2.4% on average for all
SNPs and by 4.0% on average for SNPs with mid-range power.
However, it failed to improve the resolution in one case (CEU
population and for the SNPs with mid-range power).

The new MVN method shows

the greatest amount of
improvement in resolution. The resolution is improved by 27.1%
on average for all SNPs and by 44.5% on average for SNPs with
mid-range power. This shows that the resolution is so dramatically
improved that the distance between the peak association statistic
and the causal variant became, on average, almost half compared

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i150 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

Incorporating information to association studies

Table 1. Summary of the power comparison among all 10 ENCODE regions

Pop.

CEU
YRI
CHB
JPT

No. of
tags

No. of
SNPs

10 710
13 176
8934
9248

678
708
606
608
Average

Trad

0.664
0.445
0.716
0.684
0.627

Mult (MAF),
n (%)
0.660 (−0.6)
0.437 (−1.6)
0.710 (−0.9)
0.675 (−1.4)
0.621 (−1.1)

All SNPs

Mult (LD),
n (%)

MVN,
n (%)

0.672 (1.3)
0.451 (1.5)
0.726 (1.4)
0.690 (0.9)
0.635 (1.2)

0.697 (5.0)
0.537 (20.8)
0.760 (6.1)
0.722 (5.6)
0.679 (8.3)

Trad

0.698
0.586
0.708
0.712
0.676

The numbers in parentheses are the power gain compared with the traditional method

Table 2. Summary of the resolution comparison among all 10 ENCODE regions

SNPs with power between 0.1 and 0.9
Mult (MAF),
n (%)

Mult (LD),
n (%)

MVN,
n (%)

0.706 (1.1)
0.577 (−1.6)
0.708 (−0.1)
0.696 (−2.3)
0.671 (−0.7)

0.733 (5.0)
0.604 (3.1)
0.740 (4.5)
0.736 (3.4)
0.703 (4.0)

0.784 (12.2)
0.731 (24.7)
0.813 (14.7)
0.803 (12.8)
0.782 (15.7)

Pop.

CEU
YRI
CHB
JPT
Average

Trad

33 334
47 017
26 582
30 740
34 418

Mult (MAF),
n (%)
33 377 (−0.1)
49 128 (−4.5)
25 340 (4.7)
30 195 (1.8)
34 510 (−0.3)

All SNPs

Mult (LD),
n (%)

MVN,
n (%)

33 078 (0.8)
45 561 (3.1)
25 977 (2.3)
29 808 (3.0)
33 606 (2.4)

27 153 (18.5)
30 247 (35.7)
20 045 (24.6)
22 917 (25.4)
25 090 (27.1)

Trad

42 983
49 245
36 633
42 342
42 801

SNPs with power between 0.1 and 0.9

Mult (MAF),
n (%)
43 658 (−1.6)
50 828 (−3.2)
35 182 (4.0)
40 771 (3.7)
42 610 (0.4)

Mult (LD),
n (%)
43 040 (−0.1)
45 690 (7.2)
34 875 (4.8)
40 731 (3.8)
41 084 (4.0)

MVN,
n (%)

27 505 (36.0)
27 299 (44.6)
19 981 (45.5)
20 183 (52.3)
23 742 (44.5)

The unit of resolution is basepairs. The numbers in parentheses are the improvement percentage in resolution compared with the traditional method

with the traditional method in the case of the SNPs with mid-range
power.

We make an unrealistic assumption that we know the relative
risk of the causal polymorphism to be 1.30 and use this assumption
to determine the optimal thresholds. We measure the effect of an
incorrect assumption by obtaining optimal thresholds at a relative
risk of 1.30 and measure the power of these thresholds under a
wide range of relative risks. Figure 1 shows the total average
power under different relative risks for the traditional method,
the multithreshold method with LD and MAF prior, and the new
MVN method. Even when the assumed relative risk is incorrect, the
multithreshold method and the new MVN method outperform the
traditional method.

3.2 Extrinsic information on candidate

gene-sized regions

We measure the impact of extrinsic information on candidate
gene-sized regions using the HapMap data ENCODE regions
by simulating association studies with unequal priors at
the
polymorphisms. We ﬁrst consider the assumption that causal SNPs
can be anywhere in the genome, and randomly pick 10% of the
variants. Then, we upweight the likelihoods of being causal of
these polymorphisms by 25 times. We simulate association studies
by picking the causal SNP among these polymorphisms. As we
upweight the likelihood of being causal for the actual causal SNP in
this simulation, we expect that the methods accounting for the prior
information will show a better performance.

In our results, the power increase of the multithreshold method
with LD and MAF prior and the MVN method are 2.0% and
11.3% relative to the traditional method, respectively. The amount
of power increase is greater compared with when no extrinsic

Fig. 1. Average power under varying relative risks

prior information was given (1.2% and 8.3%), as expected. The
resolution improvements of the two methods are 5.6% and 55.5%,
which are also greater than the improvements we had when no
extrinsic prior information was given (4.0% and 15.7%). The most
notable change by incorporating extrinsic prior information occurred
on the resolution improvement percentage of the MVN method
(15.7–55.5%). When considering the SNPs with mid-range power,

i151

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i151 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

G.Darnell et al.

the resolution improvement of the MVN method relative to the
traditional method is as great as 70.4% after incorporating the prior
information. This shows that the use of correct prior information can
help both the power and the resolution of the methods we proposed,
especially the resolution of the MVN method. On the other hand, the
power and resolution of the multithreshold method with only MAF
prior did not beneﬁt from the extrinsic prior information, possibly
because the method only takes into account the markers and not the
uncollected putative causal variants.

4 DISCUSSION
We have presented a novel statistical method for incorporating prior
information into association studies. The advantage of our method
is that we can optimally incorporate prior information with respect
to statistical power but still report p-values for each variant. By
incorporating the correlation structure underlying the HapMap, we
manipulate the signiﬁcance threshold at each SNP to improve the
overall power of a study. Experiments show that our method has
a similar computational overhead yet greatly increased power and
resolution to traditional association study methods.

Our method has similarities with, the method presented in (Roeder
et al., 2007) and (Roeder and Wasserman, 2009). The difference
is that while Roeder et al. present the general framework for
optimally setting multithresholds for tests, our method is speciﬁcally
focusing on the context of genetic association studies using available
information of both MAF and LD. For example,
if only the
non-centrality parameter of the statistic at the tested markers is
considered as presented in the general framework of Roeder et al.,
the method will be exactly equivalent to the multithreshold method
with MAF prior that we examined in our simulations. We show
that this method does not achieve a better performance than the
traditional method in terms of both power and resolution. Moreover,
we present the novel MVN method that assumes correlation between
markers and that outperforms both the traditional method and the
multithreshold method of (Eskin, 2008), which is distinctive from
the framework assuming independency between the tests.

The new MVN method has some similarities with the weighted
haplotype test (Zaitlen et al., 2007) or imputation method (Marchini
et al., 2007). In both the new method and their methods, the
unobserved causal variant is tested using the observed markers.
However, the intrinsic difference is that our method takes into
account prior information to optimally set signiﬁcance thresholds
differently to each causal variant in the context of multiple-testing
correction. Moreover, the application of the method is much simpler
than those methods, requiring only the MAF and LD information
from the reference dataset but not the actual haplotype data.

As we use prior information to improve power and resolution,
the drawback is that the performance will not be optimal if the
prior information is incorrect. For example,
the MAF or LD
information from the HapMap data can have sampling variation and
the extrinsic information about the deleterious effect of the variant
can be inaccurate. A possible approach dealing with inaccurate prior
information can be explicitly accounting for the uncertainty. For
example, we reduce the correlation coefﬁcient estimated from the
HapMap by a small amount because the likelihood of the MVN
distribution becomes zero if the perfectly correlated markers in the
reference is not perfectly correlated in the sample. A systematic
approach dealing with prior uncertainty will be an interesting subject

i152

of the future research. However, we assume that the uncertainty in
the prior information will be decreased in the future as the sample
size of the reference dataset increases (1000 Genomes Project
Consortium, 2010).

Funding: G.D., D.D., B.H. and E.E. are supported by National
Science Foundation grants 0513612, 0731455, 0729049, 0916676
and 1065276, and National Institutes of Health grants K25-
HL080079, U01-DA024417, P01-HL30568 and PO1-HL28481.
B.H. is supported by the Samsung Scholarship.

Conﬂict of Interest: None declared.

REFERENCES
1000 Genomes Project Consortium. (2010) A map of human genome variation from

population-scale sequencing. Nature, 467, 1061–1073.

Adzhubei,I.A. et al. (2010) A method and server for predicting damaging missense

mutations. Nat. Methods, 7, 248–249.

Altshuler,D. et al. (2005) A haplotype map of the human genome. Nature, 437,

1299–1320.

de Bakker,P.I.W. et al. (2005) Efﬁciency and power in genetic association studies. Nat.

Genet., 37, 1217–1223.

Devlin,B. and Risch,N. (1995) A comparison of linkage disequilibrium measure for

ﬁne-scale mapping. Genomics, 29, 311–322.

ENCODE Project Consortium. (2007) Identiﬁcation and analysis of functional elements

in 1% of the human genome by the encode pilot project. Nature, 447, 799–816.

Eskin,E. (2008) Increasing power in association studies by using linkage disequilibrium
structure and molecular function as prior information. Genome Res., 18, 653–660.
Franke,A. et al. (2010) Genome-wide meta-analysis increases to 71 the number of

conﬁrmed crohn’s disease susceptibility loci. Nat. Genet., 4, 1118–1125.

Fridley,B.L. et al. (2010) Bayesian mixture models for the incorporation of prior
knowledge to inform genetic association studies. Genet. Epidemiol., 34, 418–426.
Han,B. et al. (2009) Rapid and accurate multiple testing correction and power estimation

for millions of correlated markers. PLoS Genet., 5, 1–14.

Marchini,J. et al. (2007) A new multipoint method for genome-wide association studies

by imputation of genotypes. Nat. Genet., 39, 906–913.

Matsuzaki,H. et al. (2004) Genotyping over 100,000 SNPS on a pair of oligonucleotide

arrays. Nat. Methods, 1, 109–111.

Pe’er,I. et al. (2006) Evaluating and improving power in whole-genome association

studies using ﬁxed marker sets. Nat. Genet., 38, 663–667.

Pe’er,I. et al. (2008) Estimation of the multiple testing burden for genomewide
association studies of nearly all common variants. Genet. Epidemiol., 32, 381–385.
Pritchard,J. and Przeworski,M. (2001). Linkage disequilibrium in humans: models and

data. Am. J. Hum. Genet., 69, 1–4.

Roeder,K. and Wasserman,L. (2009) Genome-wide signiﬁcance levels and weighted

hypothesis testing. Stat. Sci., 24, 398–413.

Risch,N. and Merikangas,K. (1996) The future of genetic studies of complex human

diseases. Science, 273, 1516–1517.

Roeder,K. et al. (2007) Improving power in genome-wide association studies: weights

tip the scale. Genet. Epidemiol., 31, 741–747.

Visscher,P.M. et al. (2012) Five years of GWAS discovery. Am. J. Hum. Genet., 90,

7–24.

Zaitlen,N. et al. (2007) Leveraging the hapmap correlation structure in association

studies. Am. J. Hum. Genet., 80, 683–691.

APPENDIX
A1. Maximizing power in a multithreshold

association study
(cid:5)
∗
Our task is to ﬁnd t
m that maximize (3) under the condition
ti = α. We use the method of Lagrange multipliers to ﬁnd such
∗
∗
m . This is our objective function
1

∗
1

...t

...t

t

(cid:6) ci(cid:5)

P(t1...tm)=

Ps(ti/2,λi

cj

(cid:7)

√
N )+l

α−

(cid:6)

(cid:8)

ti

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i152 i147–i153

Copyedited by: TRJ

MANUSCRIPT CATEGORY:

Incorporating information to association studies

When we take partial derivative with respect to ti and set it equal

to 0, we observe

P(t1...tm)= ci(cid:5)

∂
∂ti

√

N )+l=0

d
dti

Ps(ti/2,λi

ci

the deﬁnition of the CDF of the normal

distribution:

First, we present

(cid:11)
−t2/2dt
x
(cid:13)
(cid:14)(cid:15)
−∞e
x√
2
Now, we present the properties of erf(x).
−t2

(x)= 1√
(cid:12)
2π
1+erf
= 1
2
(cid:11)

erf (x)= 2

dt

e

x

π

0

−x2√

π

erf (x)= 2e

d
dx

Now, we consider the power function

Ps(t,k)= (−1(t/2)−k)+1−(−1(1−t/2)−k)

where k is the non-centrality parameter.

To maximize the power of a standard association study with

respect to t, we ﬁnd

d
dt

Ps(t,k)= d
dt
= d
dt

(cid:7)
(−1(t/2)−k)+1−(−1(1−t/2)−k)
(cid:7)
(−1(t/2)−k)
(−1(1−t/2)−k)

(cid:8)

(cid:8)

(cid:7)

(cid:8)

By applying (A.1), we get

d
dt

Ps(t,k)= d
(cid:16)
dt

− d
dt

1
2

− d
dt
(cid:16)

(cid:17)

(cid:16)
(cid:17)

1
2
1+erf

√
2

−1(t/2)−k

1+erf
(cid:16)
−1(1−t/2)−k
(cid:17)
(cid:16)
(cid:16)

√
2
−1(t/2)−k

erf
−1(1−t/2)−k

d
dt

√

2

= 1
(cid:17)
2

− 1
2

d
dt

erf

√

2

(cid:18)(cid:19)(cid:18)
(cid:18)(cid:19)(cid:18)
(cid:18)(cid:19)
(cid:18)(cid:19)

d
dt

By using (A.2), we get
√
Ps(t,k)=(1/2)(2/
−(1/2)(2/
=(1/
√

√
2π)e
√

(cid:20)

2π)e
−

2

√

√

(cid:20)

−

(cid:7)

(cid:21)2

−1(t/2)−k

−1(1−t/2)−k

(cid:21)2
(cid:7)

(cid:8)
−1(t/2)
d
(cid:8)
dt
−1(1−t/2)
(cid:7)
(cid:8)
−.5[−1(t/2)−k]2 d
−1(t/2)
(cid:7)
(cid:8)
dt
−1(1−t/2)

d
dt

2

2π)e
−.5[−1(1−t/2)−k]2 d
dt

−(1/

2π)e

(A.3)
Equation (A.3) can be simpliﬁed using the property −1
(1−t/2)=−−1(t/2),

(cid:7)

(cid:8)

Ps(t,k)=(1/

d
dt

2π)e

−.5[−1(t/2)+k]2 d
dt

−1(t/2)

√

(cid:7)

(cid:8)

−.5[−1(t/2)−k]2 d
dt
−.5[−1(t/2)+k]2 +e

−−1(t/2)
−.5[−1(t/2)−k]2

(cid:15)

√
2π)e

(cid:12)

2π)
e
−1(t/2)

−(1/
√
=(1/
∗ d
dt

(A.1)

(A.2)

Now, we solve for d
dt

d
dt
and the property:

−1(t/2). We use the property:

−1(x)=√
−1(t/2)=√
−1(t/2)= d
dt

2[erf
2[erf
(cid:20)√

−1(2x−1)]
−1(2(t/2)−1)]
(cid:21)

−1(t−1)

2erf
√

d
dx

(cid:20)√

2erf

d
dt

(cid:8)

π
2

[erf
−1(t−1)

[erf
−1(x)]=
[e
(cid:7)
(cid:21)
=√
d
2
√
dt
=
2π
2

erf
[erf

e

−1(x)]2]
−1(t−1)
−1(t−1)]2

(A.4)

(A.5)

(A.6)

√
Using, (A.5) and (A.6), we ﬁnd
−1(t/2)=

d
dt

e.5(−1(t/2))2

2π
2

By plugging this into (A.4), we have

Ps(t,k)= 0.5φ(−1(t/2);k,1)+0.5φ(−1(t/2);−k,1)

φ(−1(t/2);0,1)

.

d
dt

This equation is the likelihood ratio of a random variable s at the
value −1(t/2) or equivalently at the value −−1(t/2), between
the alternative hypothesis s∼0.5N (k,1)+0.5N (−k,1) and the null
hypothesis s∼ N (0,1). The 50:50 mixture of the two symmetrically
positioned distributions under the alternative hypothesis can be
considered due to the two-sided testing that we perform when we
do not have any prior knowledge about the direction of the allele
effect.

,

∗

∗

to set

A2. Controlling false-positive rate using permutation
When considering many correlated markers in an association study,
we need to ﬁnd a valid threshold of statistic, C
the
signiﬁcance threshold for each test such that the overall false-
positive rate of the study is controlled to α. The following algorithm
is the general method for the permutation procedure, for which
the resulting vector allows us to determine a certain C
to limit
the overall false-positive rate of the study. In our example, the 5%
quantile of S yields an α level of 0.05.
Initialize empty vector S
for j=1→ n do
Randomly assign disease status of individuals
for marker i=1→ m do
Obtain statistic si at each marker i
end for
Keep max{s1...sm} in S.
end for
Sort S.
Take top 5% quantile of S. This value is C

∗

.

[20:04 28/5/2012 Bioinformatics-bts235.tex]

Page: i153 i147–i153

i153

