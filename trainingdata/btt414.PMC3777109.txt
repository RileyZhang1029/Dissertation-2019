ABSTRACT Motivation: The research area metabolomics achieved tremendous popularity and development in the last couple of years.
Owing to its unique interdisciplinarity, it requires to combine knowledge from vari-ous scientific disciplines.
Advances in the high-throughput technology and the consequently growing quality and quantity of data put new demands on applied analytical and computational methods.
Exploration of finally generated and analyzed datasets furthermore relies on powerful tools for data mining and visualization.
Results: To cover and keep up with these requirements, we have created MeltDB 2.0, a next-generation web application addressing storage, sharing, standardization, integration and analysis of metabo-lomics experiments.
New features improve both efficiency and effect-ivity of the entire processing pipeline of chromatographic raw data from pre-processing to the derivation of new biological knowledge.
First, the generation of high-quality metabolic datasets has been vastly simplified.
Second, the new statistics tool box allows to inves-tigate these datasets according to a wide spectrum of scientific and explorative questions.
Availability: The system is publicly available at https://meltdb.cebitec.
uni-bielefeld.de.
A login is required but freely available.
Contact: nkessler@cebitec.uni-bielefeld.de Received on May 6, 2012; revised on July 11, 2013; accepted on July 14, 2013 1 INTRODUCTION Metabolomics research covers all aspects of the investigation of small molecule metabolite compositions resulting from cellular processes and constitutes an integrated part of systems biology (Bino et al., 2004).
Like transcriptomics and proteomics, meta-bolomics is capable of measuring extrinsically initiated changes in organisms.
The metabolome, the entity of all small molecules in a cell, organism or tissue, is considered to be the closest to the phenotype of all-omes (Fiehn, 2002).
Compared with other molecular levels or-omics methods, metabolomics is challenging in its high degree of interdiscipli-narity, interlinking experts from research fields as diverse as engineering, physics, chemistry and biology and from cheminfor-matics over bioinformatics to statistics, data mining and finally visualization.
Both sample acquisition and subsequent analysis are auto-mated in high-throughput instruments, which has continuously posed challenges on the systematic storage and computational processing of the gathered experimental datasets, starting in the early 2000s.
The increasing number and quality of measurements not only raised the generated data volume but also allowed to address more complex biological questions within conducted ex-periments.
To comprehensively address these demands, bioinfor-matics internet applications were developed.
MeltDB, a software platform for the analysis and integration of data from metabolo-mics experiments, has been published by Neuweger et al.
(2008).
Xia et al.
(2009) released MetaboAnalyst, a comprehensive tool suite for metabolomic data analysis.
Carroll et al.
(2010) pub-lished the MetabolomeExpress web server as a public place to process, interpret and share GC/MS metabolomics datasets.
Since around 2008, we have observed that the requirements to comprehensive metabolomics software platforms have changed: The general growth of the field of metabolomics and the increas-ing number of collaborations diversified the user community of researchers and their individual scientific goals.
It is obvious that the success of a metabolomics study depends on an efficient and effective collaboration of this interdisciplinary research commu-nity.
Thus, not only the availability and sharing of the data is important but also special functions have to be significantly ex-tended with specific features to consider all researchers demands and perspectives.
In addition, the ever-increasing throughput and the constant lack of time makes it immensely important that automated pre-processing methods are reliable and that analyses and manual intervention are fast and easy.
Since Metabolomics approaches are applied to more and more scientific objectives, a powerful set of statistical methods is mandatory, ranging from hypothesis-driven statistical tests to less specified and untargeted data-mining methods, such as clustering and dimension reduc-tion.
Finally, the wealth of generated data poses a necessity for exploratory data analysis tools and information visualization.
To tackle these new challenges systematically, a next gener-ation of bioinformatics tools needed to be developed, covering all of the aforementioned aspects of metabolome data analysis, ranging from processing raw data (RD) to finishing and finally the derivation of biological knowledge.
During the stages of that process, one can identify four successive data categories that represent different levels of data classification and annotation as well as different levels of abstraction.
First, RD, stored and organized in meaningful groups, build the basis.
Then, pre-processed data (PD) is computed, where peaks and their*To whom correspondence should be addressed.
The Author 2013.
Published by Oxford University Press.
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.
For commercial re-use, please contact journals.permissions@oup.com https://meltdb.cebitec.uni-bielefeld.de https://meltdb.cebitec.uni-bielefeld.de mailto:nkessler@cebitec.uni-bielefeld.de `` '' to `` '' `` '' `` '' , , And (EDA) above raw data ( ) s quantities have been detected.
It follows integrated data (ID), where peaks that putatively originate from the same compound are consistently annotated over chromatograms of an experiment and thus become comparable.
Last, derivative data (DD) is achieved by statistical analyses of metabolite quantities in an experiment and then visualized to allow effective exploration and to draw conclusions.
In this manuscript, we present MeltDB 2.0, which offers novel tools to challenge the rising wealth of data quality and quantity and support the analysis of all four categories RD, PD, ID and DD and includes a multitude of updates.
New and improved preprocessing methods underpin the reliability of automatically created annotations.
At the same time, straightforward tools for manual peak annotation simplify the curation even of large ex-periments.
To help answering questions of different scientific objectives, the set of statistical analyses and data-mining tools has been strongly enriched.
To finally nail down the quintessence of an experiments outcome, data exploration is supported by new interactive and telling information visualizations.
2 IMPLEMENTATION AND METHODS The first version of the MeltDB software platform, a three-tiered web application and database server published in 2008 (Neuweger et al., 2008), provides means for the standardization, systematic storage and analysis of gas chromatographymass spectrometry (GC-MS) metabolomics experiments.
Within a powerful project and user management, raw chromatograms of various file formats can be uploaded and organized into chro-matogram groups (e.g.
replicates, factor levels) and experiments.
A flexible processing pipeline allows to find, quantify and iden-tify peaks in the raw chromatograms.
Subsequently, a set of statistical tools and visualizations can be applied to analyze the gathered data tables.
This fast growing, free online platform today hosts425 distinct projects conducted by4150 registered users from around the world.
More than 17 000 chromatograms have been uploaded and analyzed yet.
In the following, all major improvements to the entire process from RD to DD will be described in more details.
Figure 1 summarizes the four stages of data processing and associates visualizations and data mining methods that can be performed in MeltDB 2.0 to each stage.
2.1 From RD to PD: improved pre-processing In metabolomics data analysis, pre-processing is a critical step, as ID and DD build on PD.
To ensure a reliable data basis for statistical data exploration, MeltDB 2.0 is equipped with several new and updated algorithms for the early steps of experiment data analysis.
The growing list of pre-processing methods now includes sup-port for the centWave algorithm by Tautenhahn et al.
(2008) for chromatographic peak detection, which features a high sensitiv-ity, and updates of the XCMS package (Smith et al., 2006) for chromatogram alignment and profiling analyses.
In addition, the ChromA (Hoffmann and Stoye, 2009) software is added to the list of supported chromatogram alignment tools.
ChromA com-putes pairwise alignments of chromatograms without a priori knowledge, but it is capable of optionally using previously matched or identified peaks as anchor points, which speeds up the process.
The calculation of retention time indices in GC-MS measure-ments is improved and can now also be performed manually using the web interface.
Peaks of added substances can be as-signed with retention indices and will be used as anchors for interpolating other peaks retention indices (Ettre, 1994), which Fig.1.
The overview shows the information processing in MeltDB 2.0 as well as visualizations and tools that are applicable to each level of data: RD, PD, ID and DD.
Although different chromatogram viewers are available immediately after RD upload, heatmaps and data matrices can only be computed as soon as data have been integrated, i.e.
there are peaks that are consistently named across chromatograms.
To finally derive knowledge from the data, MeltDB 2.0 offers a versatile set of statistics and data-mining tools 2453 MeltDB 2.0 , 3 more than more than , raw data derivative data raw data pre-processed data I integrated data derivative data up pre-processed data In order  support subsequent peak identification (Kopka et al., 2005).
The detection of alkanes as retention markers can be automated.
Furthermore, peak identification itself is facilitated with a powerful feature: MeltDB 2.0 offers a new Reference list tool to save peaks of measured reference substances as Reference in the MeltDB database.
The stored data comprises retention indi-ces, quantification masses and mass spectra of reference com-pounds.
This helps to generate project specific databases that complement the Golm Metabolite Database (http://gmd.
mpimp-golm.mpg.de/) (Kopka et al., 2005) or the National Institute of Standards and Technology standard reference data-base 1A (http://www.nist.gov/srd/nist1a.cfm).
The tool allows to aggregate
