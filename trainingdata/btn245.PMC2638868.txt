BIOINFORMATICS ORIGINAL PAPER Vol.
24 no.
15 2008, pages 1688 1697  doi:10.1093/bioinformatics/btn245  Gene expression Knowledge-based gene expression classiﬁcation via matrix factorization R. Schachtner1, D. Lutter1,2,3, P. Knollmüller1, A. M. Tomé4, F. J. Theis1,2, G. Schmitz3, M. Stetter5, P. Gómez Vilda6 and E. W. Lang1,  1CIML/Biophysics, University of Regensburg, D-93040 Regensburg, 2CMB/IBI, GSF Munich, 3Clinical Chemistry, University Hospital Regensburg, D-93042 Regensburg, Germany, 4IEETA/DETI, Universidade de Aveiro, 3810-193 Aveiro, Portugal, 5Siemens Corporate Technology, Siemens AG, Munich, Germany and 6DATSI/FI, Universidad Politécnica de Madrid, E-18500 Madrid, Spain Received on September 24, 2007  revised on May 14, 2008  accepted on May 23, 2008 Advance Access publication June 5, 2008 Associate Editor: Olga Troyanskaya  ABSTRACT Motivation: Modern machine learning methods based on matrix decomposition techniques, like independent component analysis (ICA) or non-negative matrix factorization (NMF), provide new and efﬁcient analysis tools which are currently explored to analyze gene expression proﬁles.
These exploratory feature extraction techniques yield expression modes (ICA) or metagenes (NMF).
These extracted features are considered indicative of underlying regulatory processes.
They can as well be applied to the classiﬁcation of gene expression datasets by grouping samples into different categories for diagnostic purposes or group genes into functional categories for further investigation of related metabolic pathways and regulatory networks.
Results: In this study we focus on unsupervised matrix factorization techniques and apply ICA and sparse NMF to microarray datasets.
The latter monitor the gene expression levels of human peripheral blood cells during differentiation from monocytes to macrophages.
We show that these tools are able to identify relevant signatures in the deduced component matrices and extract informative sets of marker genes from these gene expression proﬁles.
The methods rely on the joint discriminative power of a set of marker genes rather than on single marker genes.
With these sets of marker genes, corroborated by leave-one-out or random forest cross-validation, the datasets could easily be classiﬁed into related diagnostic categories.
The latter correspond to either monocytes versus macrophages or healthy vs Niemann Pick C disease patients.
Supplementary information: Supplementary data are available at Bioinformatics online.
Contact: elmar.lang@biologie.uni-regensburg.de  1 INTRODUCTION Modern signal processing and machine learning techniques provide appropriate tools to analyze high-throughput datasets like microarrays.
Despite the fact that many problems still remain to be solved (Dougherty and Datta, 2005  Dougherty et al., 2005      To whom correspondence should be addressed.
Quackenbush, 2001), some consensus is slowly reached as to how data should be analyzed properly (Allison et al., 2006).
Raw gene expression level measurements need sophisticated preprocessing (Wu and Irizarry, 2007) encompassing background correction, summarization, normalization (Baldi and Hatﬁeld, 2002  Hochreiter et al., 2006) and missing value imputation (Troyanskaya et al., 2001), which is often done using software available from the chip producer (Affymetrix, 2002).
After preprocessing, normalized gene expression levels can be analyzed using feature extraction (Guyon and Elisseeff, 2003) and classiﬁcation (Dudoit et al., 2002) methods.
Any statistical analysis of gene expression probe level data, however, has to face the  large N, small M  problem setting, where N denotes the number of genes (= features, variables, parameters) and M denotes the number of samples (= experiments, environments, tissues).
Also overﬁtting has to be avoided to construct a classiﬁer with a good generalization ability (Spang et al., 2002).
Any robust classiﬁer needs a sample- per-feature (SpF) ratio of 5-to 10-fold, while with usual microarray probe level measurements the SpF amounts to 1/50 1/200 roughly.
Hence a substantial reduction of the feature space dimensionality via gene or feature selection is often the only way out of this SpF dilemma.
Traditionally two strategies exist to analyze such sets of gene expression signatures: Supervised approaches and Unsupervised approaches.
Supervised approaches afford prior knowledge such as class labels, clinical outcomes, prior densities, etc.
and a truly representative set of training data.
They are generally used for classiﬁcation of malignancies within a discriminant analysis.
Unsupervised approaches explore correlations in the high- dimensional data space and ﬁnd appropriate transformations to identify relevant subspaces and group observations accordingly.
However, such approaches often need additional constraints to yield unique answers but they allow for the detection of new, yet unknown classes (Saidi et al., 2004).
For a detailed account of the relevant literature see the extended  Introduction  in the accompanying Supplementary Material.
There is a recent  in applying exploratory matrix factorization (MF) techniques, like principal component analysis (PCA), independent component analysis (ICA) or non-negative  interest    2008 The Author(s) This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/2.0/uk/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.
[11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1688  1688 1697   matrix factorization (NMF), to gene expression level measurements with microarrays (Liebermeister, 2002).
In this study we propose to include diagnostic knowledge and explore the potential of matrix decomposition techniques to identify and extract marker genes from microarray data sets and classify these datasets according to the diagnostic classes they represent.
Note that the feature extraction process via exploratory matrix decomposition techniques is unsupervised, but the identiﬁcation of the most relevant features follows the supervision of diagnostic information available.
Preliminary work along these lines has been presented recently at a conference (Schachtner et al., 2007a).
Corresponding supervised feature extraction and classiﬁcation techniques like support vector machines (SVM) have been applied to the same dataset and are discussed in short as well.
For a more detailed discussion of these supervised techniques, though applied to different datasets, see (Schachtner et al., 2007b).
2 THE MONOCYTE MACROPHAGE DATASET For our analysis we combined the gene-chip results from three different experimental settings to the monocyte macrophage (MoMa) dataset (Lutter et al., 2008).
In each experiment human peripheral blood monocytes were isolated from healthy donors (Experiment 1 and 2) and from donors with Niemann Pick type C disease (Experiment 3).
Monocytes were differentiated to macrophages for 4 days in the presence of M-CSF (50 ng/ml, R&D Systems).
Differentiation was conﬁrmed by phase contrast microscopy.
Gene-expression proﬁles were determined using Affymetrix HG-U133A (Experiment 1 and 2) and HG-U133plus2.0 (Experiment 3) Gene Chips covering 22 215 probe sets and about 18 400 transcripts (HG-U133A).
Probe sets only covered by HG-U133plus2.0 array were excluded from further analysis.
In Experiment 1 pooled RNA was used for hybridization, while in Experiment 2 and 3 RNA from single donors were used.
The ﬁnal dataset consisted of seven monocyte and seven macrophage expression proﬁles and contained 22 215 probe sets.
After ﬁltering out probe sets which had at least one absent call, 5969 probe sets remained for further analysis.
Exp.
1 7 refer to monocytes and Exp.
8 14 to macrophages.
Exp.
1 4 and 8 11 stem from healthy subjects, the rest from diseased subjects.
3 METHODS The data are traditionally represented as a N M-dimensional data matrix X whose M columns represent gene expression signatures (GES) of N genes during M experiments or environmental conditions while the N rows represent gene expression proﬁles (GEP) of each of the N genes across all M experimental conditions.
Column vectors are denoted as, for example, x m, while row vectors are denoted as xn  in the following.
The index m is always signifying an environmental condition in the following whereas the index n always refers to a certain gene.
3.1 Gene selection schemes A general problem with microarray datasets is the problem of overﬁtting which arises whenever the number N of parameters (genes) is large compared to the number M of samples (experimental conditions).
One way around this problem is to preselect a reduced number of genes which are ranked according to some scoring scheme.
The data matrix X contains in its columns the GESs observed during M experimental conditions.
Out of these, K genes and their corresponding class label were preselected from the training dataset, using different selection methods and scoring schemes, to result  Matrix Factorization  in a (K+1) M-dimensional data matrix whose column vectors served as input to the Lagrangian SVM (LSVM) classiﬁer which thus operated in a (K+1)-dimensional subspace of the N-dimensional gene space.
3.1.1 Random gene picking First and simplest, random gene picking was used to preselect K-tuples of genes whose gene expression proﬁles were used to train the LSVM classiﬁer.
If the resulting decision hyperplane correctly classiﬁed the training set, a leave-one-out (LOO) cross-validation was applied to estimate the classiﬁcation error.
With the current dataset single marker genes could always be identiﬁed which could classify the dataset according to the classiﬁcation task considered, be it monocyte versus macrophage or healthy versus NPC disease.
Thus the algorithm was used with k=1 only.
3.1.2 Score-based gene selection Thereby the following scoring criteria are considered:  1.
FCh: A simple and often used score is the Fold Change (FCh).
2. w-score: In Golub et al.
(1999), an empirical w-score was proposed.
This score has been criticized, however, to yield incorrect units in the related discriminant function (Dudoit et al., 2002).
3.
T-score: In Liu et al.
(2005) a score based on a likelihood ratio of in  class and between class variances was suggested.
4. c-score: Galton (1888, 1889) proposed a statistical correlation score nowadays known as Pearson correlation (Pearson, 1901), which can be used to measure the similarity between the n-th GEP xn  of the data matrix and a design vector d reﬂecting the diagnostic knowledge available from the experimental design.
5.
SAM: The signiﬁcance analysis of microarrays (SAM) represents a  variance stabilized version of a t-test (Tusher et al., 2001).
The gene selection can now proceed by choosing either a ﬁxed number of genes with the highest scores or by deﬁning a threshold and selecting all genes with scores above this threshold.
Here a set of 50 genes is selected always.
3.1.3 SVM-based gene selection A gene selection method different from the selection schemes discussed above can be derived from the SVM directly (Barnhill et al., 2002).
A SVM estimates an optimal hyperplane, which is characterized by a vector w normal to the hyperplane, separating the dataset into appropriate subspaces.
Gene expression signatures x m, representing the expression levels of all genes in gene space, can be projected onto these normal vectors via dot products.
Hence the components of w indicate the importance of a gene for the classiﬁcation task.
Genes which have small components only in w can be removed as their associated unit vectors almost lie parallel to the hyperplane, hence they are orthogonal to the direction of optimal class discrimination, represented by w, and will not contribute to the classiﬁcation.
Note that all these scores are based on the discriminative power of single gene statistics.
Thus they ignore the joint discriminative power of a group of genes where each single gene might exhibit a low individual score.
This is clearly a deﬁcit of these gene selection schemes.
3.2 Feature generation and selection schemes MF techniques like ICA or NMF seem promising in generating features suitable for diagnostic classiﬁcation purposes.
A key feature of ICA as well as NMF is the ability to identify patterns that together explain the observed GESs as a linear combination of expression modes (ICA) or metagenes (NMF), respectively.
Hence they overcome the limitations inherent to single gene statistics as discussed earlier.
In the following we will discuss these feature generation techniques in their application to microarray datasets.
For feature selection we consider a modiﬁed Pearson score where we replace the observed GEPs xn  of the data matrix by corresponding component proﬁles obtained from the feature generation step by applying matrix decomposition techniques to the data matrix.
Note that while the feature  1689  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1689  1688 1697   R.Schachtner et al.
generation techniques are completely unsupervised, the subsequent feature selection and classiﬁcation affords the inclusion of diagnostic knowledge through a corresponding design vector di for class i and renders the methods semi-supervised instead.
3.2.1 Data representation and preprocessing The gene expression levels are represented by an (N M) data matrix X=[x 1   x M] with each column x m representing the expression levels of all genes in one of the M experiments or environmental conditions.
With NMF, a decomposition is then sought according to X=WH which is not unique, of course, and needs further speciﬁcation.
The columns of W are called metagenes.
They represent the GESs combined together according to the weights contained in the rows of H which are called meta-experiments.
Note that the data matrix is non-square with N  103M which renders a transposition of the data matrix necessary when techniques like ICA are applied.
Hence ICA follows the data model: XT =AS where the columns of matrix A represent the basis vectors of a new representation which is obtained by grouping together the observed GEPs according to the weights contained in the rows of S which are called expression modes.
Note that the latter are constrained to be as statistically independent as possible.
Accordingly, the columns of matrix A may be named feature proﬁles.
Further, each row am  contains the weights to combine the independent expression modes to the observed GESs.
The raw expression data have been normalized per chip.
As normalization and summarization tool MAS 5.0 has been applied by the medical doctors who owned and produced the datasets.
The raw datasets have never been available to us for alternative preprocessing.
Hence, more advanced preprocessing tools like RMA (Bolstad et al., 2003  Irrizarry et al., 2003), GCRMA (Wu et al., 2004), FARMS (Hochreiter et al., 2006  Talloen et al., 2007) or DFW (Chen et al., 2007) could not be applied and, in part, have not been available yet at the time the data were produced and processed.
3.2.2 ICA Analysis The M N data matrix XT was used as input to the JADE algorithm (Cardoso and Souloumiac, 1993, 1996) which is a nearly exact algebraic algorithm focusing on the 4th order cumulant of the distribution of expression levels within the expression modes.
It was preferred over stochastic algorithms like the fastICA which yield slightly different results in every run and need several repetitions to identify the robustly estimated expression modes.
Note that JADE encompasses centering and whitening procedures as preprocessing steps.
The number of extracted expression modes K   M need not correspond to the maximum possible and can be chosen deliberately.
The output is a K M demixing matrix B, which allows the computation of the corresponding expression modes.
It is deﬁned through the relation BXT =YT =BAS=DPS with D, a diagonal scaling matrix and P, a permutation matrix.
Typical results show expression modes which exhibit both positive and negative expression levels, though the raw expression proﬁles only have positive expression levels, of course.
Note that either the expression modes or their related basis vectors can be normalized to unity because of the inherent scaling indeterminacy of ICA.
An ICA-based gene grouping scheme to analyze gene expression proﬁles was proposed by (Lee and Batzoglou, 2003).
A thorough discussion of this rather classical ICA approach, applied to the current dataset, can be found in Lutter et al.
(2008), where also a discussion of the biological and medical implications of the ﬁndings is discussed in greater detail.
Hence we abstain here from any such discussion and put the emphasis on the new methodological aspect.
In contrast to this classical analysis, here a different approach is taken which utilizes basic properties of the matrix decomposition model and incorporates diagnostic knowledge to evaluate the structure of the feature proﬁles, i.e.
the basis vectors of the new representation, and deduce a corresponding expression mode to identify a set of marker genes with sufﬁcient discriminative power concerning the classiﬁcation task at hand.
ICA essentially seeks a new representation of the observed dataset with the columns of matrix A representing the new basis vectors.
Whereas the original dataset X is interpreted as M data vectors (experiments) in N dimensions (genes), with ICA the transposed data XT matrix is considered.
Hence, the data are interpreted as N data vectors, each representing the expression proﬁle  1690  of one of the N genes in an M(cid:4) N-dimensional feature space.
The latter is spanned by the M-dimensional column vectors of matrix A which represent the new coordinate system.
Hence, individual gene expression proﬁles are mapped onto feature proﬁles and the component proﬁles, i.e.
the columns of S, associated with the expression proﬁles by the rules of matrix multiplication contain the weights with which every feature proﬁle contributes to each observed expression proﬁle.
If the matrix decomposition is adequate, a concise analysis of the structure of these feature proﬁles comprising the columns of matrix A might hopefully provide insights into the structure of the dataset itself.
After the ICA decomposition XT =A S, the matrix S contains K   M supposedly statistically independent expression modes sm  R1 N ,1  m  (K   M) forming the rows of S. Now note that to every gene expression signature a corresponding row of matrix A is related which contains the weights with which each of the K   M independent expression modes contributes to the gene expression signature under consideration.
Hence each column of A can be associated with one speciﬁc expression mode sm  to which it is related by the rules of matrix multiplication.
This observation forms the basis of the proposed feature selection scheme.
In a ﬁrst step an informative feature proﬁle reﬂecting the available diagnostic information of the set of experiments is identiﬁed and in a second step the genes of the associated independent expression mode are analyzed with respect to their diagnostic classiﬁcation potential.
Each investigated microarray dataset represents at least two different classes of cells, such as cell lines taken either from healthy subjects (Class 1) or patients suffering from any disease (Class  1).
If the gene expression signatures x1 ,...,xM  of the different experiments are arranged according to their diagnostic class label, i.e.
the j experiments of Class 1 constitute the ﬁrst j rows of the data matrix XT , whereas the members of Class  1, i.e.
xm  M m=j+1, are collected in the remaining rows, this assignment is also valid for the rows of matrix A.
Suppose one of the independent expression modes sm  is reﬂecting a putative cellular gene regulation process which is related to the diagnostic difference between the classes.
Then to every gene expression signature of Class 1, this characteristic expression mode should contribute substantially signalled by a large weight in the corresponding feature proﬁle whereas its contribution to Class  1 experiments should be less (or vice versa).
Since the k-th column of A contains the weights with which the k-th expression mode sk  contributes to all observed gene expression signatures, this column should show large/small feature components according to the class labels.
Hence, in contrast to the method in Lee and Batzoglou (2003), the clinical diagnosis of the experiments is taken into account.
The strategy concentrates on the identiﬁcation of a column of A, which shows a class speciﬁc signature according to a design vector d containing the class labels of each experiment.
The expression mode related to that speciﬁc column is assumed to provide a good candidate for further class speciﬁc analysis concerning the identiﬁcation of marker genes.
Informative columns were identiﬁed using the correlation coefﬁcient  corr(a n,d)  of each column vector of A with a design vector d whose m-th entry is dm= 1, according to the class label of experiment m.  3.2.3 Local NMF analysis NMF replaces the assumption of statistically independent expression modes by a positivity constraint concerning the entries of the matrices into which the given data matrix of observed expression levels is to be decomposed.
As the experimentally observed data correspond to ﬂuorescence intensity levels, such positivity constraints seem more natural than independent expression modes which contain numerous negative entries.
Such negative entries appear as well in the matrix of corresponding mixing coefﬁcients meaning that different expression modes may partially compensate their respective contributions to the observed expression levels.
Hence the constrained NMF model has the potential to identify sets of functionally related genes more accurately.
Applying NMF, the data matrix corresponds to the usual N M matrix X=[x 1   x M].
Each column of X, called a gene expression signature, comprises the gene expression levels of all genes resulting from one experiment.
After applying  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1690  1688 1697   the LNMF algorithm (Li et al., 2001), the data matrix is decomposed into two new matrices W and H. The columns of W=[w 1   w k] are called metagenes.
One of them is expected to be characteristic of a regulatory process, which is responsible for the class speciﬁc difference in the observed experiments.
Its contribution to the observed gene expression signatures is contained in the rows of matrix H which are called meta-experiments.
Once an informative meta-experiment is identiﬁed through its correlation to the design vector encompassing the diagnostic information available, further analysis can be focused only on the genes contained in the corresponding metagene.
The search strategy is similar to the one used in case of the ICA analysis discussed earlier.
As before all experiments were classiﬁed according to available diagnostic information and labeled accordingly.
The correlation coefﬁcients between every meta-experiment hm  and d are then computed.
Empirically, a correlation coefﬁcient  corr(hm ,d)   0.9 signiﬁes a sufﬁcient similarity between hm  and d. Besides the maximum number of iterations which controls the precision of the decomposition, the number of extracted basis components K, i.e.
the metagenes, is the only adjustable parameter affecting the structure of W and H. For several decompositions X= WH using different numbers K of metagenes [w 1   w K], the matrices H are studied with respect to the appearance of correlation coefﬁcients  corr(hm ,d ) close to 1.
A metagene is considered informative only if all entries of the corresponding meta-experiment which belong to Class 1 are smaller than all other entries of that meta-experiment (or vice versa).
After a total number of 5000 iterations, the cost function of the LNMF algorithm did not show noticeable changes with any of the datasets investigated.
For K =2,...,49, ten separate simulations were carried out each time and only the simulation showing the smallest reconstruction error was retained.
Further matrix decompositions with K =50,60,...,400 metagenes were examined.
In the latter case, only three simulations were performed for each K. Note that NMF traditionally chooses K (cid:4) M to go for a more compact representation of the data matrix.
However, deliberately choosing K (cid:6) M opens the way to a sparse and hopefully more informative and straightforwardly interpretable representation of the dataset with co-regulated genes combined into one metagene.
to the hyperplane,  (cid:1)(cid:7)x,wopt(cid:8)+b  where wopt =(cid:3)  3.3 Classiﬁer 3.3.1 SVM classiﬁer SVM (Schölkopf and Smola, 2002) are appropriate tools whenever data classiﬁcation is the goal.
They are based on geometric considerations in a vector space.
Given an optimal separating hyperplane, characterized through its vector wopt normal the (cid:2) corresponding decision rule reads f (x)= sgn  (1) m SV ymαmxSV m and ym represents the class label, αm represents a hyperparameter and xSV m indicates the support vectors closest to the separating hyperplane.
The solution to this quadratic optimization problem is implemented in the LSVM algorithm (Mangasarian and Musicant, 2001), a MATLAB version of which is available at www.cs.wisc.edu/ musicant/lsvm/ and has been used in this study.
For cross-validation to evaluate the performance of the LSVM classiﬁer, a LOO procedure was applied.
Note that in every case the test sample has been taken out before the classiﬁer was trained to avoid any bias in the decision making (Simon, 2003).
3.3.2 MF classiﬁer MF of the data matrix has been considered a feature generation technique sofar.
The resulting M-dim feature proﬁles (ICA: columns of A) or the M-dim meta-experiments (NMF: rows of H) have then been used for feature selection purposes by correlating them with a design vector d the components of which represent class labels encoding the diagnostic information available about the respective experiments or environmental conditions.
But the known class labels of the GESs (ICA: m  or NMF: x m) also translate to corresponding labels for the rows ak  xT in case of ICA or the columns h k in case of NMF.
Similarities between  Matrix Factorization  these row or column vectors, respectively, can thus be used to classify the observations directly without having to identify appropriate sets of marker genes.
The method will be explained in the following referring to the NMF notation but can be translated to the ICA notation immediately by recognizing the correspondence of metagene expression mode and feature proﬁle meta-experiment, i.e.
W(cid:1)ST and H(cid:1)AT , respectively.
Note that from X=WH it follows that W# x m=h m where W# denotes the pseudo-inverse of W. Now the similarities between the columns of H can be used to classify the observations.
Though any method based on similarity measures can be used, we simply estimate the correlation coefﬁcient, i.e.
cm  corr(htest ,h m).
Now for each class a separate index set Ii of indices is created, where I1 encompasses all indices m for which x m  Class 1 while I 1 contains all remaining indices.
This thus results in two sets of correlation coefﬁcients corresponding to the two assignments m  I1 or m  I 1.
Two rules for class assignment were tested:  (cid:4)  (cid:127) Average correlation:  if(cid:7)cm(1)(cid:8)  (cid:7)cm( 1)(cid:8) otherwise  label(htest m )=  1  1  (2) where (cid:7)....(cid:8) denotes an average of the correlation coefﬁcients over the respective index set.
(cid:127) Maximal correlation:  if max cm(1)   max cm( 1)  otherwise  (3) where max cm( 1)  denotes the maximal value of all correlation coefﬁcients within either the set I1 or I 1.  label(htest m )=  1  1  (cid:4)  Rule 1 thus assigns the class label according to an average correlation of the test vector with all vectors belonging to one or the other index set.
Rule 2 assigns the class label according to the maximal correlation occurring between the test vector and the members of each index set.
3.3.3 Random forest classiﬁer Last but not least a random forest (RF) classiﬁer (Breiman, 2001  Diaz-Uriarte, 2007  Diaz-Uriarte and de Andrés, 2006) was applied to a set of 50 genes which were selected by either a) the highest scores, b) the highest expression values in the most informative expression mode in case of ICA feature selection or c) the highest expression levels in the most informative metagene in case of NMF feature selection.
RF is a classiﬁcation algorithm which uses an ensemble of classiﬁcation trees.
Each tree is built using a bootstrap sample of the data, and at each node of the decision tree the candidate set of variables is a random subset of the variables.
Hence RF uses both bagging and random variable selection which results in largely uncorrelated decision trees.
RF shows improved accuracy in comparison to other supervised learning methods.
Apart from this it provides a stability measure of the list of genes selected according to some well- deﬁned measure of variable importance.
This is a deﬁnite advantage over other cross-validation schemes, hence it was applied to all features (= gene lists) generated with other techniques in this contribution.
4 RESULTS AND DISCUSSION The following results discuss the application of the various gene or feature selection schemes and classiﬁers to the microarray datasets.
The goal was to identify an as small as possible set of marker genes which allow for a diagnostic classiﬁcation of the given microarray experiments devoted to the investigation of the related disease.
These marker genes would allow the design of special purpose chips which could provide a less costly alternative to genome-wide microarray diagnostics.
The cases to be distinguished by the classiﬁer in the MoMa  datasets are the following:  (cid:127) Case 1: monocyte versus macrophage (MoMa) (cid:127) Case 2: healthy versus Niemann Pick C disease (HeDi)  1691  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1691  1688 1697   R.Schachtner et al.
Table 1.
The classiﬁcation task was to classify monocytes versus macrophages (Case 1:MoMa)  No.
SGP/SVM-LOO  ICA-GEL-neg  ICA-RF-neg  ICA-GEL-pos  ICA-RF-pos  NMF-GEL  NMF-RF  PABPC4 SNURF/SNRP PEBP1 ITGAL ZNF331 CRYL1  1 2 3 4 5 6 7 8 9 10  NFKBIA S100A9 IL8 FCN1 S100A8 CSPG2 TNFAIP3 DUSP1 PRG1 FPR1  H3F3A PPP1R15A HSPA5 H3F3A RGS2 CYP1B1 CD83 CYBB HNRPH1 CYP1B1  GPNMB MMP9 CTSB FUCA1 LIPA CD63 LAMP1 TFRC CSTB K-ALPHA-1  CD59 CTSB ADFP LIPA CTSL K-ALPHA-1 GM2A HEXB PPIA SAT  GPNMB HLA-DRB1 CD74 SAT PSAP HLA-DRB1 HLA-DRB1 GRN GM2A GRN  CPVL CST3 ADFP LIPA MS4A6A HLA-DPA1 C12orf8 GM2A CECR1 BASP1  SGP/SVM-LOO: genes of the dataset which lead to an error rate  (LOO) 2 when genes were selected by either single gene picking or a SVM and LOO cross-validation was invoked.
The genes are ranked according to their corresponding c-scores.
ICA-GEL-neg/pos: the 10 most strongly expressed genes of expression submodes sneg/pos , respectively, when a total of k=8 expression modes were extracted by ICA.
NMF-GEL: the 10 most highly expressed genes in the most informative metagene w 28 selected by LNMF.
NMF-RF: the most informative genes of metagene w 28 according to the RF classiﬁcation of the 50 most highly expressed genes of the most informative metagene w 28 selected by NMF.
6   4.1 Gene selection and classiﬁcation 4.1.1 Random gene picking and classiﬁcation The simplest possibility tested was the identiﬁcation of randomly picked single genes which were able to classify the datasets into the given classes according to both classiﬁcation cases using the LSVM classiﬁer and LOO cross-validation.
Hence 14 LOO test have been performed.
Results obtained with the MoMa dataset concerning the Case 1 classiﬁcation are listed in Table 1, ﬁrst column (SGP/SVM-LOO).
Only genes with a classiﬁcation error rate  (LOO)  2 are listed.
Concerning Case 2 classiﬁcation, a total of 531 genes resulted from gene picking or SVM selection which showed a classiﬁcation error rate  (LOO)=0 when LOO cross-validation was applied.
These genes were ranked according to their c-score and the 10 genes with the highest c-scores (see later) are listed in Table 2, ﬁrst column (SGP/SVM-LOO).
Please, note that different genes might have the same Affy-id, hence the same gene name (Loci-id) might appear multiply in the following lists.
Entries in bold face in these tables represent genes which were also selected as marker genes with other methods, hence appear in several columns of the table with the same type of classiﬁcation (Case 1 or Case 2).
Entries in italics in these tables represent marker genes which also appear in lists related with the other type of classiﬁcation (Case 1 and Case 2), hence appear in both tables.
4.1.2 SVM-based gene selection and classiﬁcation The recursive gene elimination procedure discussed earlier has been tested with the MoMa dataset.
As the LSVM algorithm is not able to handle datasets with many thousand genes, each dataset has been partitioned into subsets of roughly 1000 genes each.
For each subset an optimal separating hyperplane has been estimated using LSVM.
Two strategies were followed to ﬁlter out a set of diagnostic marker genes:  1.
Remove the gene with the smallest squared contribution to w and run LSVM on the reduced dataset.
When no solution can be obtained with the reduced set, then stop.
Merge the 100 most important genes of each set and repeat the procedure.
2.
Remove the 100 least important genes with the smallest components in w as long as more than 200 genes are in the set.
For smaller sets remove genes step by step.
1692  In each case the algorithm stopped at one of the genes listed in Tables 1 or 2 corroborating the ﬁndings already achieved with single gene picking and LOO cross-validation.
The comparison of the scores of these genes with respect to the different scoring schemes show that the genes selected with either the single gene picking or the SVM-based selection scheme rank quite differently in the different scoring schemes.
Choosing the 50 genes with the highest score of every scoring list, most of the genes in Table 1 would not have been selected at all by simple score ranking.
The best correspondence is achieved with a ranking according to the c- score/SAM-score.
Note that the SAM-score ranking is identical to the c-score ranking.
Hence, we only will consider this latter scoring scheme further on.
4.1.3 Score-based gene selection and RF classiﬁcation The score-based gene selection methods discussed earlier yield quite different collections of genes.
The various scores of all genes of the dataset were calculated and the genes were sorted in descending order according to these scores.
The 50 most highly ranked genes according to the different scores were then selected for further evaluation using a RF classiﬁer.
In the following we concentrate only on the more interesting Case 2 (HeDi) classiﬁcation.
Furthermore we only present results in case of the c-score which turned out to be the most reliable and, furthermore, yielded an identical ranking as the SAM - score.
Table 2 summarizes the 19 genes with the highest importance according to the mean decrease accuracy and mean decrease Gini index (Breiman, 2001) estimated by the RF classiﬁer (Fig.
1).
4.2 Feature generation, selection and classiﬁcation In the following we apply the matrix decomposition techniques discussed earlier feature generation and selection which incorporates diagnostic knowledge available about the experiments.
Sets of marker genes will result, which were subjected to a RF classiﬁer to identify the most relevant genes for the classiﬁcation task at hand.
for  4.2.1 Analysis of feature proﬁles and expression modes generated by ICA Using a decomposition into K = M=14 independent  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1692  1688 1697   Table 2.
The classiﬁcation task was to classify healthy versus Nieman Pick C disease (Case 2: HeDi)  No.
SGP/SVM-LOO  C-Sc-RF  ICA-GEL-neg  ICA-GEL-pos  ICA-RF-neg  ICA-RF-pos  NMF-GEL  NMF-RF  Matrix Factorization  3GM2A STAB1 GM2A HLA-A SOD2 NFKBIA IL8 HLA-B SAT PSAP  RY1 RAD23B UBE2L3 MIF NUDT21 PCMT1 SAP18 SNX3 CASP1 RAB31  RPS6KA4 C14orf131 SAP18 COX7c CHMP5 SUMO1 PNN OAZ1 TDE2 RAB1A  SAP18 PNN RAB1A SUMO1 RAB31 NEDD8 RPS25 ATP6Y1C1 CHMP5 TSPYL1  OAZ1 C6orf62 ARPC2 RPL7 S100A4 ITM2B ARHGDIB TMSB4X ALOX5AP HLA-DRA  SOD2 ACTB NOTCH2NL GRN DUSP1 HLA-C GRN AHNAK HLA-F CTSD  RPL11 RPL7 ACTR2 RAB1A ALOX5AP HSPA8 SERPINA1 S100A4 H3F3A ARPC2 C6orf62 HNRPA1 S100A10 RAB31  PEBP1 CD163 DIP unknown GRN MMD STX7 MPST GRN PRKACB GUSB GALC NPC2 SPTBN1 RRAGD C5orf13 SNRP/SNURF GRB10 CTSD  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 SGP/SVM-LOO: the ﬁrst 10 marker genes out of a list of 531 genes of the dataset which lead to an error rate  (LOO)=0 when genes were selected by either single gene picking or a SVM and LOO cross-validation was invoked.
The genes are ranked according to their corresponding c-scores.
The ﬁrst two genes had a positive c-score, all others a negative c-score.
C-Sc-RF: list of genes of the dataset which, after ranking by their c-score, were selected as most informative by a RF classiﬁer.
Only the 50 highest ranked genes were input to the RF-classiﬁer.
ICA-GEL: 10 most strongly expressed genes of expression mode s3  related with case 2 when a total of k=8 expression modes were extracted by ICA.
3  ) of expression mode s3  related with case 2 when a total of k=8 expression modes ICA-RF: the most informative genes, according to a RF classiﬁer, of the submodes (sneg were extracted by ICA.
Only the 50 most highly expressed genes were input to the RF-classiﬁer.
NMF-GEL: the 10 most highly expressed genes in the most informative metagene w 13 selected by LNMF.
NMF-RF: the most informative genes of metagene w 13 according to the RF classiﬁcation of the 50 most highly expressed genes of the most informative metagene w 13 selected by NMF.
3  ,spos  0.015  0.010  0.005  0.000  0.25  0.20  0.15  0.10  0.05  0.00  Mean Decrease Accuracy - Cscores  7 X T S  3 6 1 D C  D M M  I  P D  P B P  N R G  B C A K R P  T S P M  1 N B T P S  N R G  C L A G  B S U G  2 6 1 P 4 3 4 p Z F K D  F R U N S  / / /  N P R N S  2 C P N  D G A R R  0 1 B R G  D S T C  3 1 f r o 5 C  P A T R C  P B P  T A R C  B L B C  B M N P G  1 B R D A L H  -  8 f r o 2 1 C  3 6 1 D C  1 G P C C  6 4 7 0 A A K  I  3 R E M O H  4 F C T  B 4 F E  I  2 P B G U C  4 2 0 3 1 C G M  K 2 P M B  D G A R R  1 R A L  I  B S T C  I  1 X M  P B P  2 G N C C  1 3 3 F N Z  A 1 L P B S O  2 Z E F  3 T S C  G L M A C  A X E H  2 D Y M S  1 N M T S  H C E F  Mean Decrease Gini - Cscores  7 X T S  B S U G  C L A G  D S T C  T S P M  F R U N S  / / /  N P R N S  3 1  f r o 5 C  B C A K R P  0 1 B R G  1 N B T P S  N R G  2 C P N  D M M  N R G  I  P D  2 6 1 P 4 3 4 p Z F K D  P B P  3 6 1 D C  D G A R R  P A T R C  P B P  T A R C  B M N P G  B L B C  3 6 1 D C  8  f r o 2 1 C  1 G P C C  B S T C  I  1 X M  A X E H  2 Z E F  G L M A C  1 B R D A L H  -  2 D Y M S  3 R E M O H  6 4 7 0 A A K  I  4 2 0 3 1 C G M  B 4 F E  I  2 P B G U C  4 F C T  H C E F  3 T S C  1 N M T S  K 2 P M B  1 3 3 F N Z  A 1 L P B S O  P B P  1 R A L  I  2 G N C C  D G A R R  Fig.
1.
Mean decrease accuracy and Gini index determined with a RF classiﬁer of the 50 genes of the dataset with the highest c-score.
Note that both indices label the same 19 genes as most informative though their ordering is slightly different.
expression modes, column a 7 of the resulting mixing matrix A showed a moderately strong correlation  corr(a 7,d 1) =0.7 with the design vector d 1=(d1,1= 1,...,d7,1= 1,d8,1= 1,...,d14,1=1) from those taken from macrophages.
Column a 1  corr(a 1,d 2) =0.95 with design a vector d 2=(d1,2=1,...,d4,2=1,d5,2= 1,...,d7,2= 1,d8,2= 1,...d11,2=1,d12,2,...,d14,2).
The signature of Column 7 is not  to discriminate GESs taken from monocytes showed  correlation coefﬁcient  very clear cut.
Hence a systematic investigation of the structure of the mixing matrices was carried out while increasing the extracted number of expression modes from K =2,...,14.
The necessary dimension reduction step can be done during the whitening step of the JADE algorithm.
The information loss is not critical in any case as the ﬁrst three principal components cover 96.1% of the variance.
Note that such an ordering principle does not hold in case of ICA.
It is thus unclear whether such a dimension reduction removes informative components which posses large higher order correlations but accidentally only small second order correlations.
It is because of this uncertainty that we performed a systematic investigation of the decomposition up to the full rank of the data matrix.
The resulting maximal correlation coefﬁcients   corr(a k ,d i)  showed little variation in both cases with average values (cid:7) corr(a k ,d 1) (cid:8)K =0.79 and (cid:7) corr(a k ,d 2) (cid:8)K =0.94.
Shallow maxima occur at k=3 in Case 1 and at k=8 in Case 2.
Figures 2 and 3 present the feature proﬁles a 6 and a 3 maximally correlated with design vectors d1 and d2 and the related expression modes s6  and s3 .
A list of the 10 most strongly expressed genes in each of the extracted expression modes is given in Tables 1 and 2.
[11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1693  1688 1697  1693   R.Schachtner et al.
Table 3.
List of marker genes of the MoMa dataset, Case 1, according to Table 1, ﬁrst column and their corresponding rank according to the various scores listed above  Gene symb.
c  w  +  T     T  SAM  FCh  MoMa dataset: Case 1 classiﬁcation PABPC4 SNURF PEBP1 PEBP1 ITGAL ZNF331 CRYL1   50 49  50  50  50 22  50   50 01 09 02  50 45  50   50  50 23  50  50  50  50   50  50  50  50  50  50  50   50 01 09 02  50 45  50   50  50 09 24  50  50  50  600  400  200  0   200  20  10  0   10   20  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  1000  2000  3000  4000  5000  6000  Fig.
2.
ICA(JADE): feature proﬁle a 6 for k=8 and the related expression mode s6 .
Feature proﬁle a 6 shows a strong correlation with the design vector d1 in Case 1 (monocyte versus macrophage).
0  200  400  600  800  1000  1200  5  0   5   10  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  1000  2000  3000  4000  5000  6000  Mean Decrease Accuracy - Heldi - negative  1 1 L P R  7 L P R  A 1 B A R  2 R T C A  8 A P S H  4 A 0 0 1 S  P A 5 X O L A  2 C P R A  I  1 A N P R E S  6 2 9 0 4 4 C O L  / / /  A 3 F 3 H  1 A P R N H  1 3 B A R  2 6  f r o 6 C  0 1 A 0 0 1 S  I  B P P  I  B D G H R A  5 2 S P R  C 7 X O C  E A H W Y  A H D L  5 S P R  1 Y 4 S P R  6 L P R  2 M L A C  6 1 0 C P S H  6 E S A N R  3 L S M T  / / /  X 4 B S M  4 5 3 0 9 3 C O L  / / /  A 8 1 L P R  T E S  1 Z A O  A 7 C E L C  B 2 M T  I  1 K G P  1 H P R N H  A R D A L H  -  5 1 L P R  9 P R S  1 M L A C  1 O N E  1 A X N A  1 A P D A L H  -  5 L P R  1 G R P  2 P L P  4 N T R  A 1 P K S  3 A B U T  0 2 S P R  8 A P S H  e k  i l - 0 P L P R  / / /  0 P L P R  Mean Decrease Accuracy - Heldi - positive  0.020  0.015  0.010  0.005  0.000  0.025  0.020  0.015  0.010  0.005  0.000  2 D O S  L N 2 H C T O N  B T C A  N R G  N R G  K A N H A  -  C A L H  1 P S U D  F - A L H  D S T C  I  A B K F N  B M N P G  9 1 7 0 2 J L F  F A T L  I  -  C A L H  P A S P  2 P C U  -  B A L H  1 A G G  -  A A L H  -  G A L H  0 1 S P R  1 A C U F  4 R C X C  8 2 S P R  H 4 A T L  1 M T S Q S  B P B E C  1 P A 6 P T A  S R A W  -  A A L H  P F D A  0 3 F  I  I  1 B 2 N A M  I  3 P A F N T  9  f r o 2 2 C  T A S  1 T A G M  P A S P  P O C E  1 A G G  -  C A L H  A 2 M G  A 2 M G  1 B A T S  9 1 7 0 2 J L F  8 L  I  F G D H  -  G A L H  1 C E D M A D A  Fig.
4.
Mean decrease accuracy according to a RF classiﬁcation of the 50 most highly expressed genes in expression submode sneg 3  selected by ICA with k=8 extracted expression modes in total.
Only the 14 and 10 genes, respectively, with the highest mean decrease accuracy are considered informative.
3  and spos  a RF classiﬁer.
In Table 1, the columns labeled ICA-GEL-neg/pos, ICA-RF-neg/pos contain either the 10 genes with the highest expression level (GEL) in the most informative expression mode or the most informative genes selected by a RF classiﬁer.
The columns labeled NMF-GEL/RF contain the corresponding genes from the most informative metagene selected with LNMF feature selection.
The most highly expressed 50 genes of the expression submodes or of the corresponding metagene have been subjected to a RF classiﬁcation.
The importance of the variable decreases exponentially in all three examples, hence only the ﬁrst 10 genes are listed as their importance was then already down to one- third of the maximal value.
The corresponding results obtained in the more interesting classiﬁcation Case 2 are listed in Table 2.
According to the mean decrease accuracy estimated, 14 and 10 genes stand out as most informative as illustrated in Figure 4.
They are listed in columns labeled ICA-RF-neg/pos and NMF-RF in Table 2, respectively.
Fig.
3.
ICA(JADE): feature proﬁle a 3 for k=8 and the related expression mode s3 .
The feature proﬁle a 3 shows a strong correlation with the design vector d2 in Case 2 (healthy versus diseased).
These marker genes are involved in a gene regulation network and all genes in this network can be associated with the MeSH term gene expression regulation, except FUCA1 and STAB1.
For a thorough discussion of the related pathways identiﬁed by applying BiblioSphere MeSH- and GeneOntology ﬁlter tools see (Lutter et al., 2008).
informative expression modes s6  Having selected the most (Case 1) and s3  (Case 2), their 50 most strongly expressed genes have been selected from every submode and supplied to  4.2.2 Analysis of meta-experiments and metagenes generated by LNMF A LNMF analysis was also performed on the 14 experiments of the dataset.
Again the number k of extracted metagenes was varied systematically to identify an optimal decomposition of the N M data matrix X.
For every k, the correlation coefﬁcients between the meta-experiments and the design vectors di ,i=1,2 were computed.
Again a RF classiﬁer was used to select the most informative genes from the most informative metagene.
Monocyte versus macrophage: For k   100, several meta- experiments show small expression levels for all monocyte experiments compared with larger expression levels for the macrophage experiments, indicated by a large correlation coefﬁcient  1694  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1694  1688 1697   Matrix Factorization  Mean Decrease Accuracy - MoMa  L V P C  3 T S C  P F D A  A P L  I  1 A P D A L H  -  A 6 A 4 S M  8  f r o 2 1 C  A 2 M G  1 R C E C  1 P S A B  B M D A L H  -  2 R C S T L G  B S T C  B M N P G  S N G  3 6 1 D C  A 1 F H  I  2 P C U  1 P P M  P A S P  1 D S F M  1 M A C E P  1 A C U F  B G P P  N R G  N R G  N R G  H 4 A T L  T R G C F  K S T C  3 D L P  4 A X N A  D S T C  A 2 M G  2 C P N  4 7 D C  1 H A S A  4 R C X C  1 B P D A L H  -  3 1 F S F N T - 2 1 F S F  T A S  P A S P  3 6 1 D C  1 B R D A L H  -  A M D A L H  -  1 R A 3 C  1 B R D A L H  -  1 B R D A L H  -  1 C E D M A D A  3 1 F S F N T - 2 1 F S F  Mean Decrease Accuracy - Heldi  0.05  0.04  0.03  0.02  0.01  0.00  0.025  0.020  0.015  0.010  0.005  0.000  1 Y R  B 3 2 D A R  3 L 2 E B U  I  F M  1 T M C P  1 2 T D U N  8 1 P A S  1 P S A C  3 X N S  1 3 B A R  I  B P P  C H D S  5 2 S P R  4 M E M T  C 7 X O C  8 S L A G L  1 R C S L P  A 2 1 R 1 P P P  A 1 F S A  1 L Y P S T  1 G 2 E B U  4 D B M  3 M S L  1 Z A O  8 D D E N  A C 3 P P P  6 N T C D  2 F B R N  6 1 6 9 3 J L F  1 G H  I  P A M S  5 P M H C  - - -  2 F T A  I  2 P T A T H  A 1 B A R  2 2 F H P  1 K L C  A L O P A P  7 R 1 P P P  1 O M U S  7 D E M T  1 D 1 L S R  1 C 1 V 6 P T A  3 2 1 0 4 4 C O L  1 E C R A M S  2 P M A L  C 1 E B U  4 D E M  K 2 R L O P  Fig.
7.
Mean decrease accuracy according to a RF classiﬁcation of the 50 most highly expressed genes in metagene w 28 and metagene w 13 selected by LNMF.
In case of underexpressed metagenes related to the disease, only a few signiﬁcant meta-experiments appear for K   60.
As an example, a decomposition in K = 370 metagenes is considered.
Meta-experiment h13  yields  corr(h13 ,d2 ) = 0.98 with respect to the separation between the classes  healthy  and  diseased  (Fig.
6).
The 10 most strongly expressed genes in metagene w 13 which qualify as marker genes for the discrimination between healthy subjects and Niemann Pick C patients are listed in Table 2 in column labeled NMF-GEL.
Again the 50 most highly expressed genes in metagene w 13 have been subjected to a RF classiﬁcation, where 10 marker genes, listed in Table 2 in column labeled NMF- RF, stand out as most informative for Case 2 (HeDi) classiﬁcation (Fig.
7).
though.
As can be seen from Table 4,  4.3 MF classiﬁer Applying the MF classiﬁer described eralier, the similarity between either the rows of matrix A (ICA) or the columns of matrix H (NMF) was studied using the dataset with LOO cross-validation.
Note that the matrix decomposition step used the complete data matrix, in most cases one false classiﬁcation occurred in Case 1 classiﬁcation leading to the suspicion of a falsely classiﬁed data sample which could be identiﬁed as Experiment 4.
Compared to ICA-based feature selection and matrix decomposition, the corresponding LNMF- based feature selection and matrix decomposition lead to a more robust classiﬁcation of all four diagnostic classes underlying the dataset with respect to a variation of the number k of extracted features.
However, with features encompassing more than seven genes a close to perfect classiﬁcation with a close to zero classiﬁcation error resulted.
4.3.1 Comparison of expression modes and metagenes Though both the ICA and the LNMF algorithm lead to data matrix  1695  Fig.
5.
Signature of meta-experiment h28  of Hk=29 and corresponding GES of metagene w 28 of Wk=29.
Fig.
6.
Signature of meta-experiment h13  and corresponding metagene w 13. of  corr(hk ,di, )    0.9.
Up to K =90 mostly one signiﬁcant meta- experiment was observed, for K  90, except K = 120,170 and 190, at least two signiﬁcant meta-experiments were detected.
Rows of H related to the reverse case el(macrophage)   el(monocyte) do not appear at a comparable level of correlation to the design vector.
Figure 5 exhibits the signature of row h28  of Hk=29 and the related metagene.
The 50 most highly expressed genes in metagene w 28 have also been subjected to a RF classiﬁcation to obtain a measure of importance of these genes for the decision in question (Case 1 MoMa).
Only 4 genes stand out as informative (Fig.
7) but the mean decrease accuracy decreases exponentially, hence only the 10 most important genes are listed in Table 1 together with the 10 most highly expressed genes in metagene w 28.
Healthy versus diseased: In this case, the number of meta- experiments with a strong correlation with the design vector reﬂecting overexpressed genes in case of cell lines taken from Niemann Pick C patients increases nearly linearly with increasing k.  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1695  1688 1697   R.Schachtner et al.
Table 4.
Number of false classiﬁcations of the MF classiﬁer using ICA (left) or NMF (right) for matrix decomposition and LOO cross-validation  K  JADE MoMa avg  max  LNMF MoMa avg  max  JADE HeDi avg  max  LNMF VHeDi avg  max  2 3 4 5 6 7 8 9 10 11 12 13 14  11 3 3 2 3 1 1 1 2 1 1 1 1  11 5 4 2 2 1 1 2 2 2 2 2 2  4 1 1 1 1 1 1 1 2 1 1 2 2  9 1 1 1 1 1 1 1 1 1 2 2 2  11 5 5 4 4 1 0 0 0 0 0 0 0  12 5 3 2 1 0 0 0 0 0 0 0 0  3 0 0 0 0 0 0 0 0 0 0 0 0  5 0 0 0 0 0 0 0 0 0 0 0 0  Class labels: Mo - Monocyte, Ma - Macrophage, He - healthy, Di - Niemann Pick C disease.
decompositions which ﬁnally lead to robust and efﬁcient diagnostic classiﬁcation of the datasets, they nonetheless resulted with groups of strongly over- or under-expressed genes in the related metagenes and expression proﬁles which showed only partial overlap.
It is interesting to compare the distribution of correlation coefﬁcients of the individually observed expression proﬁles of the identiﬁed marker genes for both algorithms.
It turned out that the LNMF algorithm results in a much narrower distribution of c-values meaning that it yields a much more consistent set of diagnostic marker genes when measured by the correlation to the diagnostic design vector.
5 SUMMARY AND CONCLUSION 5.1 Summary In this study microarray datasets from a monocyte macrophage differentiation study have been analyzed.
Unsupervised feature generation strategies based on MF techniques were combined with knowledge-based feature selection and classiﬁcation strategies referring to diagnostic information available about the class labels of the experiments.
The importance of the generated features, i.e.
either the expression modes or the metagenes, was assessed by measuring the correlation of the related feature proﬁles or meta- experiments with the diagnostic design vector of the experiment under consideration.
Two strategies were then followed to achieve classiﬁcation: either an MF classiﬁer was applied directly or a set of marker genes was extracted from the most informative expression mode or metagene and classiﬁcation was achieved applying an SVM classiﬁer with LOO cross-validation.
Marker genes were extracted based either on their expression level in the most informative feature vector or by applying an RF classiﬁer to evaluate their level of importance for the classiﬁcation decision at hand.
5.2 Conclusion Concerning the identiﬁed marker genes, a remarkable number of marker genes could be corroborated by at least one other method, mostly of the MF venue.
These genes are indicated in bold face in  1696  Tables 1 and 2.
It is interesting to see that in case of ICA feature generation most of the genes with the highest expression level in the most informative expression submode, listed under ICA-GEL-neg, are corroborated by the RF classiﬁer as being especially important for the classiﬁcation decisions at hand.
This lends credit to the ICA  feature generation and selection procedure which indeed results in an informative set of marker genes.
But in case of the NMF- GEL/RF methodology only little correspondence between both lists can be seen.
Hence in the NMF methodology strong expression levels cannot be considered a valid selection criterion to identify marker genes though these genes belong to the feature vector which was identiﬁed as most relevant for the classiﬁcation decision at hand according to the diagnostic knowledge available.
Also, there is still considerable divergence between the results obtained with the ICA and the NMF methodologies for both classiﬁcation cases considered.
One of the reasons might be the different constraints active in both feature generation methods (ICA versus NMF) investigated.
The constraints operative with ICA assume statistical independence of the generated expression modes, thus only features which comply to this property can be detected.
On the other hand, the sparseness and positivity constraints of the LNMF algorithm lead to metagenes which contain localized features (= few highly expressed values and many zeros) and only positive expression levels.
The gene expression signatures of the underlying biological regulatory processes are expected to have non-Gaussian distributions, hence uncorrelated metagenes and independent expression modes are expected to be different.
Further selection of marker genes solely based on their expression level in the feature vectors is not a statistically valid criterion, hence results might not be expected to conform to marker genes selected by the statistically well-founded RF method or the supervised techniques discussed as well.
Still Tables 1 and 2 show a couple of genes which have been identiﬁed consistently with different methods for the classiﬁcation tasks at hand.
These genes can be considered well-justiﬁed marker genes.
Strong overlap is also observed between the lists resulting from the SGP/SVM-LOO and the NMF-GEL methodology in Case 2 classiﬁcation meaning that each of these strongly expressed genes of the most informative metagene is able to also individually classify the cell line investigated.
Note that only two of these genes, i.e.
SAP1 and RAB1A, are also identiﬁed by the ICA-GEL/RF methodology, hence are identiﬁed by three of the four methodologies investigated.
In Case 1 classiﬁcation, no correspondence between the standard methodologies and the MF-based techniques can be observed, however.
Further note that no single gene could be identiﬁed with these standard techniques which could classify monocytes versus macrophages perfectly.
These observations might indicate that the joint discriminative power of a set of genes is necessary to successfully classify Case 1.
If so then none of the gene which perform best individually belongs to this set.
All matrix decompositions strategies lead to classiﬁcation results of the MF classiﬁer with classiﬁcation errors comparable to those obtained with supervised techniques.
Since the quality of the results did not change when the number K of extracted basis vectors was increased, the classiﬁcation performance did not favor one of the tested LNMF runs.
Despite that one monocyte sample must deﬁnitely be considered to be an outlier, i.e.
this probe set is expected to be falsely classiﬁed in the original dataset.
No single tested  [11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1696  1688 1697   decomposition, neither by JADE nor by LNMF, classiﬁed these samples correctly.
Concerning more standard supervised techniques, marker genes were selected by their ability to individually classify the cell lines under study applying an SVM classiﬁer with LOO cross-validation.
Preselection strategies based on various single gene scoring schemes were considered as well.
It seems that the Pearson correlation score achieved the most useful results in what concerns reproducibility of the extracted marker genes by other methods.
The resulting list of marker genes was for the HeDi classiﬁcation problem also compared to an importance ranking resulting from the application of an RF classiﬁer to the 50 most highly ranked genes according to all scores employed.
No overlap is observed between both lists.
However, 6 out of 10 genes of the SGP/SVM-LOO list could be conﬁrmed by other methods but only one gene of the C-Sc-RF list is corroborated also by the ICA-RF-pos methodology.
Though the classiﬁcation errors are comparable,  the matrix decomposition-based approach has the advantage of not having to deal with each gene in isolation as is the case with the supervised techniques considered.
The matrix decomposition technique instead provides a feature selection and classiﬁcation tool which uses diagnostic knowledge available and the joint discriminative power of a group of most informative genes.
If it only were to classify the type of cell lines investigated, the MF classiﬁer does well and identiﬁcation of marker genes is not necessary.
ACKNOWLEDGEMENTS Funding: This work is supported by grants from Siemens AG, Munich, the DFG (Graduate College 638) and the DAAD (PPP Luso - Alem a and PPP Hispano - Alemanas) which is gratefully acknowledged.
Conﬂict of Interest: none declared.
REFERENCES Affymetrix (2002) Affymetrix Microarray Suite User Guide.
Affymetrix Santa Clara,  CA.
Allison,D.
et al.
(2006) Microarray data analysis: from disarray to consolidation and  consensus.
Nat.
Rev.
Genet., 7, 55 65.
Baldi,P.
and Hatﬁeld,W.
(2002) DNA Microarrays and Gene Expression.
Cambridge  University Press.
Matrix Factorization  Diaz-Uriarte,R.
(2007) Genesrf and varselrf: a web-based tool and r package for gene selection and classiﬁcation using random forest.
BMC Bioinformatics, 8, 328 335.
Diaz-Uriarte,R.
and de Andrés,S.A.
(2006) Gene selection and classiﬁcation of  microarray data using random forest.
BMC Bioinformatics, 7, 3 16.
Dougherty,E.
and Datta,A.
(2005) Genomic signal processing: diagnosis and therapy.
IEEE Signal Proc.
Mag., 22, 107 112.
Dougherty,E.
et al.
(2005) Research issues in genomic signal processing.
IEEE Signal  Proc.
Mag., Nov, 46 68.
Dudoit,S.
et al.
(2002) Comparision of dicrimination methods for classiﬁcation of  tumors using gene expression data.
J.
Am.
Stat.
Assoc., 97, 77 87.
Galton,F.
(1888) Co-relations and their measurement, chieﬂy from anthropometric data.
Proc.
R.
Soc., 45, 135 145.
Galton,F.
(1889) Co-relations and their measurement, chieﬂy from anthropometric data.
Nature, 39, 238.
Golub,T.R.
et al.
(1999) Molecular classiﬁcation of cancer: class discovery and class  prediction by gene expression monitoring.
Science, 286.
Guyon,I.
and Elisseeff,A.
(2003) An introduction to variable and feature selection.
J. Mach.
Learn.
Res., 3, 1157 1182.
Hochreiter,J.
et al.
(2006) A new summarization method for affymetrix probe level data.
Bioinformatics, 22, 943 949.
Irrizarry,R.A.
et al.
(2003) Summaries of affymetrix genechip probe level data.
Nucleic  Acids Res., 31, 1 8.
Lee,S.-I.
and Batzoglou,S.
(2003) Application of independent component analysis to  microarrays.
Genome Biol., 4, R76.1 R76.21.
Li,S.
et al.
(2001) Learning spatially localized, parts-based representation.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, vol.
1.
Liebermeister,W.
(2002) Linear modes of gene expression determined by independent  component analysis.
Bioinformatics, 18, 51 60.
Liu,Z.
et al.
(2005) Gene expression data classiﬁcation with kernel principal component  analysis.
J. Biomed.
Biotechnol., 2, 155 159.
Lutter,D.
et al.
(2008) Analysing M-CSF dependent monocyte/macrophage differentiation and meta-clustering with independent component analysis derived expression modes.
BMC Bioinformatics, in press.
Mangasarian,O.
and Musicant,D.
(2001) Lagrangian support vector machines.
J. Mach.
Learn.
Res., 1, 161 177.
Pearson,K.
(1901) On lines and planes of closest ﬁt to points in space.
Phil.
Mag., 2,  559 572.
Quackenbush,J.
(2001) Computational analysis of microarray data.
Nature, 2, 418 427.
Saidi,S.
A. et al.
(2004) Independent component analysis of microarray data in the study  of endometrial cancer.
Oncogene, 23, 6677 6683.
Schachtner,R.
et al.
(2007a) Blind matrix decomposition techniques to identify marker genes from microarrays.
In Davies et al.
(eds), Lecture Notes in Computer Science, vol.
4666.
Springer.
Schachtner,R.
et al.
(2007b) Routes to identify marker genes for microarray classiﬁcation.
In Dittmar,A.
and Clark,J.
(eds), In Proceeding of the 29th International Conference on IEEE Engineering in Medicine and Biology Society.
IEEE-EmBC, Lyon, France, pp.
4617 4620.
Schölkopf,B.
and Smola,A.
(2002) Learning with Kernels.
MIT Press.
Simon,R.
(2003) Supervised analysis when the number of candidate features (p) greatly  exceeds the number of cases (n).
SIGKDD Explor., 5, 31 36.
Barnhill,S.
et al.
(2002) Gene selection for cancer classiﬁcation using support vector  Spang,R.
et al.
(2002) Prediction and uncertainty in the analysis of gene expression  machines.
Mach.
Learn., 46, 389 422.
Bolstad,B.M.
et al.
(2003) A comparison of normalization methods for high density oligonucleotide array data based on bias and variance.
Bioinformatics, 19, 185 193.
Breiman,L.
(2001) Random forests.
Mach.
Learn., 45, 5 32.
Cardoso,J.-F. and Souloumiac,A.
(1993) Blind beamformimg for non-gaussian signals.
IEEE Proc., F140, 362 370.  proﬁles.
In Silico Biol., 2, 33 58.
Talloen,W.
et al.
(2007) I/NI-calls for the exclusion of non-informative genes: a highly  effective ﬁltering tool for microarray data.
Bioinformatics, 23, 2897 2902.
Troyanskaya,O.
et al.
(2001) Missing value estimation methods for DNA microarrays.
Bioinformatics, 17, 520 525.
Tusher,V.G.
et al.
(2001) Signiﬁcance analysis of microarrays applied to the ionizing  radiation response.
PNAS, 98, 5116 5121.
Cardoso,J.-F. and Souloumiac,A.
(1996) Jacobi angles for simultaneous diagonalization.
Wu,Z.
and Irizarry,R.
(2007) A statistical framework for the analysis of microarray  SIAM J.
Math.
Anal.
Appl., 17, 161 164.  probe-level data.
Ann.
Appl.
Stat., 1, 333 357.
Chen,Z.
et al.
(2007) A distribution free summarization method for affymetrix genechip  Wu,Z.
et al.
(2004) A model-based background adjustment for oligonucleotide  arrays.
Bioinformatics, 23, 321 327.  expression arrays.
J.
Am.
Stat.
Assoc., 99, 909 917.
[11:37 17/7/03 Bioinformatics-btn245.tex]  Page: 1697  1688 1697  1697
