BIOINFORMATICS  Vol.
30 ECCB 2014, pages i445 i452 doi:10.1093/bioinformatics/btu451  Experimental design schemes for learning Boolean network models Nir Atias, Michal Gershenzon, Katia Labazin and Roded Sharan* Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv 69978, Israel  ABSTRACT Motivation: A holy grail of biological research is a working model of the cell.
Current modeling frameworks, especially in the protein pro- tein interaction domain, are mostly topological in nature, calling for stronger and more expressive network models.
One promising alter- native is logic-based or Boolean network modeling, which was suc- cessfully applied to model signaling regulatory circuits in human.
Learning such models requires observing the system under a sufficient number of different conditions.
To date, the amount of measured data is the main bottleneck in learning informative Boolean models, under- scoring the need for efficient experimental design strategies.
Results: We developed novel design approaches that greedily select an experiment to be performed so as to maximize the difference or the entropy in the results it induces with respect to current best-fit models.
Unique to our maximum difference approach is the ability to account for all (possibly exponential number of) Boolean models displaying high fit to the available data.
We applied both approaches to simulated and real data from the EFGR and IL1 signaling systems in human.
We demonstrate the utility of the developed strategies in substantially im- proving on a random selection approach.
Our design schemes high- light the redundancy in these datasets, leading up to 11-fold savings in the number of experiments to be performed.
Availability and implementation: Source code will be made available upon acceptance of the manuscript.
Contact: roded@post.tau.ac.il  1 INTRODUCTION  Network analysis tools have become over the last decade the method of choice for studying genome-wide data, yielding im- portant insights into gene function, interaction and evolution.
Nevertheless, most of these tools, especially in the protein pro- tein interaction domain, have been limited to pure topological analysis of the pertaining networks, calling for stronger and more expressive network models (Huang and Fraenkel, 2009  Yeger- Lotem et al., 2009  Yosef et al., 2009).
Recently, Boolean network modeling has been successfully at- tempted at signaling networks, yielding a qualitative functional understanding of signaling pathways and the ability to predict their behavior under different perturbations and environmental cues (Mitsos et al., 2009  Saez-Rodriguez et al., 2009  Sharan and Karp, 2012).
However, because of the sparsity of the currently available data, learning such models de novo remains a formid- able task, requiring computational strategies to efficiently priori- tize experimental conditions that will best reveal the underlying model.
We refer the reader to Karlebach and Shamir (2008) for a comprehensive survey of Boolean modeling.
*To whom correspondence should be addressed.
identification problem (Apgar  An alternative modeling technique for signaling pathways dy- namics based on ordinary differential equations (ODEs) was thoroughly studied (Hughey et al., 2010).
These equations offer a mechanistic chemically based view on the change in the level of cellular species as a function of the levels of their interactors.
The dependency of such a detailed modeling on the availability of experimental data has triggered two lines of work of algorithmic experimental design (Kreutz and Timmer, 2009): the first ad- dressing the challenge in parameter estimation (Balsa-Canto et al., 2008  Bandara et al., 2009) and the second addressing et al., 2008  the model Harrington et al., 2012  Kremling et al., 2004  M elyk  uti et al., 2010).
Nevertheless, the application of this formalism to large- scale modeling is limited by the large number of required par- ameters whose estimation is difficult (Gutenkunst et al., 2007).
In contrast to the relatively rich literature on ODEs, experi- mental design algorithms for Boolean networks are scarce.
Ideker et al.
(2000) proposed an experimental design scheme involving two principal entities: a predictor that generates models given an experimental data and a chooser that selects the next experiment to be conducted based on information the- oretic principles.
These two entities were used in an iterative manner to learn a genetic network from gene expression data.
A similar entropy-based criterion was used by Szczurek et al.
(2009) to learn regulatory relations downstream to a given sig- naling pathway.
Barrett and Palsson (2006) proposed an experi- mental design algorithm for learning regulatory networks that maximizes at each step an estimate of the expected information gain.
In the context of signaling networks, we have previously sketched a maximum entropy-based experimental design scheme (Sharan and Karp, 2012), but the scheme was not completely defined nor its utility was tested.
Here we propose two comprehensive experimental design stra- tegies.
The first realizes the maximum entropy principle to guide the selection of experiments in the context of Boolean networks learning.
The second strategy learns de novo experiments that maximize the disagreement between current best-fit models, a criterion that we term maximum difference.
For this optimization task, we propose a novel algorithm that considers the entire space of candidate models and possible experiments.
We implement and test these strategies on simulated and real experimental data using two detailed Boolean models for EGFR and IL1 signaling.
We show that both strategies can be used to prioritize experiments and discover redundancies among them, considerably outperforming a random-choice scheme.
In particu- lar, we find that the maximum difference criterion is superior to all other approaches in all the settings we tested, leading to 5 11- fold savings in the number of experiments to be performed with respect to the available experiment sets.
ß The Author 2014.
Published by Oxford University Press.
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.
For commercial re-use, please contact journals.permissions@oup.com   N.Atias et al.
2 METHODS  2.1 Data retrieval To evaluate a design scheme, we applied it to prioritize experiments in the context of two signaling systems in human: EGFR signaling, which regu- lates cellular growth, proliferation, differentiation and motility  and IL1 signaling, which is involved in coordinating the immune response upon bacterial infection and tissue injury.
Both systems are well studied, and detailed manual models exist for them.
In particular, Samaga et al.
(2009) have constructed a comprehensive Boolean model of the EGFR system, which contains 112 molecular species and their associated Boolean func- tions  Ryll et al.
(2011) have created a Boolean model of the IL1 system with 121 molecular species.
We retrieved these models from the CellNetAnalyzer repository (http://www.mpi-magdeburg.mpg.de/proje cts/cna/repository.html).
To learn logical models for these systems, we used data published by the above authors on the activity (phosphorylation) levels of certain pro- teins under different cellular conditions.
Specifically, Samaga et al.
mea- sured within the EGFR system the activity levels of 11 proteins under 34 distinct conditions in Hep2G cells.
Similarly, Ryll et al.
measured within the IL1 system the activity levels of nine proteins under 14 distinct con- ditions in primary hepatocytes.
Following Ryll et al.
(2011) and Samaga et al.
(2009), we focused our analysis on the measurements at the 30 min time point, representing the early response of each system.
2.2 Experimental design criteria Previously, an optimal algorithm for learning Boolean models given ex- perimental data was introduced by Sharan and Karp (2012).
However, because of the sparsity of experimental data, the learning procedure yields many models, each explaining the data equally well.
To overcome this difficulty in model identification, additional experimental data are needed.
Here, we studied two strategies to elucidate informative experi- ments: the first based on a maximum entropy criterion and the other based on a novel criterion, termed maximum difference criterion.
2.2.1 Maximum entropy criterion In information theory, the en- tropy statistic is a standard scoring method that quantifies the informa- tion encoded in a given random variable, where higher entropy implies a more informative distribution.
An experimental design scheme based on the maximum entropy approach has been previously studied in different settings, such as the identification of regulatory interactions (Ideker et al., 2000) and regulatory functions downstream to signaling pathways (Szczurek et al., 2009).
We have sketched a maximum entropy-based strategy for experimental design of Boolean network (Sharan and Karp, 2012) but did not implement or demonstrate the utility of this approach.
Here we implement an experimental design strategy based on a max- imum entropy approach.
At the heart of this strategy is the evaluation of the entropy of a candidate experiment e according to the predicted re- sponse of different models.
Formally, let re be the response vector of some model to the experimental conditions set in e. Denote by pðreÞ the prob- ability of observing the response re across all the candidate models.
Then, the entropy of the experiment is given by  X  EntropyðeÞ=    pðreÞ   log pðreÞ  ð1Þ  r  highest entropy from a set of candidate experiments.
The maximum entropy strategy prioritizes the experiment with the Note that computing the entropy requires the calculation of pðreÞ, the distribution of responses over all models that fit the currently available data well.
However, enumeration of all such models is intractable.
Previous approaches assumed that a set of possible models is given or that the model space can be sampled.
In this work, we adopt the latter ap- proach and sample up to a fixed number of best-fit models.
Specifically,  i446  we solve an integer linear program (ILP) to infer a best-fit model and use the ILP solver to enumerate multiple solutions.
The actual number of solutions is varied to study its impact on the performance of our strategy (see below).
Other sampling approaches use Monte Carlo simulations  however, these are often computationally intensive and require large run- ning times (Kreutz and Timmer, 2009).
X  n  2.2.2 Maximum difference criterion We propose and implement an intuitive criterion for experimental design strategy based on maximum difference.
This criterion is defined as the Hamming distance between two Boolean response vectors.
Formally, given an experiment e, let rM1 e  rM2 e be the response vectors of two models to the experimental condi- tions defined in e. Then, the difference criterion is defined by  DifferenceðeÞ=  jrM1 eðiÞ   rM2 eðiÞj  ð2Þ  i=1  where j j denotes absolute value.
We note that M elyk  uti et al.
(2010) have previously experimented with an approach based on similar intuition in the context of ODE models.
The maximum difference strategy prioritizes experiments resulting in the highest difference between a pair of models that equally agree with the available experimental data.
While considering the difference induced by only two models, this criterion is amenable to efficient computation via an integer linear programming formulation, allowing us to learn a de novo experiment that maximizes this criterion over all optimal models, elim- inating the need to enumerate models or to suggest candidate experiments a priori as in the maximum entropy approach.
2.3 Maximum difference learning algorithm We develop an algorithm to learn an experiment that maximizes the dif- ference criterion over the entire space of optimal models.
The input to the algorithm consists of a directed acyclic network over a set of nodes V and a set of experiments E whose outcome is already known.
The algorithm uses the learning algorithm by Sharan and Karp (2012) as a building block and its outline is as follows (see Fig.
1): (i) Duplicate the ILP of Sharan and Karp so that each copy holds a distinct model  these models (M1, M2) are used to evaluate the maximum difference criterion.
(ii) Use the term for the objective as defined in the Sharan and Karp formulation and its corresponding optimal value (OPT) to further constrain the copies of the program to describe solutions that optimally agree with the experimental data.
(iii) Add to the resulting program new variables and corresponding constraints to represent the experiment to learn ( ^e) as well as its readouts under each copy (rM1  ^e   rM2  ^e ).
Finally, (iv) define a new objective to maximize the differ- ence between readouts, as per Equation (2).
An optimal solution to this linear program details a maximum difference experiment.
Moreover, to maximize the objective, the corresponding variables of the duplicated programs describe two different models.
2.3.1 Implementation details We first formulate the problem using an ILP and subsequently solve it with a dedicated solver.
Generally, an ILP assumes the following form:  cTx min s:t: Ax   b  x 2 f0  1g  ð3Þ ð4Þ ð5Þ  Given a directed acyclic graph G with a set of vertices V, each repre- senting a molecular species, Sharan and Karp (2012) learn an optimal model with respect to a given experimental dataset E using an ILP for- mulation with variables x = (a,t) where ae,v is a binary variable denoting the activity level of species v in an experiment e, and tv represent the Boolean function associated with v. Additionally, their formulation   Experimental design for Boolean networks  perturbation defined by i 2 f1  2g where  )  indicates an  if-then  operator (see below).
s. Formally  ðiÞ sv=j ) a ^e v=j 8j 2 f0  1g   Finally, to maximize the difference between the two models the object-  P  ive for the ILP is given by modeled using an auxiliary variable dab such that  ð2Þ ð1Þ v2V ja ^e v   a ^e vj  the expression ja   bj is  a4b ) dab=a   b a   b ) dab=b   a  ð6Þ ð7Þ  The complete ILP is as follows (the constraints for Boolean function  adherence are omitted for brevity):  X  ð2Þ ð1Þ  ja ^e v   a ^e vj  min  v2V  s:t:  AxðiÞ   b  cTxðiÞ   OPT  i 2 f1  2g  i 2 f1  2g  ðiÞ sv=j ) a ^e v=j  i  j 2 f1  2g  ðiÞ ^e v 2 f0  1g xðiÞ  a sv 2 f0  1  2g  i 2 f1  2g  v 2 V  ð8Þ  ð9Þ  ð10Þ  ð11Þ  ð12Þ  ð13Þ  A restricted version of the algorithm additionally receives a set of ex- periments Elist=ðe1  .
.
.
ekÞ to choose from.
In this version, an additional integral variable   2 ½1  k  is introduced to the formulation indicating the chosen experiment.
Then, the following constraints are added to the program:   =i ) sv=IeiðvÞ 8i=1::k  v 2 Ie  ð14Þ  We use the restricted version of the algorithm in the application to the real datasets where the set of experimental conditions was predefined.
We also note that, in a similar fashion, additional constraints may be imposed on the algorithm to exclude experiments that are hard or impossible to conduct in a real setting.
Finally, we solve both the restricted and unrestricted versions of the  ILP using CPLEX.
2.3.2 If-then operator using ILP Our construction uses  if-then  clauses to model relationships between constraints.
These may be ex- pressed as follows:  ð15Þ  If aT  1 x   b1 then aT  2 x   b2    or, equivalently, by           aT 1 x4b1  ð16Þ To express this operator using ILP, let y 2 f0  1g be a binary vari- able and C1, C2 be two large constants and consider the following con- straints:  2 x   b2    aT  1 x4b1   C1   y aT 2 x   b2+C2   ð1   yÞ aT when y = 0, the first constraint holds while aT 2 x is, in practice, free to assume any feasible value  similarly, when y = 1, the second constraint must hold, and aT  1 x is not constrained.
ð17Þ  ð18Þ  In practice, we model  if-then  operators and absolute value terms  using the CPLEX built-in facilities.
i447  Fig.
1.
Overview of the experiment learning algorithm.
We start from an ILP (Sharan and Karp, 2012) that learns a Boolean network model M whose readouts have OPT disagreements with the experimental data.
In our formulation, this program is duplicated so that two models M1 and M2 are learned simultaneously.
The models are further constrained so that: they both have at most OPT disagreements with the experimental data and are therefore optimal and that they both simulate an unknown experiment ^e.
The objective optimizes the difference between the readouts of the models (rM1  ^e   rM2  ^e , resp.)
as per Equation (2)  uses constraints to ensure that the activity level of a species v is (i) com- patible with the activity levels of its predecessors and its Boolean func- tion  or (ii) determined by the experimental conditions so that ae v= IeðvÞ 8v 2 Ie, where Ie(v) is the activity level of species v as under the experimental conditions of e.  and tð2Þ  To generate a program for learning a maximum difference experiment, we first duplicate the variables and constraints in the above program and add the constraint cTx   OPT to each copy, where OPT is the value of the objective for an optimal solution to the original program.
Thus, the integral variables tð1Þ represent two models, each of which is optimal with respect to the available experimental data.
We also intro- ð1Þ ð2Þ ^e v  a duce the variables a ^e v to represent the activity states under a max- ^e.
Additionally, we introduce integral imum difference experiment variables sv 2 f0  1  2g for every species v indicating whether v is main- tained at an inactive state (0), active state (1) or not perturbed (2) in this maximum difference experiment.
v  v  We then add the following constraints to the ILP: (i) constraints to maintain the Boolean functions in ^e as in the original program and (ii) constraints to ensure that the activity level of species v matches the   N.Atias et al.
2.4 Simulation process For a given signaling system, let m* be a Boolean model that is known in advance, and let Ev be a set of experiments for validation.
Given an experimental design strategy and some initial subset of experiments E0, we measured the performance of the strategy by the number of additional experiments it used until a model whose predictions perfectly match the validation dataset (Ev) was learned.
We call such a model an optimal model.
We summarize our results using the third quartile (75th percentile) of the additional experiments distribution, which is robust to outliers in the data.
To generate the simulated datasets, we started with the known model m* and a subset of the nodes whose function we wished to learn.
We repeatedly simulated experimental data by randomly setting the experi- mental conditions, i.e.
assigning random binary values to a random subset of the nodes and calculating the readouts according to m*.
As mentioned above, the validation set, Ev, was generated independently from the other sets.
Additionally, we generated a different set of experi- ments, Elist, to prioritize out of which the set of initial experiments, E0, was selected.
The entire set of experiments in Elist, but not their readouts, was available to design schemes that prioritize experiments (such as the maximum entropy scheme), whereas only E0 was available to methods that infer experiments de novo, namely, to the maximum difference scheme and then random control scheme.
To ensure a fair comparison between the different methods Elist was sufficiently large to uncover an optimal model.
To study the different approaches in heterogeneous, yet realistic set- tings, we varied number of unknown functions in the range 10, 15, 16, 17, 18 and 20 species (the original data contained 16 unknown functions).
Similarly, the sets of perturbed and measured species were constrained to a subset of the species of equal size.
For our evaluation, we used initial subsets, E0, ranging in size from 1 to 8 to account for different amounts of prior knowledge pertaining to the system at hand.
Initial subsets for which the learned model performed as well as a model that was derived from the entire dataset were omitted.
For each size of the initial subset, up to 30 random subsets were repeat- edly sampled from Elist, and the third quartile of the number of additional experiments required to construct an optimal model was reported.
We repeat these analyses with 10 simulated datasets.
To study the effect of the number of available models on the perform- ance of the maximum entropy design, we fixed the number of unknown species to 16 while increasing the number of available models over 10, 30, 50, 70, 100 and up to 200.
To evaluate the stopping criteria, once an experiment was chosen, we enumerated such multiple models for all ex- perimental design strategies and stopped when at least one optimal model was found.
2.5 Significance assessment We assess the significance of the hypothesis that one strategy requires less experiments relative to another to arrive at an optimal model using a one- sided Wilcoxon paired test as implemented in R.  2.6 Quartiles standard error We estimate the standard error using Maritz Jarrett standard error esti- mation method (Maritz and Jarrett, 1978).
3 RESULTS  for model selection.
Despite its appealing theoretical properties, computing the entropy depends on the challenging task of esti- mating the distribution of the responses across candidate models and on the availability of a list of candidate experiments.
The second scheme, termed maximum difference, is an intui- tive and novel criterion maximizing the disagreement between two candidate models.
Using an ILP formulation, we optimally solve this model and uncover a de novo experiment maximizing this criterion.
Unique to our approach is its ability to implicitly consider all candidate models and experiments alleviating the need to specify them a priori.
3.2 Evaluation with simulated data  Given a known Boolean model for a signaling system, an experi- mental design strategy and an initial set of experiments, we meas- ure the performance of the strategy by the number of additional experiments it uses until an optimal model is learned and report the third quartile of the additional attempts in each dataset.
Here, an optimal model is one agreeing with the known model on a set of experiments that were not initially available to the experimental design strategy.
The simulation procedure (see Section 2) generated experimental conditions uniformly at random to provide an unbiased sample of the experimental space.
In contrast, in real published datasets, the choice of ex- perimental conditions is guided and may impact the relative per- formance of design schemes.
We compared the running times of the maximum difference and maximum entropy strategies when suggesting a single experi- ment to be conducted (Fig.
2).
Expectedly, the time of the max- imum entropy approach grew with the number of models being enumerated, whereas the maximum  the performance of  i  ) c e s (   e m T g n n n u R     i  * o * o  MaxDifference (EGFR) MaxEntropy (EGFR) MaxDifference (IL1) MaxEntropy (IL1)  o o  * *  o o  o o o * * * * * * o  5  4  3  2  1  0  o o  * *  0  2000  4000  6000  8000  10000  Models  3.1 Experimental design schemes for Boolean models  We propose and implement two experimental design schemes for Boolean network models.
The first scheme is based on maximum entropy approach, an accepted information theoretic criterion  Fig.
2.
Runtime comparison.
A comparison of the running times of the maximum difference and maximum entropy approaches.
Running times are given on two datasets (EGFR and IL1) when computing a single experiment to be conducted as a function of the number of available optimal models  i448   Experimental design for Boolean networks  (A)  5 1  s t n e m  i r e p x E   #  0 1  5  0  10  30  50  70 # Available Models  MinEntropy Random MaxEntropy MaxDifference  (B)  5 1  0 1  5  0  10  100  200  30  50  70 # Available Models  100  200  Fig.
3.
Sensitivity to the number of available models.
The estimation of entropy was dependent on the number of available models.
In contrast, the maximum difference learning algorithm optimized over all candidate models.
In both panels, the x-axis denotes the number of available models for entropy estimation, and the y-axis denotes the third quartile of the number of experiments required to obtain an optimal model (lower is better).
Error bars denote standard error.
(A) Simulation with EFGR signaling.
(B) simulation with IL1 signaling  difference approach was not affected by it, underscoring its ad- vantage in handling complex problems that admit (for a given experimental dataset) many optimal solutions.
We used the EGFR Boolean model by Samaga et al.
and the IL1 model by Ryll et al.
to compare the performance of four design strategies: (i) a naive approach choosing experiments at random, (ii) a maximum entropy approach based on a sample of models, (iii) a minimum entropy approach serving as a control and (iv) a maximum difference approach.
First, we sought to study the effect that the number of avail- able models has on the performance of the maximum entropy- based strategy.
Therefore, we applied the above evaluation scheme while increasing the number of models.
When the simulated data were generated from the EGFR Boolean network model, we found that when only a handful of models were available, the maximum entropy approach per- formed worse than randomly choosing an experiment, requiring two additional experiments.
However, as more models were available the performance relative to the random approach im- proved.
With 200 models available for the evaluation of the en- tropy, the performance of this approach was comparable with the maximum difference scheme.
In our tests, the maximal margin relative to random was obtained when 50 models were available, leading to an improvement of three experiments (see Fig.
3A).
The minimum entropy approach performed worse than all other methods  the performance of the method did not vary much when using 30 models or more.
Remarkably, the maximum difference approach significantly outperformed all other methods, across the parameter space (P53:72   10  16 relative to maximum entropy, the next best method, on 70 models).
Notably, the advantage in implicitly considering all op- timal models was evident as the performance of the method was constant across the parameter range.
We obtained similar results when the simulated datasets were generated using the IL1 signaling model (Fig.
3B).
In this case, the maximum entropy approach performed better than the random approach even when only few models were available.
Again, only when 200 models where available for the estimation of the entropy criterion the performance of the method was com- parable with that of the maximum difference approach.
In this dataset, a maximal margin of five experiments relative to random was obtained when 200 models were available.
Again, the max- imum difference approach outperformed all other methods across the entire parameter space (P51:73   10  18 relative to maximum entropy on 100 models).
Next, we examined the effect of the size of the learning task (i.e.
the number of Boolean functions that need to be learned) on the performance of the different methods.
To this end, we applied our evaluation scheme while fixing the number of models and varying the number of unknown functions in the range of 10 20, guided by the 16 unknown functions in the EGFR model.
When simulating the datasets through the EGFR model, the performance of the maximum entropy approach was closer to the random scheme than to the maximum difference design scheme (Fig.
4A).
Still, maximum entropy designs were consist- ently better than random (P51:75   10  3 for 18 unknown func- tions) with a margin of two experiments.
Additionally, with higher uncertainty, the number of additional experiments grew.
For 10 unknown functions the maximum entropy strategy also performed similar to random.
However, in this case, the space of possible models was greatly reduced to a point where even the random selection required four experiments for convergence, thus, room for improvement was limited to begin with.
Notably,  the maximum difference approach significantly outperformed all other methods while increasing the marginal  i449   N.Atias et al.
(A)  5 1  0 1  5  s t n e m  i r e p x E   #  MinEntropy Random MaxEntropy MaxDifference  (B)  5 1  0 1  5  0  10  15  16  17  18  20  Unknown functions  0  10  15  16  17  18  20  Unknown functions  Fig.
4.
Sensitivity to the number of unknown functions.
Increasing the number of unknown functions led to increment in the number of experiments that are required to uncover the underlying model in all but the maximum difference strategy, which retained an almost constant performance.
In both panels, the x-axis denotes the number of unknown functions, and the y-axis denotes the third quartile of the number of experiments required to obtain an optimal model (lower is better).
Error bars denote standard error.
(A) Simulation with EGFR signaling.
(B) Simulation with IL1 signaling  gap as the number of functions increased (P59:32   10 relative to maximum entropy for 15 unknown functions).
For example, the reduction in required experiments relative to max- imum entropy, which was the next best-performing method increased from one experiment for 15 unknown functions to five experiments for 18 unknown functions.
26  A similar behavior was observed when simulating the datasets through the IL1 model.
Again, the maximum entropy approach performed significantly better than the random design scheme (P57:71   10  25 for 20 unknown functions).
Still the maximum difference approach was superior to the maximum entropy scheme in all but a single scenario where 17 functions were pre- dicted.
Notably, the maximum difference approach required as little as half of the experiments required by the maximum en- tropy approach, which was the next best method, to converge when running the simulation with 10, 16, 18 and 20 missing functions.
Furthermore, the performance of the maximum dif- ference approach was nearly constant regardless of the size of the learning task.
3.3 Application to real data  To examine the utility of the different approaches in a more realistic setting, we applied them to the available datasets of phosphorylation measurements under different experimental conditions for the EGFR (34 experiments) and IL1 (14 experi- ments) systems.
We ran the different design strategies with increasing subsets of the data as starting points and measured the number of experiments needed to obtain a model that was as good as the one learned from all the available experiments.
The results are depicted in Figure 5.  i450  In this  setting, we  could not apply the maximum difference and random strategies in a straightforward manner, as we cannot simulate de novo experiments.
Instead, we applied restricted versions of these strategies, allowing them to choose only experiments that were included in the available data.
A key difference between the maximum difference and maximum entropy strategies in this setting is that the former implicitly considered all possible models where the later required a sample of models to evaluate the maximum entropy criterion.
In both datasets, the maximum difference approach performed best, regardless of the number of initial experiments.
On the EGFR dataset, maximum difference performed best with a sig- nificant advantage over the maximum entropy approach (P55:6   10  118  1.75 average difference between third quar- tiles).
Both methods significantly outperformed the random se- lection with margins of 1:5ðP51:4   10  44Þ experiments for maximum entropy and 3:25ðP55:3   10  191Þ experiments for the maximum difference design.
Similar results were obtained for the IL1 system, where data for only 14 experimental conditions were available.
Even with this small amount of data the reduction in the number of add- itional experiments that were required by the maximum differ- ence strategy was the maximum difference approach required on average 1.25 less ex- periments than both the maximum entropy approach ðP51:5    71Þ.
Interestingly, 10 the maximum entropy design performed comparably with the random approach in this dataset.
73Þ and the random approach ðP55:1   10  statistically significant.
Specifically,  The analyses of the real datasets revealed that the max- imum difference approach required less than three experiments   +  x o  *  +  x  o  *  +  x  o  *  (A)  2 1  s t n e m  i r e p x E   #  0 1  8  6  4  2  0  +  +  +  x o  *  x o  *  +  x o  *  7  +  x  o *  8  x  o  *  6  1  2  4  3 # Initial experiments  5  (B)  8  +  x o  *  s t n e m  i r e p x E   #  6  4  2  0  +  o x  *  1  2  Experimental design for Boolean networks  o x + *  MaxEntropy Random (restricted) MinEntropy MaxDifference (restricted)  +  o x  *  +  x o  *  + x o  *  + x o  *  + x o *  4  3 # Initial experiments  5  6  7  + x o  *  8  Fig.
5.
Performance evaluation on real data.
The x-axis denotes the number of initial experiments, and the y-axis denotes the third quartile of the number of additional experiments required to reconstruct a model fitting the data as well as a model obtained from the all the available experimental data.
(A) Results on the EGFR system.
(B) Results on the IL1 system  to learn an optimal model, achieving a 5 11-fold improvement over the respective sets of available experiments.
the development of other strategies that better sample the model space.
4 DISCUSSION  ACKNOWLEDGEMENT  In this article, we studied two approaches for experimental design in Boolean networks.
Our main contribution is in the de- velopment of an algorithm to optimally solve the maximum dif- ference design criterion while exploring the space of all optimal models under all possible experiments.
In addition, we implemented a method based on the well-studied criterion of maximum entropy and demonstrated its utility over a random selection of experiment as well as its limitations under varying conditions.
Our evaluation of these schemes indicated that under many conditions, especially in the face of scarce data and increasing complexity of the underlying system, our novel maximum difference approach outperforms the maximum entropy scheme.
Our findings suggest that current studies might suffer from redundant experimentation with respect to the available models of the systems at hand.
Furthermore, results on simulated data suggest that by adopting an experimental design scheme, much of the redundancy may be eliminated.
Thus, our approach should be beneficial for the study of systems whose underlying model is sufficiently detailed and may be formalized as a Boolean network.
On the methodological side, the maximum difference ap- proach is limited to considering the differences between pairs of models, calling for a generalized approach that considers mul- tiple models.
Additionally, in our current sampling procedure, we rely on the ILP solver to retrieve a diverse family of models.
Maximum entropy and similar approaches should benefit from  The authors comments.
thank Dana Silverbush for her valuable  Funding: Edmond J. Safra Center for Bioinformatics at Tel Aviv University (to N.A.)
and the I-CORE Program of the Planning and Budgeting Committee and The Israel Science Foundation (757/12 to R.S.).
Conflicts of Interest: none declared.
REFERENCES  Apgar,J.F.
et al.
(2008) Stimulus design for model selection and validation in cell  signaling.
PLoS Comput.
Biol., 4, e30.
Balsa-Canto,E.
et al.
(2008) Computational procedures for optimal experimental  design in biological systems.
IET Syst.
Biol., 2, 163 172.
Bandara,S.
et al.
(2009) Optimal experimental design for parameter estimation of a  cell signaling model.
PLoS Comput.
Biol., 5, e1000558.
Barrett,C.L.
and Palsson,B.O.
(2006) Iterative reconstruction of transcriptional  regulatory networks: an algorithmic approach.
PLoS Comput.
Biol., 2, e52.
Gutenkunst,R.N.
et al.
(2007) Universally sloppy parameter sensitivities in systems  biology models.
PLoS Comput.
Biol., 3, 1871 1878.
Harrington,H.A.
et al.
(2012) Parameter-free model discrimination criterion based  on steady-state coplanarity.
Proc.
Natl Acad.
Sci.
USA, 109, 15746 15751.
Huang,S.-S. and Fraenkel,E.
(2009) Integrating proteomic, transcriptional, and interactome data reveals hidden components of signaling and regulatory net- works.
Sci.
Signal., 2, ra40.
Hughey,J.J.
et al.
(2010) Computational modeling of mammalian signaling net-  works.
Wiley Interdiscip.
Rev.
Syst.
Biol.
Med., 2, 194 209.
Ideker,T.E.
et al.
(2000) Discovery of regulatory interactions through perturbation:  inference and experimental design.
Pac.
Symp.
Biocomput., 5, 305 316.  i451   N.Atias et al.
Karlebach,G.
and Shamir,R.
(2008) Modelling and analysis of gene regulatory net-  works.
Nat.
Rev.
Mol.
Cell Biol., 9, 770 780.
Kremling,A.
et al.
(2004) A benchmark for methods in reverse engineering and model discrimination: problem formulation and solutions.
Genome Res., 14, 1773 1785.
Kreutz,C.
and Timmer,J.
(2009) Systems biology: experimental design.
FEBS J.,  276, 923 942.
Maritz,J.S.
and Jarrett,R.G.
(1978) A note on estimating the variance of the sample  median.
J.
Am.
Stat.
Assoc., 73, 194 196.
Saez-Rodriguez,J.
et al.
(2009) Discrete logic modelling as a means to link protein signalling networks with functional analysis of mammalian signal transduction.
Mol.
Syst.
Biol., 5, 331.
Samaga,R.
et al.
(2009) The logic of EGFR/ErbB signaling: theoretical properties  and analysis of high-throughput data.
PLoS Comput.
Biol., 5, e1000438.
Sharan,R.
and Karp,R.M.
(2012) Reconstructing boolean models of signaling.
In: Proceedings of international conference on Research in Computational Molecular Biology.
RECOMB 12. pp.
261 271.
Springer- Verlag, Berlin, Heidelberg.
the 16th Annual  M elyk  uti,B.
et al.
(2010) Discriminating between rival biochemical network models:  Szczurek,E.
et al.
(2009) Elucidating regulatory mechanisms downstream of a  three approaches to optimal experiment design.
BMC Syst.
Biol., 4, 38.  signaling pathway using informative experiments.
Mol.
Syst.
Biol., 5, 287.
Mitsos,A.
et al.
(2009) Identifying drug effects via pathway alterations using an integer linear programming optimization formulation on phosphoproteomic data.
PLoS Comput.
Biol., 5, e1000591.
Yeger-Lotem,E.
et al.
(2009) Bridging high-throughput genetic and transcriptional data reveals cellular responses to alpha-synuclein toxicity.
Nat.
Genet., 41, 316 323.
Ryll,A.
et al.
(2011) Large-scale network models of IL-1 and IL-6 signalling and  Yosef,N.
et al.
(2009) Toward accurate reconstruction of functional protein net-  their hepatocellular specification.
Mol.
Biosyst., 7, 3253 3270.  works.
Mol.
Syst.
Biol., 5, 248.  i452
