BIOINFORMATICS ORIGINAL PAPER  Vol.
29 no.
16 2013, pages 1987 1996 doi:10.1093/bioinformatics/btt335  Gene expression  Advance Access publication June 8, 2013  Joint network and node selection for pathway-based genomic data analysis Shandian Zhe1, Syed A.
Z. Naqvi1, Yifan Yang2 and Yuan Qi1,3,* 1Department of Computer Science, 2Department of Biology, and 3Department of Statistics, Purdue University, West Lafayette, IN 47907, USA Associate Editor: Martin Bishop  ABSTRACT Motivation: By capturing various biochemical interactions, biological pathways provide insight into underlying biological processes.
Given high-dimensional microarray or RNA-sequencing data, a critical chal- lenge is how to integrate them with rich information from pathway databases to jointly select relevant pathways and genes for phenotype prediction or disease prognosis.
Addressing this challenge can help us deepen biological understanding of phenotypes and diseases from a systems perspective.
Results: In this article, we propose a novel sparse Bayesian model for joint network and node selection.
This model integrates information from networks (e.g.
pathways) and nodes (e.g.
genes) by a hybrid of conditional and generative components.
For the conditional compo- nent, we propose a sparse prior based on graph Laplacian matrices, each of which encodes detailed correlation structures between net- work nodes.
For the generative component, we use a spike and slab prior over network nodes.
The integration of these two components, coupled with efficient variational inference, enables the selection of networks as well as correlated network nodes in the selected networks.
Simulation results demonstrate improved predictive performance and selection accuracy of our method over alternative methods.
Based on three expression datasets for cancer study and the KEGG pathway database, we selected relevant genes and pathways, many of which are supported by biological literature.
In addition to pathway analysis, our method is expected to have a wide range of applications in selecting relevant groups of correlated high-dimensional biomarkers.
Availability: The code can be downloaded at www.cs.purdue.edu/ homes/szhe/software.html.
Contact: alanqi@purdue.edu  Received on February 9, 2013  revised on June 5, 2013  accepted on June 6, 2013  1 INTRODUCTION  With the popularity of high-throughput biological data such as microarray and RNA-sequencing data, many variable selection methods such as lasso (Tibshirani, 1996) and elastic net (Zou and Hastie, 2005) have been proposed and applied to select for disease diagnosis or prognosis.
these approaches ignore invaluable biological Nevertheless,  relevant genes  *To whom correspondence should be addressed.
pathway information accumulated over decades of research  hence, their selection results can be difficult to interpret biologic- ally and their predictive performance can be limited by a small sample size of expression profiles.
To overcome these limitations, a promising direction is to integrate expression profiles with rich biological knowledge in pathway databases.
Because pathways organize genes into biologically functional groups and model their interactions that capture correlation between genes, this information integration can improve not only the predictive performance but also interpretability of the selection results.
Thus, a critical need is to integrate pathway information with expression profiles for joint selection of pathways and genes associated with a phenotype or disease.
Despite their success in many applications, previous sparse learning methods are limited by several factors for the integra- tion of pathway information with expression profiles.
For example, group lasso (Yuan and Lin, 2007) can be used to utilize memberships of genes in pathways via a l1=2 norm to select groups of genes, but they ignore pathway structural information.
An excellent work by Li and Li (2008) overcomes this limitation by incorporating pathway structures in a Laplacian matrix of a global graph to guide the selection of relevant genes.
In addition to graph Laplacians, binary Markov random field priors can be used to represent pathway information to influence gene selec- tion (Li and Zhang, 2010  Stingo and Vannucci, 2010  Wei and Li, 2007, 2008).
These network-regularized approaches do not explicitly select pathways.
However, not all pathways are rele- vant, and pathway selection can yield insight into underlying biological processes.
A pioneering approach to joint pathway and gene selection by Stingo et al.
(2011) uses binary Markov random field priors and couples gene and pathway selection by hard constraints for example, if a gene is selected, all the path- ways it belongs to will be selected.
However, this consistency constraint might be too rigid from a biological perspective: an active gene for cancer progression does not necessarily imply that all the pathways it belongs to are active.
Given the Markov random field priors and the nonlinear constraints, posterior dis- tributions are inferred by a Markov Chain Monte Carlo (MCMC) method (Stingo et al., 2011).
But the convergence of MCMC for high-dimensional problems is known to take a long time.
To overcome these limitations, we propose a new sparse Bayesian approach, called Network and NOde Selection (NaNOS), for joint pathway and gene selection.
NaNOS is a sparse hybrid Bayesian model that integrates conditional and generative components in a principled Bayesian framework  ß The Author 2013.
Published by Oxford University Press.
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.
For commercial re-use, please contact journals.permissions@oup.com   S.Zhe et al.
(Lasserre et al., 2006).
For the conditional component, we use a graph Laplacian matrix to encode information of each network (e.g.
a pathway) and incorporate it into a sparse prior distribu- tion to select individual networks.
For the generative component, we use a spike and slab prior distribution to choose relevant nodes (e.g.
genes) in selected networks.
For this hybrid model, we do not impose the hard consistency constraints used by Stingo et al.
(2011).
Furthermore, the prior distribution of our model does not contain intractable partition functions.
This en- ables us to give a full Bayesian treatment over model parameters and develop an efficient variational inference algorithm to obtain approximate posterior distributions for Bayesian estimation.
As described in Section 3, our inference algorithm is designed to handle both continuous and discrete outcomes.
Simulation results in Section 4 demonstrate superior perform- ance of our method over alternative methods for predicting continuous or binary responses, as well as comparable or im- proved performance for selecting relevant genes and pathways.
Furthermore, on real expression data for diffuse large B cell lymphoma adenocarcinoma (PDAC) and colorectal cancer (CRC), our results yield meaning- ful biological interpretations supported by biological literature.
(DLBCL), pancreatic ductal  2 MODEL  In this section, we present the hybrid Bayesian model, NaNOS, for network and node selection.
First, let us start from the clas- sical variable selection problem.
Suppose we have N independent and identically distributed samples D ¼ fðx1, t1Þ, .
.
.
,ðxN, tNÞg, where xi and ti are the explanatory variables and the response of the i-th sample, respectively.
The explanatory variables can be various biomarkers, such as gene expression levels or single-nu- cleotide polymorphisms.
Following the tradition in variable selection, we normalize the values of each variable so that its mean and standard deviation are 0 and 1, respectively.
The response can be certain phenotype or disease status.
We aim to predict based on the explanatory variables X ¼ ½x1, .
.
.
, xN T and to select a small number of variables relevant for the prediction.
Because the number of variables (e.g.
genes) is often much bigger than the number of samples, the prediction and selection tasks are statis- tically challenging.
the response vector t ¼ ½t1, .
.
.
, tN    gene  various  revealing  To reduce the difficulty of variable selection, we can use valuable information from networks, each of which contains certain variables as nodes and represents their interactions.
For example, biological pathways cluster genes into functional groups, interactions.
Based on M networks, we organize the explanatory variables xi into M subvectors, each of which comprises the values of explanatory variables in its corresponding network.
If a variable (i.e.
a gene) appears in multiple networks (i.e.
pathways), we duplicate its value in these networks.
Note that networks here are exchange- able with graphs  we can use them to represent not only biological pathways but also linkage disequilibrium structures for genetic variation analysis.
Our model is a Bayesian hybrid of conditional and generative models based on a framework proposed by (Lasserre et al., 2006).
The conditional component selects individual networks via  discriminative  training, the generative  general  1988  component chooses relevant nodes in the selected networks and the two models are glued together through a joint prior distribution, so that the selected networks can guide node selec- tion and, in return, the selected nodes can influence network selection.
Specifically, for the conditional model, we use a Gaussian data  likelihood function for the continuous response  pðtjX, w,  Þ ¼  NðtijxT  i w,   1Þ  ð1Þ  Y  N  i¼1  Y  N  i¼1  where w are regression weights, each of which represents the contribution of the corresponding node to the response, and   is the precision parameter.
For the unknown variance  , we assign an uninformative diffuse Gamma prior, Gamð jg, hÞ with g ¼ h ¼ 10 6.
For the binary response, we use a logistic likelihood  pðtjX, wÞ ¼   ðxT  i wÞti½1    ðxT  i wÞ 1 ti  ð2Þ  where ti 2 f0, 1g, w are classifier weights and  ð Þ is the logistic function [i.e.
ðyÞ ¼ ð1 þ expð yÞÞ 1].
Based on the M networks, we partition w into M groups, so that w ¼ ½w1, .
.
.
, wM   where wk are the weights for the explanatory variables in the k-th network.
To incorporate the topological information of a network, we use its normalized Laplacian matrix representation.
Specifically, given an adjacent matrix Gk that represents the edges (i.e.
inter- actions) between nodes in the k-th network, the normalized Laplacian matrix Lk is defined as  8  : 1   Lkði, jÞ ¼ P 0 j Gkði, jÞ is the degree of the i-th node in the  i ¼ j and degðiÞ 6¼ 0 i 6¼ j and Gkði, jÞ 6¼ 0 otherwise  ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ p degðiÞdegðjÞ  1  where degðiÞ ¼ k-th network.
Based on the graph Laplacian matrices, we design the follow-  ing mixture prior over wk to select relevant networks: k Þ kNðwkj0, s2IkÞ1  k  1  pðwkj kÞ ¼ Nðwkj0, s1L  ð3Þ  where  k is a binary variable indicating whether the k-th network is selected, s14s2, s2   0 and Ik is an identity matrix.
We set the hyperparameters s1 and s2 based on cross-validation (CV) in our experiments.
To make sure Lk is strictly positive-definite, we add a diagonal matrix 10 6Ik to Lk.
In (3), Lk captures the correlation information between nodes in the k-th network.
Note that if we replace Lk by Ik in the slab component, the prior ð3Þ becomes a simple generalization of the classical spike for group and slab prior (George and McCulloch, 1997) selection.
When  k ¼ 1, the k-th network is selected and the elements of wk are encouraged to be similar to each other due to the Laplacian matrix Lk  when  k ¼ 0, because s2 is close to zero, the corresponding Gaussian prior prunes wk.
We use a Bernoulli prior distribution to reflect the uncertainty in  k, pð kÞ ¼ ðukÞ kð1   ukÞ1  k where uk 2 ½0, 1  is the selection probability.
Without any prior preference over selecting or prun- ing the k-th network, we assign a uniform prior over uk: pðukÞ ¼ 1 [i.e.
pðukÞ ¼ Betaðuk  a, bÞ where a ¼ b ¼ 1].
Joint network and node selection for pathway-based genomic data analysis  e  To identify relevant nodes, we introduce a latent vector  wk in the generative model for each network k, which is tightly linked to wk as explained later.
We use a spike and slab prior: Nð  wkjj0, r1Þ kjNð  wkjj0, r2Þ1  kj  pðe wkj kÞ ¼  pk  appears in multiple networks and is selected, our model will not force all the networks that contain this node to be chosen.
The reason is that we duplicate the value of this node in the networks and treat their corresponding regression or classifica- tion weights as separate model parameters.
Y Y ¼ pð0je  j¼1 pk  j¼1  ¼  Nð0j  wkj, r1Þ kjNð0j  wkj, r2Þ1  kj wk,  kÞ  ð4Þ  3 ALGORITHM  shown above, the spike and slab prior pðe form as pð0je  where pk is the number of nodes in the k-th network, r2   0 and  kj is a binary variable indicating whether to select the j-th node in the k-th network.
We give  kj a Bernoulli prior, pð kjÞ ¼ ðvkjÞ kjð1   vkjÞ1  kj , and a uniform prior over vkj: pðvkjÞ ¼ 1 (i.e.
pðvkjÞ ¼ Betaðvkjjc, dÞ where c ¼ d ¼ 1).
As wkj kÞ has the same e wk,  kÞ, which can be viewed as a generative model in other words, the observation 0 is sampled from wk.
This view enables us to combine the sparse conditional model for network selection with the sparse generative model for node selection via a principled hybrid Bayesian model.
Specifically, to link the conditional and generative models  together, we introduce a prior on  e pðe wkjwkÞ ¼ Nðe wk: e wkjwk,  IÞ  so  pðe wkjwkÞ ¼  ðe  where the variance   controls how similar joint model.
For set wk   wkÞ where  ðfÞ ¼ 1 if  wk and wk are in our that f¼ 0 and  ðfÞ ¼ 0 otherwise.
The graphical model representation of the joint model is given in Figure 1.  simplicity, we    ¼ 0  node are removed.
Because wk ¼e  ðe  The network and node selections are consistent with each e other in a probabilistic sense.
If a network is pruned, all its wk is enforced by the prior wk   wkÞ, when  k ¼ 0, wk ¼ 0 implies wk ¼ 0.
As a result, the spike component in (4) will be selected for all the nodes in the k-th network (i.e.
kj ¼ 0 for j ¼ 1, .
.
.
, pk) with a higher probability than the slab component.
On the other hand, it is easy to see that if one or multiple nodes in a network are selected, then this network will be selected too.
Note that if a node  ð5Þ  wk,  kÞ Bernð kjukÞ BetaðukÞ   ð6Þ  In this section, we present the variational Bayesian algorithm for model estimation.
Specifically, we develop the variational updates to efficiently approximate the posterior distribution of weights w, the network-selection indicators  , the node-selection indicators  , the network- and node-selection probabilities u and v and the precision parameter   for regression.
Based on the posteriors of   and  , we can decide which networks and nodes are selected.
For regression, based on the model specification in Section 2,  the posterior distribution of our model is  e pðw, w,  ,  , u, v,  jt, XÞ Y pðwkj kÞpðe NðtjXw,   1IÞGammað Þ  ¼ 1 Z Y  wkjwkÞpð0je where pðwkj kÞ and pð0je wkjwkÞ ¼  ðe pðe  Bernð kjjvkjÞBetaðvkjÞ  k  j  wk,  kÞ are defined in (3) and (4), wk   wkÞ and Z is the normalization constant.
For classification, the posterior distribution is similar to (6), except that we replace the Gaussian likelihood (1) by the logistic function (2) and remove the precision parameter   and its prior for regression in (6).
Specifically,  Classical Markov chain Monte Carlo methods can be applied to approximate the posterior distribution.
However, given the high dimensionality of the parameters (e.g.
w and  ), it would take a long time for a sampler to converge.
In practice, it is even difficult to judge the sampler s convergence.
Thus, we resort to a computationally efficient variational approximation to (6).
posterior distribution in (6) by a factorized distribution: Q( )¼ QðwÞQð ÞQð ÞQðuÞQðvÞQð Þ, where   denotes all the latent vari- ables.
Note that, for classification, we do not have Q ð Þ. w   wÞ, we do not need a separate wÞ.
To solve Qð Þ, we minimize the Kullback- Leibler (KL) divergence between the exact and approximate posterior distributions of  :  Because we set pðe distribution Qðe  wjwÞ ¼  ðe  approximate  exact  the  we  Z  KLðQð Þjjpð jt, XÞÞ ¼  Qð Þ ln  Qð Þ pð jt, XÞ d   ð7Þ  Fig.
1.
The graphical model representation of NaNOS  Applying coordinate descent for the minimization of (7), we obtain efficient updates for the variational distributions as described in the following sections.
The updates are iterative: we update one of the variational distributions at a time while having all the other variational distributions fixed, and iterate these updates until these updates monotonically decrease the value of the KL divergence (7), which is lower bounded by zero, they are guaranteed to converge in terms of the KL value (Bishop, 2006).
convergence.
Because  1989   S.Zhe et al.
3.1 Regression  The variational distributions for regression have the following forms:  Y Y Y Y  k  k  QðwÞ ¼ Nðwjm,  Þ Y k ð1    kÞ1  k   k  Qð Þ ¼  k  Qð Þ ¼  QðuÞ /  QðvÞ /  ð kjÞ kjð1    kjÞ1  kj  j  ðukÞ  ak 1ð1   ukÞ  bk 1 Y  ðvkjÞ  ckj 1ð1   vkjÞ  dkj 1  k  j  Qð Þ ¼  ð j  g,  hÞ  Their parameters are iteratively updated as follows:    ¼ ðA þ h iXTXÞ 1  m ¼ h i XTt   bk ¼ 1    k þ b  dkj ¼ 1    kj þ d     s1 s2  ln   ak ¼  k þ a  ckj ¼  kj þ c      k ¼ 1=ð1 þ expðhlnð1   ukÞi   hln uki þ pk 2 Lk   1 s2     hlnð1   vkjÞi   hln vkji hðwkjÞ2i    hwkwT ki      1   2  kj ¼ 1=  lnjLkj þ 1   2  1 þ exp þ 1 r1 r2 2  þ 1 2  1 s1  1 r1  ln  tr  Ik    1 X r2   h ¼ h þ 1 2  tTt   mTXTt þ 1 2  i hwwTixi xT  i  ð8Þ  ð9Þ  ð10Þ  ð11Þ  ð12Þ  ð13Þ  ð14Þ  ð15Þ  ð16Þ  ð17Þ  ð18Þ  ð19Þ   g ¼ g þ N ð20Þ 2 diagð Þþ diagðf kLkgkÞ þ 1 where A ¼ 1 diagð1    Þ [note that diagðf kLkgkÞ is a block-diagonal ma- trix], h i means expectation over the corresponding variational distribution, and the required moments in the above equations are  diagðfð1    kÞIkgkÞþ 1  1 r2  r1  s1  s2  hwwTi ¼   þ mmT hln uki ¼  ð  akÞ    ð  ekÞ hln vkji ¼  ð  ckjÞ    ð  fkjÞ  h i ¼  g=  h hlnð1   ukÞi ¼  ð  bkÞ    ð  ekÞ hlnð1   vkjÞi ¼  ð  dkjÞ    ð  fkjÞ  where  ðxÞ ¼ d  dx ln  ðxÞ,  ek ¼  ak þ  bk and  fkj ¼  ckj þ  dkj.
3.2 Classification  Compared with regression, the classification task is more challenging.
Because of the logistic function (2), we cannot dir- ectly solve the variational distribution QðwÞ.
Therefore, we use a  1990  lower bound proposed by (Jaakkola and Jordan, 2000) to replace the logistic function in the joint distribution:   ðyÞtð1    ðyÞÞ1 t         fð Þðð2t   1Þ2y2    2Þ  ð21Þ  ð2t   1Þy      2     ð Þ exp where fðxÞ ¼ 1 4  tanhð =2Þ, and   is a variational parameter.
Note that the equality is achieved when   ¼ ð2t   1Þy.
Because the logarithm of the lower bound (21) is quadratic in y, it essentially converts the logistic function into a Gaussian form so that the variational inference becomes tractable.
Combining the maximization of the lower bound (21) with the minimization of the KL divergence (7), we obtain the variational updates for classification.
They are the same as those for the regression task, except for that QðwÞ ¼ Nðwjm,  Þ, now we have ð22Þ    A þ 2   XTð2t   1Þ  X  fð iÞxixT    ¼      1  i  i  m ¼ 1 2  where A is the same as in the regression.
In addition, maximization of the lower bound of the logistic  function gives the update for the variational parameter  i:  i ¼ xT  2  i hwwTixi:  ð23Þ  3.3 Computational cost  The computational cost of the proposed algorithm is dominated by (14) for regression and (22) for classification.
For both cases, it takes Oðp3Þ for matrix inversion to obtain   and OðNp þ p2Þ to obtain m for each iteration.
Thus, the total cost is Oðp3 þ NpÞ and, for most applications where p4N, it simplifies to Oðp3Þ.
4 EXPERIMENTS  In this section, we apply NaNOS to synthetic and real gene expression data to select pathways (i.e.
networks) and genes (i.e.
nodes), and provide biological analysis of our results.
We also compare NaNOS with alternative methods, including lasso (Tibshirani, 1996), elastic net (Zou and Hastie, 2005), group lasso (Jacob et al., 2009  Yuan and Lin, 2007), the network-con- strained regularization approach [Li and Li (2008), henceforth  LL ] and the sparse Bayesian model with the classical spike and slab prior (George and McCulloch, 1997).
For lasso and elastic net, we used the Glmnet software package (www-stat.stanford.
edu/ tibs/glmnet-matlab/).
For group lasso, we treat each path- way as a group.
To handle genes appearing in multiple pathways (i.e.
groups), we first duplicated their expression levels for each group as suggested by (Jacob et al., 2009) and then used the SLEP software package (www.public.asu.edu/ jye02/Software/ SLEP/) for group lasso estimation.
For the spike and slab model, we implemented variational inference similar to our updates in Section 3.
Just as NaNOS, all these software packages use the Gaussian likelihood for regression and the logistic likeli- hood for classification.
We used the default configuration of these software packages for the maximum number of iterations, initial values and the threshold for convergence.
To tune regu- larization weights in lasso, group lasso and the LL approach, we conducted thorough 10-fold CV on training data (i.e.
not using the test data) using a large computer cluster.
The CV grids on the   Joint network and node selection for pathway-based genomic data analysis  lasso  (both  free parameters are summarized here: for lasso,   ¼ ½0 : 0:01 : 1   for elastic net,   ¼ ½0 : 0:01 : 1  and   ¼ ½0 : 0:01 : 1   for group regression),   ¼ ½0 : 0:01 : 1   and for the LL approach,  1 ¼ ½1 : 25 : 300  and  2 ¼ ½1 : 25 : 300  (we also did a second-level CV after we pruned the range of  1 and  2 values based on the first-level CV).
Finally, for NaNOS, the CV grids are s1 ¼ r1 ¼ ½0:1, 1, 3  and s2 ¼ r2 ¼ ½10 3, 10 4, 10 5, 10 6 .
regression  logistic  and  On the synthetic data for which we knew the true relevant pathways, we also compared NaNOS with a popular tool for gene set enrichment analysis (GSEA) (Mootha et al., 2003  Subramanian et al., 2005).
We treated each pathway as a set, used GSEA s default configuration and applied its suggested criterion false discovery rate (FDR) 525% to discover enriched pathways.
We then identified all the genes in these enriched path- ways as target genes.
Because GSEA cannot provide predictions on responses t, we did not include it for comparison on the real data.
4.1 Simulation studies  We first compare all the methods on synthetic data in the following three experiments.
Experiment 1.
We followed the first and second data gener- ation models used by Li and Li (2008).
Specifically, we simulated expression levels of 200 transcription factors (TFs), each control- ling 10 genes in a simple tree-structured regulatory network, and assumed that four pathways including all of their genes have effect on the response t. We sampled the expression levels of each TF from a standard normal distribution, xTF   Nð0, 1Þ and the expression level of each gene that this TF regulates from Nð0:7xTF, 0:51Þ.
This implies a correlation of 0:7 between the ﬃﬃﬃﬃ TF and its target genes.
For the first model with the continuous response, we designed p  , corresponding to the TF and 10 genes it regulates, and then  for each pathway,   ¼ ½1,  a weight vector  p , .
.
.
,  ﬃﬃﬃﬃ  1 10  1 10  sampled t as follows:       w ¼ ½5 ,   5 , 3 ,   3 , 0 t ¼ Xw þ   eÞ and 0 is a vector of all zeros.
where     Nð0,  2 2 664    ¼ 1,  The second model is the same as the first one, except that the genes regulated by the same TF can have either positive or nega- tive effect on the response t. Specifically, we set   1ﬃﬃﬃﬃﬃ p , 10   1ﬃﬃﬃﬃﬃ p , 10   1ﬃﬃﬃﬃﬃ p , 10  3 775: 1ﬃﬃﬃﬃﬃ 1ﬃﬃﬃﬃﬃ  ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ  p p , .
.
.
, 10  10  7  For the first and second models, the noise variance was set to be e ¼ ð jw2 j Þ=4 so that the signal-to-noise ratio was 12:85 and  2 7:54, respectively.
For the binary response, we followed the same procedure as for the continuous response to generate expression profiles X and the parameters w. Then we sampled t from (2).
For each of the settings, we simulated 100 samples for training and 100 samples for test.
We repeated the simulation 50 times.
To evaluate the predictive performance, we calculated the  prediction mean-squared error for regression and the error rate for classification.
To examine the accuracy of gene and pathway and specificity and summarized them in the F1 score, F1 ¼ 24 ðsensitivity   specificityÞ=ðsensitivity þ specificityÞ: The bigger the F1 score, the higher the selection accuracy.
selection, we  computed  sensitivity  also  All the results are summarized in Figure 2, in which the error bars represent the standard errors.
For all the settings, NaNOS gives smaller errors and higher F1 scores for gene selection than the other methods, except that, for classification of the samples from the second data model, NaNOS and group lasso obtain the comparable F1 scores.
All the improvements are significant under the two-sample t-test (P50.05).
We also show the accuracy of group lasso, GSEA and NaNOS for pathway selection in Figure 5.
Again, NaNOS achieves significantly higher selection accuracy.
Because the LL approach was developed for regression, we did not have its classification results.
While the LL approach uses the topological information of all the pathways, they are merged together into a global network for regularization.
In con- trast, using a sparse prior over individual pathways, NaNOS can explicitly select pathways relevant to the response, guiding the gene selection.
This may contribute to its improved performance.
Experiment 2.
For the second experiment, we did not require all genes in relevant pathways to have effect on the response.
Specifically, we simulated expression levels of 100 TFs, each regulating 21 genes in a simple regulatory network.
We sampled the expression levels of the TFs, the regulated genes and their response in the same way as in Experiment 1, except that we set  2 664    ¼ 1,  3 775  1ﬃﬃﬃﬃﬃ 1ﬃﬃﬃﬃﬃ  ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ  p p , .
.
.
, 21 21   ﬄﬄﬄﬄ zﬄﬄﬄﬄ   , 0, .
.
.
, 0  11  10  2 664  for the first data generation model and   1ﬃﬃﬃﬃﬃ p , 21   1ﬃﬃﬃﬃﬃ p , 21   1ﬃﬃﬃﬃﬃ p , 21  1ﬃﬃﬃﬃﬃ 1ﬃﬃﬃﬃﬃ  ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ  p p , .
.
.
, 21  21    ¼ 1,  3 775 ð24Þ   ﬄﬄﬄﬄ zﬄﬄﬄﬄ   , 0, .
.
.
, 0  11  7  for the second data generation model.
Note that the last 11 zero elements in   indicate that the corresponding genes have no effect on the response t, even in the four relevant pathways.
The results for both the continuous and binary responses are summarized in Figures 3 and 5.
For regression based on the first data model, NaNOS and LL obtain the comparable F1 scores  for all the other cases, NaNOS significantly outperforms the alternative methods in terms of both prediction and selection accuracy (P50.05).
Experiment 3.
Finally, we simulated the data as in Experiment 2, except that we replaced in the denominators in (24) with 21, to obtain a weaker regulatory effect of the TF.
Again, as shown in Figures 4 and 5, NaNOS outperforms the competing methods significantly.
ﬃﬃﬃﬃﬃ p 21  4.2 Application to expression data  Now we demonstrate the proposed method by analyzing gene expression datasets for the cancer studies of DLBCL (Rosenwald et al., 2002), CRC (Ancona et al., 2006) and  1991   S.Zhe et al.
(a)  (b)  (c)  (d)  Fig.
2.
Prediction errors and F1 scores for gene selection in Experiment 1.
ENet, S&S and GLasso stand for elastic net, the spike and slab model and group lasso, respectively  Data 1 and 2 indicate the first and second data generation models  (a)  (b)  (c)  (d)  Fig.
3.
Prediction errors and F1 scores for gene selection in Experiment 2  (a)  (b)  (c)  (d)  Fig.
4.
Prediction errors and F1 scores for gene selection in Experiment 3  PDAC (Badea et al., 2008).
We used the probeset-to-gene map- ping provided in these studies.
For the CRC and PDAC datasets in which multiple probes were mapped to the same genes, we took the average expression level of these probes.
We used the pathway information from the KEGG pathway database (www.
genome.jp/kegg/pathway.html) by mapping genes from the cancer studies into the database, particularly in the categories of Environmental Information Processing, Cellular Processes and Organismal Systems.
4.2.1 Diffuse large B cell lymphoma We used gene expression profiles of 240 DLBCL patients from an uncensored study in the Lymphoma and Leukemia Molecular Profiling Project (Rosenwald et al., 2002).
From 7399 probes, we found 752 genes and 46 pathways in the KEGG dataset.
The median sur- vival time of the patients is 2.8 years after diagnosis and chemo- therapy.
We used the logarithm of survival times of patients as the response variable in our analysis.
We randomly split the dataset into 120 training and 120 test samples 100 times and ran all the competing methods on each partition.
The test performance is visualized in Figure 6a.
NaNOS significantly outperforms lasso, elastic net and group lasso.
Although the results of the LL approach can contain con- nected subnetworks, these subnetworks do not necessarily cor- respond to (part of) a biological pathway.
For instance, they may  1992  (a)  (b)  Fig.
5.
F1 scores for pathway selection.
EXP  stands for  Experiment  and  D  stands for  Data model   consist of components from multiple overlapped pathways.
In contrast, NaNOS explicitly selects relevant pathways.
Four path- ways had the selection posterior probabilities larger than 0.95 and they were consistently chosen in all the 100 splits.
Two of these pathways are discussed below.
First, NaNOS selected the antigen processing and presentation pathway.
The part of this pathway containing selected genes is visualized in Figure 7a.
A selected regulator CIITA was shown to regulate two classes of antigens MHC I and II in DLBCL (Cycon et al., 2009).
The loss of MHC II on lymphoma cells including the selected HLA-DMB, -DQB1, -DMA, -DRA, -DRB1, -DPA1, -DPB1 and -DQA1 was shown to be related to poor prognosis and reduced survival in DLBCL patients (Rosenwald et al., 2002).
Joint network and node selection for pathway-based genomic data analysis  (a)  (b)  (c)  Fig.
6.
Predictive performance on three gene expression studies of cancer  (c)  (a)  (b)  Fig.
7.
Examples of part of identified pathways.
(a) The antigen processing and presentation pathway for DLBCL  (b) the cell cycle pathway for CRC  (c) the TGF-  signaling pathway for PDAC.
Shaded and unshaded boxes indicate selected and not selected genes, respectively  The selected MHC I (e.g.
HLA-A,-B,-C,-G) was reported to be absent from the cell surface, allowing the escape from immuno- surveillance of lymphoma (Amiot et al., 1998).
And the selected Ii/ CD74 and HLA-DRB were proposed to be monoclonal antibody targets for DLBCL drug design (Dupire and Coiffier, 2010).
Second, NaNOS chose cell adhesion molecules (CAMs).
Adhesive interactions between lymphocytes and the extracellular matrix (ECM) are essential for lymphocytes  migration and homing.
For example, the selected CD99 is known to be overex- pressed in DLBCL and correlated with survival times (Lee et al., 2011), and LFA-1 (ITGB2/ITGAL) can bind to ICAM on the cell surface and further lead to the invasion of lymphoma cells into hepatocytes (Terol et al., 1999).
4.2.2 Colorectal cancer We applied our model to a CRC data- set (Ancona et al., 2006).
It contains gene expression profiles from 22 normal and 25 tumor tissues.
We mapped 2455 genes from 22 283 probes into 67 KEGG pathways.
The goal was to predict whether a tissue has the CRC or not and select relevant pathways and genes.
We randomly split the dataset into 23 training and 24 test sam- ples 50 times and ran all the methods on each partition.
The test performance is visualized in Figure 6b.
Again, based on a two- sample t-test, NaNOS outperforms the alternatives significantly (P50.05).
Three out of the four pathways with the selection pos- terior probabilities larger than 0.95 are discussed below.
They were selected 20, 50 and 50 times in the 50 splits.
First, NaNOS selected the cell cycle pathway.
This selection is consistent with the original result by Ancona et al.
(2006).
As shown in Figure 7b, NaNOS selected mitotic spindle assembly related genes.
Specifically, Bub1 and Mad1 may regulate the  checkpoint complex (MCC) containing Mad2, BubR1 and Bub3.
The upregulated MCC may in turn inhibit ability of APC/C to ubiquitinate securin and further lead to mitotic event extension in CRC (Menssen et al., 2007).
NaNOS also chose cyclin/CDK complexes, among which CycD/CDK4 overexpres- sion is found in mouse colon tumor and CDK1, CDK2, CycE are increased in human CRC (Vermeulen et al., 2003  Wang et al., 1998).
NaNOS further identified the minichromosome mainte- nance (MCM) complex including MCM2 and MCM5 which are biomarkers for the CRC stage identification (Giaginis et al., 2009).
Moreover, the selected TP53 and c-Myc are known to be closely related to CRC (Menssen et al., 2007).
Second, NaNOS chose the intestinal immune network for IgA production.
A greatly increased level of IgA as a result of long- term intestinal inflammation can increase the chance of CRC (Rizzo et al., 2011) and serve as an effective biomarker for early diagnosis of CRC (Chalkias et al., 2011).
Also, selected chem- kines in this pathway, such as CXCR4 and CXCL12, may con- tribute to CRC progression (Sakai et al., 2012).
Third, NaNOS selected the cytokine cytokine receptor inter- action pathway as well as several well-known CRC-related molecules in this pathway.
For instance, CXCL13 is a biomarker for stage II CRC prognosis (Agesen et al., 2012), CXCL10 dra- matically increases with CRC progression (Toiyama et al., 2012) and IL10 secreted by CRC cells can accelerate tumor prolifer- ation and be used for the prognosis of CRC progression (Toiyama et al., 2010).
4.2.3 Pancreatic ductal adenocarcinoma This cancer dataset in- cludes expression profiles from 39 PDAC and 39 normal subjects (Badea et al., 2008).
By mapping 2781 genes from 54 677 probes  1993   S.Zhe et al.
Fig.
8.
The predictive performance of NaNOS when the pathway struc- tures are inaccurate.
When more edges are randomly selected and removed from each pathway, the performance of NaNOS degrades smoothly, but still better than the competing methods  into KEGG pathways, we obtained 67 pathways.
Our goal was to predict whether a subject has the pancreatic cancer and select relevant pathways and genes.
We randomly split the dataset into 39 training and 39 test samples 50 times and ran all the methods on each partition.
The test performance is visualized in Figure 6c.
Based on a two-sample t-test, NaNOS significantly outperforms lasso, elastic net and group lasso.
To investigate the sensitivity of NaNOS to the structural noise in the pathway database, we randomly chose 20, 50, 80 and 100% edges in each pathway and removed them.
We tested NaNOS for each case and reported the average test error rate in the new Figure 8.
As expected, the error rate of NaNOS grad- ually increases with more edges being removed because less topo- logical information in pathways is available.
But NaNOS still consistently outperformed all the alternative methods such as elastic net, the second best method on this dataset.
This experi- ment demonstrates (i) that by exploiting subtle correlation infor- mation embedded in the pathway topology, NaNOS can boost its modeling power and predictive performance, and (ii) that NaNOS is robust to small perturbation in pathway topology.
(mean 0:09 and standard deviation 0:083)  We also examined the impact of the important prior distribu- tions on pathway and gene selection probabilities uk and vkj.
As described in Section 2, we used the uniform priors [i.e.
the Beta(1,1) prior] over uk and vkj, indicating no prior preference over selecting a pathway or gene or not.
The average test error based on the uninformative priors is 9:15   0:5, as visualized in Figure 6c.
If we change the prior to an informative one, Beta(1,10) that strongly prefers sparsity, then the average test error increases slightly to 10:0   0:4.
This minor increase in error may stem from the oversparification caused by the sparsity prior that are overconfident (suggested by a small variance).
Now if we use another informative prior Beta(10,1) (mean 0:91 and standard deviation 0:083) strongly prefers dense instead of sparse estimation, then the average test error increases to 11:2   0:5.
This relatively larger error increase is exactly what we expected because now the wrong dense prior aims to select most pathways and genes.
What is important is that, no matter which of these two informative priors we chose, NaNOS consist- ently outperformed lasso and group lasso in Figure 6c.
Between these two extreme cases, if we use an uninformative or weak sparse prior [e.g.
Beta(0.5,0.5)], we find that similar prediction error rates were obtained for NaNOS as in Figure 6c.
The above analysis indicates that NaNOS is robust to the prior choice.
that  1994  In addition to using the even splitting strategy with the same number of training and test samples, we also tested the perform- ance of all the algorithms in another setting with more training samples specifically, 62 training and 16 test samples.
We repeated the random partitioning 50 times.
The average error rates for NaNOS, elastic net, lasso and group lasso are 8:00   0:89, 9:90   1:00, 12:0   1:0 and 11:0   0:14, respect- ively.
Again, the two-sample t-test indicates that NaNOS outper- forms the alternative methods significantly (P50.05).
Three out of the five pathways with the selection posterior probabilities larger than 0.95 are discussed below.
They were selected 35, 50 and 50 times in the 50 splits.
The first selected pathway was the transforming growth factor beta (TGF- ) signaling pathway.
It is essential in epithelial-mes- enchymal transition (EMT) a critical component for develop- mental and cancer processes and related to PDAC (Krantz et al., 2012).
The selected part of this pathway is visualized in Figure 7c.
It shows that IFNG, TNF- , LTBP1, DCN, TGF-  and its receptor TGF-  R1 were selected.
The TGF-  ligand  via its receptor propagates the signal through phosphorylation of Smads including the selected Smad 4, which in turn translocate into the nucleus and interact with Snail TFs to regulate EMT (Krantz et al., 2012).
The selected BMP ligand (i.e.
BMP2) is bound to BMP R1 and R2 receptors to activate Smad1, which is in a protein complex including Smad4.
Gordon et al.
(2009) showed that in PANC-1 cell line, this protein complex mediates EMT partially by increasing the activity of MMP-2.
The second identified pathway was ECM receptor interaction.
It is associated with desmoplastic reaction, a hallmark in PDAC (Shields et al., 2012).
In this pathway, NaNOS selected the in- tegrin receptors including ITGB1, ITGA2, ITGA3, ITGA5, ITGA6 and the ECM proteins collagens including COL1A1 and COL1A2, and laminins including LAMC2 and LAMB3.
Important interactions among them were revealed in a previous study by Weinel et al.
(1992).
The third chosen pathway was CAMs.
CAMs are pivotal in pancreatic cancer invasion by mediating cell cell signal transduc- tion and cell matrix communication (Keleg et al., 2003).
In this pathway, the selected molecules include calcium-dependent cad- herin family molecules (CDH2, CDH3) and neural-related mol- ecules (MAG)  both of them have shown to be related to PDAC (Kameda et al., 1999  Keleg et al., 2003).
5 DISCUSSION  As shown in the previous section, the new Bayesian approach, NaNOS, outperformed the alternative sparse learning methods on both simulation and real data by a large margin.
Now we discuss three factors that may contribute to the improved per- formance of NaNOS.
First, the spike and slab prior (3) and its generalization (4) in NaNOS separate weight regularization from the selection of vari- ables (pathways or genes).
Both the (generalized) spike and slab prior and elastic net can be viewed as mixture models in which one component encourages the selection of variables and the other helps remove irrelevant ones.
However, unlike the elastic net where the weights over l1 and l2 penalty functions are fixed, the spike and slab prior has the selection indicators over these two components estimated from data.
When a variable is   Joint network and node selection for pathway-based genomic data analysis  selected, the model has a Gaussian prior over its value (i.e.
weight) that is equivalent to a l2 regularizer (as in ridge regres- sion) and does not shrink the value of the selected variable as l1 penalty would do.
By contrast, lasso or elastic net, with a fixed mixture weight, has sparsity penalty over both pruned and se- lected variables, which can greatly shrink the values of selected variables and hurt predictive performance.
Second, NaNOS incorporates correlation structures encoded in pathways for variable selection.
Specifically, it uses pathway structures into the extended spike and slab prior distribution to explicitly model the detailed relationships between correlated genes.
In contrast, lasso and elastic net do not use this valuable correlation information in their models.
By comparing prediction accuracies of NaNOS when 0 and 100% edges are removed from pathways (Fig.
8), we can see that the detailed correlation infor- mation captured by the pathway topology can greatly improve modeling quality.
Third, NaNOS has the capability of selecting both relevant pathways and genes due to its two-layer sparse structure.
By contrast, with l1=l2 penalty, group lasso encourages the selection of all the genes in chosen pathways, leading to dense estimation.
This may be undesirable in practice and deteriorate the predictive performance of group lasso.
NaNOS enhances the flexibility of group lasso by conducting sparse estimation at both the pathway (or group) and gene levels.
Meanwhile, our Bayesian estimation effectively avoids overfitting, a problem often plaguing flexible models.
NaNOS has been applied to joint pathway and gene selection in this article.
Inspired by the seminal works in (Chuang et al., 2007  Fro  hlich et al., 2006  Srivastava et al., 2008  Zycinski et al., 2013), we can use NaNOS in a variety of biomedical applications where there are abundant high-dimensional biomarkers of indi- vidual samples and other information sources for example, the gene ontology (GO) and protein protein interaction networks information that capture correlation in the high-dimensional space.
Here we discuss two approaches to apply NaNOS when we have only GO or other group information without network topology.
The first approach is to compute some distance or similarity scores between genes based on the GO information [e.g.
following the approach by Srivastava et al.
(2008)] and then estimate the network topology based on a network learning method, for example, graphical lasso (Friedman et al., 2008).
With the estimated network topology, we can compute the graph Laplacian matrices and apply NaNOS to select genes and groups of genes.
The second approach is to directly use the group membership information in NaNOS by replacing the graph Laplacian matrices with identity matrices.
This approach becomes useful when we even do not have any information avail- able to learn the network topology.
As shown in Figure 8, even when all the edges were removed and we had only group infor- mation, NaNOS still outperformed the second best method, elas- tic net, in terms of prediction accuracy.
Funding: This work was supported by NSF IIS-0916443, NSF CAREER Award IIS-1054903, and the Center for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-0939370.
Conflict of Interest: none declared.
REFERENCES  Agesen,T.
et al.
(2012) ColoGuideEx: a robust gene classifier specific for stage II  colorectal cancer prognosis.
Gut., 61, 1560 1567.
Amiot,L.
et al.
(1998) Loss of HLA molecules in B lymphomas is associated with an  aggressive clinical course.
Br.
J.
Haematol., 100, 655 663.
Ancona,N.
et al.
(2006) On the statistical assessment of classifiers using DNA  microarray data.
BMC Bioinformatics, 7, 387.
Badea,L.
et al.
(2008) Combined gene expression analysis of whole-tissue and micro- dissected pancreatic ductal adenocarcinoma identifies genes specifically overex- pressed in tumor epithelia.
Hepatogastroenterology, 55, 2016 2027.
Bishop,C.M.
(2006) Pattern Recognition and Machine Learning (Information Science  and Statistics).
Springer-Verlag New York, Inc., Secaucus, NJ.
Chalkias,A.
et al.
(2011) Patients with colorectal cancer are characterized by increased concentration of fecal hb-hp complex, myeloperoxidase, and secretory IgA.
Am.
J. Clin.
Oncol., 34, 561 566.
Chuang,H.
et al.
(2007) Network-based classification of breast cancer metastasis.
Mol.
Syst.
Biol., 3, 140.
Cycon,K.
et al.
(2009) Alterations in CIITA constitute a common mechanism accounting for downregulation of MHC class II expression in diffuse large B-cell lymphoma (DLBCL).
Exp.
Hematol., 37, 184 194.
Dupire,S.
and Coiffier,B.
(2010) Targeted treatment and new agents in diffuse large  B cell lymphoma.
Int.
J.
Hematol., 92, 12 24.
Friedman,J.
et al.
(2008) Sparse inverse covariance estimation with the graphical  lasso.
Biostatistics, 9, 432 441.
Fro  hlich,H.
et al.
(2006) Kernel based functional gene grouping.
In: International Joint Conference on Neural Networks.
IEEE Computer Society, Los Alamitos, CA, USA, pp.
3580 3585.
George,E.I.
and McCulloch,R.E.
(1997) Approaches for bayesian variable selection.
Statistica Sinica, 7, 339 373.
Giaginis,C.
et al.
(2009) Clinical significance of MCM-2 and MCM-5 expression in colon cancer: association with clinicopathological parameters and tumor prolif- erative capacity.
Dig.
Dis.
Sci., 54, 282 291.
Gordon,K.
et al.
(2009) Bone morphogenetic proteins induce pancreatic cancer cell invasiveness through a Smad1-dependent mechanism that involves matrix metalloproteinase-2.
Carcinogenesis, 30, 238 248.
Jaakkola,T.S.
and Jordan,M.I.
(2000) Bayesian parameter estimation through vara-  tional methods.
Stat.
Comput., 10, 25 37.
Jacob,L.
et al.
(2009) Group lasso with overlap and graph lasso.
In: Proceedings the 26th International Conference on Machine Learning.
New York,  of pp.
433 440.
Kameda,K.
et al.
(1999) Expression of highly polysialylated neural cell adhesion molecule in pancreatic cancer neural invasive lesion.
Cancer Lett., 137, 201 207.
Keleg,S.
et al.
(2003) Invasion and metastasis in pancreatic cancer.
Mol.
Cancer,  2, 14.
Krantz,S.
et al.
(2012) Contribution of epithelial-to-mesenchymal  transition and cancer stem cells to pancreatic cancer progression.
J. Surg.
Res., 173, 105 112.
Lasserre,J.
et al.
(2006) Principled hybrids of generative and discriminative models.
In: IEEE Computer Society Conference on Computer Vision and Pattern Recognition.
Vol.
1, IEEE Computer Society, Washington, DC, USA, pp.
87 94.
Lee,S.
et al.
(2011) Clinicopathologic characteristics of CD99-positive diffuse large  B-cell lymphoma.
Acta.
Haematol., 125, 167 174.
Li,C.
and Li,H.
(2008) Network-constrained regularization and variable selection  for analysis of genomics data.
Bioinformatics, 24, 1175 1182.
Li,F.
and Zhang,N.
(2010) Bayesian variable selection in structured high-dimen- sional covariate space with applications in genomics.
J.
Am.
Stat.
Assoc., 105, 1202 1214.
Menssen,A.
et al.
(2007) c-MYC delays prometaphase by direct transactivation of MAD2 and BubR1: identification of mechanisms underlying c-MYC-induced DNA damage and chromosomal instability.
Cell Cycle, 6, 339 352.
Mootha,V.K.
et al.
(2003) PGC-1 -responsive genes involved in oxidative phos- phorylation are coordinately downregulated in human diabetes.
Nat.
Genet., 34, 267 273.
Rizzo,A.
et al.
(2011) Intestinal inflammation and colorectal cancer: a double-edged  sword  World J.
Gastroenterol., 17, 3092 3100.
Rosenwald,A.
et al.
(2002) The use of molecular profiling to predict survival after lymphoma.
N. Engl.
J.
Med., 346,  chemotherapy for diffuse large-B-cell 1937 1947.
1995   S.Zhe et al.
Sakai,N.
et al.
(2012) CXCR4/CXCL12 expression profile is associated with tumor microenvironment and clinical outcome of liver metastases of colorectal cancer.
Clin.
Exp.
Metastasis, 29, 101 110.
Toiyama,Y.
et al.
(2012) Evaluation of CXCL10 as a novel serum marker for pre- dicting liver metastasis and prognosis in colorectal cancer.
Int.
J.
Oncol., 40, 560 566.
Shields,M.
et al.
(2012) Biochemical role of the collagen-rich tumour microenviron-  Vermeulen,K.
et al.
(2003) The cell cycle: a review of regulation, deregulation and  ment in pancreatic cancer progression.
Biochem.
J., 441, 541 552.  therapeutic targets in cancer.
Cell Prolif., 36, 131 149.
Wang,Q.
et al.
(1998) Altered expression of cyclin D1 and cyclin-dependent kinase 4 in azoxymethane-induced mouse colon tumorigenesis.
Carcinogenesis, 19, 2001 2006.
Wei,Z.
and Li,H.
(2007) A Markov random field model for network-based analysis  of genomic data.
Bioinformatics, 23, 1537 1544.
Wei,Z.
and Li,H.
(2008) A hidden spatial-temporal Markov random field model for network-based analysis of time course gene expression data.
Ann.
Appl.
Stat., 2, 408 429.
Weinel,R.
et al.
(1992) Expression and function of VLA- 2, - 3, - 5 and  alpha6-  integrin receptors in pancreatic carcinoma.
Int.
J.
Cancer, 52, 827 833.
Yuan,M.
and Lin,Y.
(2007) Model selection and estimation in regression with  grouped variables.
J. R Stat.
Soc., B, 68, 49 67.
Zou,H.
and Hastie,T.
(2005) Regularization and variable selection via the elastic  net.
J. R Stat.
Soc., B, 67, 301 320.
Zycinski,G.
et al.
(2013) Knowledge Driven Variable Selection (KDVS) a new ap- proach to enrichment analysis of gene signatures obtained from high-through- put data.
Source Code Biol.
Med., 8, 2.  proach for 15545 15550.
Terol,M.
et al.
Srivastava,S.
et al.
(2008) A novel method incorporating gene ontology information  for unsupervised clustering and feature selection.
PLoS One, 3, 12.
Stingo,F.C.
and Vannucci,M.
(2010) Variable selection for discriminant analysis with Markov random field priors for the analysis of microarray data.
Bioinformatics, 27, 495 501.
Stingo,F.C.
et al.
(2011) Incorporating biological information into linear models: A Bayesian approach to the selection of pathways and genes.
Ann.
Appl.
Stat., 5, 1978 2002.
Subramanian,A.
et al.
(2005) Gene set enrichment analysis: a knowledge-based ap- expression profiles.
PNAS, 102,  interpreting genome-wide  (1999) Expression of beta-integrin adhesion molecules  in non-Hodgkin s lymphoma: correlation with clinical and evolutive features.
J. Clin.
Oncol., 17, 1869 1875.
Tibshirani,R.
(1996) Regression shrinkage and selection via the lasso.
J. R Stat.
Soc., B, 58, 267 288.
Toiyama,Y.
et al.
(2010) Loss of tissue expression of interleukin-10 promotes the  disease progression of colorectal carcinoma.
Surg.
Today, 40, 46 53.
1996
